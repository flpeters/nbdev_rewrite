{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from collections import namedtuple, defaultdict\n",
    "import os\n",
    "import re\n",
    "from nbdev_rewrite.imports import *\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "import ast\n",
    "from ast import iter_fields, AST\n",
    "import _ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The normal stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_config(lib_name='nbdev_rewrite', user='flpeters', nbs_path='.'):\n",
    "    \"create a config file, if it doesn't already exist\"\n",
    "    if not Config().config_file.exists(): create_config(lib_name, user, nbs_path=nbs_path)\n",
    "init_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lib():\n",
    "    \"initialize the module folder, if it's not initialized already\"\n",
    "    C = Config()\n",
    "    if (not C.lib_path.exists()) or (not (C.lib_path/'__init__.py').exists()):\n",
    "        C.lib_path.mkdir(parents=True, exist_ok=True)\n",
    "        with (C.lib_path/'__init__.py').open('w') as f:\n",
    "            f.write(f'__version__ = \"{C.version}\"\\n')\n",
    "    else: pass # module *should* already exists\n",
    "init_lib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/Projects/GitHub/nbdev_rewrite/00_export.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/01_helpers.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/02_export_v2.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/03_export_v3.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/99_index.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/sub/lalalala.ipynb')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_reserved_dirs = (Config().lib_path, Config().nbs_path, Config().doc_path)\n",
    "def crawl_nbs(path:Path=None, recurse:bool=True) -> list:\n",
    "    \"finds a list of ipynb files to convert\"\n",
    "    if path is None: path = Config().nbs_path\n",
    "    if isinstance(path, (list, tuple)):\n",
    "        for p in path: yield from crawl_nbs(p, recurse)\n",
    "    elif path.is_file(): yield path\n",
    "    else:\n",
    "        for p in path.iterdir():\n",
    "            f = p.name\n",
    "            if f.startswith('.') or f.startswith('_'): continue\n",
    "            if p.is_file():\n",
    "                if f.endswith('.ipynb'): yield p\n",
    "                else: continue\n",
    "            elif p.is_dir() and recurse:\n",
    "                if p in _reserved_dirs: continue\n",
    "                else: yield from crawl_nbs(p, recurse)\n",
    "            else: continue\n",
    "list(crawl_nbs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_nb(fname:Path) -> nbformat.notebooknode.NotebookNode:\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return nbformat.reads(f.read(), as_version=4)\n",
    "len(read_nb('03_export_v3.ipynb')['cells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test\\\\abc'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def module2path(module:str) -> str:\n",
    "    \"replaces the python module '.' seperator with os specific path seperator\"\n",
    "    return os.path.sep.join(module.split('.'))\n",
    "module2path('test.abc')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: add support for a scoped #default_exp. Support exporting cells under a specific heading to a seperate file.\n",
    "setting #default_exp on a per-heading / per-scope level, not on a once per file level."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: # file-documentation tag, for writing a doc string for an entire file, or for an entire module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _notebook2script(fname, silent=False):\n",
    "    fname = Path(fname)\n",
    "    print(fname.name)\n",
    "    nb = read_nb(fname)\n",
    "    cells = nb['cells']\n",
    "    C = Config()\n",
    "    sep = '\\n' * (max(int(C.get('cell_spacing', 1)), 0) + 1)\n",
    "    for cell in cells:\n",
    "        # scan for\n",
    "        # default_exp\n",
    "        # export\n",
    "        # hide\n",
    "        # put all the stuff in datastructure, which should be thread safe\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_export.ipynb\n",
      "01_helpers.ipynb\n",
      "02_export_v2.ipynb\n",
      "03_export_v3.ipynb\n",
      "99_index.ipynb\n",
      "lalalala.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def notebook2script(fname=None, silent=False, to_dict=False):\n",
    "    # init target module directory\n",
    "    init_lib()\n",
    "    files = crawl_nbs(fname)\n",
    "    exports = []\n",
    "    for file in files:\n",
    "        exports.append(_notebook2script(file, silent))\n",
    "    # merge_exports(exports)\n",
    "    # if fname is a file, convert only that file, if possible.\n",
    "    # if its None, use Config() directory\n",
    "    # if its a directory,\n",
    "        # crawl source directory recursively to find all files that should be converted\n",
    "    # create thread/process pool for processing all files in parallel\n",
    "    # execute compilation on each of the files, resulting in a dataformat representing the converted file.\n",
    "    # merge all files, based on cross-exporting stored in dataformat\n",
    "    # TODO: handle cross-exporting if the targeted file already exists, but wasn't compiled from scratch\n",
    "    # probably should force a recompile of that file as well\n",
    "    # write files to disk\n",
    "    return exports\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefetcher [working]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import BackgroundGenerator, prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@prefetch(max_prefetch=4)\n",
    "def file_generator():\n",
    "    for f in crawl_nbs(): yield read_nb(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "2\n",
      "100\n",
      "98\n",
      "31\n",
      "2\n",
      "0.025006\n"
     ]
    }
   ],
   "source": [
    "tt = 0\n",
    "t0 = time.time()\n",
    "for x in file_generator():\n",
    "    t1 = time.time()\n",
    "    tt += t1 - t0\n",
    "    time.sleep(.5) # work\n",
    "    print(len(x['cells']))\n",
    "    t0 = time.time()\n",
    "print(round(tt, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hello\n",
      "Hi\n",
      "Hi\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "import time\n",
    "  \n",
    "def print_hello():\n",
    "    for i in range(4):\n",
    "        time.sleep(0.5)\n",
    "        print(\"Hello\")\n",
    "        \n",
    "def print_hi(): \n",
    "    for i in range(4): \n",
    "        time.sleep(0.7)\n",
    "        print(\"Hi\") \n",
    "\n",
    "t1 = threading.Thread(target=print_hello)  \n",
    "t2 = threading.Thread(target=print_hi)  \n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for multiprocessing to work, the function thats supposed to be executed, has to be importable aka in a .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan for comments in all cells\n",
    "# check for `export`, `hide`, and `meta` comments\n",
    "# if any `meta`:\n",
    "#     execute `meta`\n",
    "#     if control inversion:\n",
    "#         pass for now\n",
    "#     check for potential new comments due to `meta` execution\n",
    "# parse or discard all remaining comments\n",
    "# execute commands\n",
    "# aggregate results back in main process\n",
    "# return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(x): return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = ProcessPoolExecutor(max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent.futures.ProcessPoolExecutor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "2\n",
      "100\n",
      "28\n",
      "31\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for file in file_generator():\n",
    "    print(len(file['cells']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor(max_workers=4) as pool:\n",
    "    print(list(pool.map(f, range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # start 4 worker processes\n",
    "    with Pool(processes=4) as pool:\n",
    "\n",
    "        # print \"[0, 1, 4,..., 81]\"\n",
    "        print(pool.map(f, range(10)))\n",
    "\n",
    "        # print same numbers in arbitrary order\n",
    "        for i in pool.imap_unordered(f, range(10)):\n",
    "            print(i)\n",
    "\n",
    "        # evaluate \"f(10)\" asynchronously\n",
    "        res = pool.apply_async(f, [10])\n",
    "        print(res.get(timeout=1))             # prints \"100\"\n",
    "\n",
    "        # make worker sleep for 10 secs\n",
    "        # res = pool.apply_async(sleep, [10])\n",
    "        # print(res.get(timeout=1))             # raises multiprocessing.TimeoutError\n",
    "\n",
    "    # exiting the 'with'-block has stopped the pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coroutines and generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From generator 1\n",
      "From user 2\n",
      "From generator 1\n",
      "From user 3\n",
      "From generator 1\n",
      "From user 4\n",
      "From generator 1\n",
      "From user 5\n",
      "From generator 1\n",
      "From user 6\n",
      "From generator 1\n",
      "From user 7\n",
      "From generator 1\n",
      "From user 8\n",
      "From generator 1\n",
      "From user 9\n",
      "From generator 1\n"
     ]
    }
   ],
   "source": [
    "def coroutine():\n",
    "    for i in range(1, 10): print(f'From generator {yield i}')\n",
    "c = coroutine()\n",
    "c.send(None)\n",
    "try:\n",
    "    while True: print(f'From user {c.send(1)}')\n",
    "except StopIteration: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# Unaffected by send\n",
    "def double_number(number):\n",
    "    while True:\n",
    "        number *=2 \n",
    "        yield number\n",
    "\n",
    "c = double_number(4)\n",
    "print(c.send(None))\n",
    "print(next(c))\n",
    "print(next(c))\n",
    "print(c.send(8))\n",
    "print(c.send(8))\n",
    "print(c.send(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "10\n",
      "3000\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Works with send\n",
    "def double_number(number):\n",
    "    while True:\n",
    "        number *= 2\n",
    "        number = yield number\n",
    "        \n",
    "c = double_number(4)\n",
    "print(c.send(None))\n",
    "print(c.send(5)) #10\n",
    "print(c.send(1500)) #3000\n",
    "print(c.send(3)) #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "20\n",
      "None\n",
      "12\n",
      "None\n",
      "188.6\n"
     ]
    }
   ],
   "source": [
    "def double_inputs():\n",
    "    while True:\n",
    "        x = yield\n",
    "        yield x * 2\n",
    "\n",
    "gen = double_inputs()\n",
    "print(next(gen))       # run up to the first yield\n",
    "print(gen.send(10))    # goes into 'x' variable\n",
    "\n",
    "print(next(gen))       # run up to the next yield\n",
    "print(gen.send(6))     # goes into 'x' again\n",
    "\n",
    "print(next(gen))       # run up to the next yield\n",
    "print(gen.send(94.3))  # goes into 'x' again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @defer.inlineCallbacks\n",
    "# def doStuff():\n",
    "#     result = yield takesTwoSeconds()\n",
    "#     nextResult = yield takesTenSeconds(result * 10)\n",
    "#     defer.returnValue(nextResult / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def doStuff():\n",
    "#     returnDeferred = defer.Deferred()\n",
    "#     def gotNextResult(nextResult):\n",
    "#         returnDeferred.callback(nextResult / 10)\n",
    "#     def gotResult(result):\n",
    "#         takesTenSeconds(result * 10).addCallback(gotNextResult)\n",
    "#     takesTwoSeconds().addCallback(gotResult)\n",
    "#     return returnDeferred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multithreading, multiprocessing and generators"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "global settings:\n",
    "- seperation amount (vertical whitespace) between cells\n",
    "- how to look for comments\n",
    "- command syntax\n",
    "- \n",
    "\n",
    "all cell data:  \n",
    "- meta cells\n",
    "- default export target\n",
    "- file name\n",
    "\n",
    "per cell data:  \n",
    "- source code\n",
    "- variable, function and class names\n",
    "- export yes/no\n",
    "- internal (export names) yes/no\n",
    "- cell number / order\n",
    "\n",
    "Things that need to be aggregated before return:\n",
    "- union of all names\n",
    "- ordered list of source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(florian): Only look for 0 indent comments?\n",
    "def iter_comments(src:str, cell_nr:int, pure_comments_only:bool=True, line_limit=None):\n",
    "    \"Detect all comments in a piece of code, excluding those that are a part of a string.\"\n",
    "    in_lstr = in_sstr = False\n",
    "    count, quote = 1, ''\n",
    "    for i, line in enumerate(src.splitlines()[:line_limit]):\n",
    "        is_pure, escape, prev_c = True, False, '\\n'\n",
    "        for j, c in enumerate(line):\n",
    "            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns\n",
    "            if is_pure and (not (c.isspace() or c == '#')): is_pure = False\n",
    "            if (in_sstr or in_lstr):\n",
    "                # assert (in_sstr and not in_lstr) or (in_lstr and not in_sstr)\n",
    "                if escape: count = 0\n",
    "                else:\n",
    "                    if (c == quote):\n",
    "                        count = ((count + 1) if (c == prev_c) else 1)\n",
    "                        if in_sstr: in_sstr = False\n",
    "                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False\n",
    "                escape = False if escape else (c == '\\\\')\n",
    "            else:                    \n",
    "                if (c == '#'):\n",
    "                    if (pure_comments_only and is_pure): yield (line, (i, j))\n",
    "                    elif (not pure_comments_only):       yield (line[j:], (i, j))\n",
    "                    break\n",
    "                elif c == \"'\" or c == '\"':\n",
    "                    count = ((count + 1) if (c == prev_c) else 1)\n",
    "                    if count == 1: in_sstr = True\n",
    "                    elif count == 3: count, in_lstr = 0, True\n",
    "                    else: raise SyntaxError(f'Unexpected quote repetition count: {count} Should be either 1 or 3. Cell_nr: {cell_nr} Line:{i}/{j}')\n",
    "                    quote = c\n",
    "            prev_c = c"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This pseudo code below doesn't look like the right way to do it..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for file in iter_files():\n",
    "    for cell in file:\n",
    "        export, internal, default_export, meta = False, False, None, None\n",
    "        for comment in cell:\n",
    "            # res = parser['export'](comment)\n",
    "            if 'export' in comment:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_receive_message\n",
    "start_message_loop\n",
    "message_callback = main\n",
    "INVERT_CONTROL = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "buckets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Two options for matching comments to commands:\n",
    "\n",
    "1: parsing a comment first, then checking if its valid, and then searching for a match\n",
    "2: for every command, check if the comment matches, and then check if its valid\n",
    "\n",
    "three steps:\n",
    "- check if it's valid syntax\n",
    "- strip comment of superficial charactes like '#' and spaces, and map to standardised schema understood by the rest of the compiler\n",
    "- match comment to command\n",
    "\n",
    "- execute command, and pass result back to the rest of the programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell:\n",
    "    def __init__(self, cell:dict, cell_nr:int):\n",
    "        # cell data\n",
    "        self.cell_nr     = cell_nr\n",
    "        self.source_code = cell['source']\n",
    "        self.cell_type   = cell['cell_type']\n",
    "        # file state\n",
    "        self.default_export = None\n",
    "        # cell state\n",
    "        self.names , self._comments = set(), None\n",
    "        self.export, self.internal  = False, False\n",
    "        \n",
    "    def iter_ruptor(self, gen):\n",
    "        agg = []\n",
    "        for x in gen:\n",
    "            agg.append(x)\n",
    "            yield x\n",
    "        self._comments = agg\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self._comments is None:\n",
    "            return self.iter_ruptor(iter_comments(self.source_code, self.cell_nr))\n",
    "        else: return iter(self._comments)\n",
    "        \n",
    "    def stage_one(self):\n",
    "        for comment in self:\n",
    "            cmd = self.decode_comment(comment)\n",
    "            if cmd is None:\n",
    "                pass\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f'{self.cell_type}, {self.export}, {self.internal}, {self.default_export},\\n{self.source_code}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = Cell(read_nb('03_export_v3.ipynb')['cells'][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x1bf7ff2b688>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# export', (0, 0))\n"
     ]
    }
   ],
   "source": [
    "for c in cell:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iter(cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E:\n",
    "    def __init__(self, file_path, cells):\n",
    "        self.default_export = None\n",
    "        self.meta_cells = {}\n",
    "        self.export_cells = {}\n",
    "        self.file_path = file_path\n",
    "        self.cells = cells\n",
    "        \n",
    "    def stage_one(self):\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            is_meta, is_export, is_internal, comments = find_builtins(cell)\n",
    "            if is_meta: self.meta_cells[i] = cell\n",
    "            if is_export: self.export_cells[i] = (cell, is_internal)\n",
    "            \n",
    "    def stage_two(self, metas, default_exports):\n",
    "        self.meta_cells     = self.merge_metas          (self.meta_cells    , metas)\n",
    "        self.default_export = self.merge_default_exports(self.default_export, default_exports)\n",
    "        \n",
    "        if self.meta_cells: self.run_meta()\n",
    "        \n",
    "            \n",
    "    def run(self):\n",
    "        self.stage_one()\n",
    "        metas, default_exports = yield self.meta_cells, self.default_export\n",
    "        self.stage_two(metas, default_exports)\n",
    "        \n",
    "        \n",
    "    def main(self):\n",
    "        # communicate with main process\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_cells(fname, cells):\n",
    "    e = E(fname, cells)\n",
    "    metas, default_exports = next(e)\n",
    "    # communicate with main process\n",
    "    return e.send(metas, default_exports)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### per file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Needs a non-parallel, and a parallel path.\n",
    "To bootstrap the compiler, multiprocessing can't be used, because of the interactive nature of notebooks.\n",
    "Once the code is exported to a .py file, multiprocessing should be possible, but also optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_file(file):\n",
    "    processes = []\n",
    "    for chunk in chunkify(file['cells']):\n",
    "        processes.append(partial_cells(chunk))\n",
    "    dist_data = {}\n",
    "    for p in processes:\n",
    "        dist_data.set_data(p.get_dist())\n",
    "    for p in processes: p.push_dist(dist_data)\n",
    "    return [p.complete() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in cells:\n",
    "    cell = Cell(cell)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### per run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Files are loaded into memory by a background thread and are then yielded to us from the generator.\n",
    "Per file parallelism is possible, but might not be best idea, because while files are mostly independent from one another, so are the individual cells, and that is probably a better target for parallelisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_file(file): print(len(file['cells']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "2\n",
      "100\n",
      "48\n",
      "31\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for file in file_generator(): do_file(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
