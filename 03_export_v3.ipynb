{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from collections import namedtuple, defaultdict\n",
    "import os\n",
    "import re\n",
    "from nbdev_rewrite.imports import *\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "import ast\n",
    "from ast import iter_fields, AST\n",
    "import _ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_ERROR:bool   = True\n",
    "REPORT_WARNING:bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_error(err:Exception):\n",
    "    if REPORT_ERROR:\n",
    "        err_type = err.__class__.__name__\n",
    "        print(f'[{err_type}]: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_warning(warn:str):\n",
    "    if REPORT_WARNING: print(f'[Warning]: {warn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_argument(args:list, name:str, cursor:int, suppress_error:bool=False) -> (bool, int, str):\n",
    "    \"Gets the next argument from the list.\\nReturns success, the cursor, and the next argument\"\n",
    "    cursor_1 = cursor + 1\n",
    "    try: return True, cursor_1, args[cursor_1]\n",
    "    except IndexError:\n",
    "        if not suppress_error:\n",
    "            report_error(SyntaxError(f\"End of arguments reached. Missing a value for argument '{name}' at position {cursor_1}\"))\n",
    "        return False, cursor, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, 'c')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'b', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SyntaxError]: End of arguments reached. Missing a value for argument 'c' at position 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, 2, '')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'c', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 2, '')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'c', 2, suppress_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_integer(value:str) -> (bool, int, float):\n",
    "    \"Try converting a str to int.\\nReturn success, the value, and possibly a float remainder.\"\n",
    "    try:\n",
    "        f_value = float(value)\n",
    "        int_value = int(f_value)\n",
    "        remainder = f_value - int_value\n",
    "    except: return False, value, None\n",
    "    return True, int_value, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, -2, -0.10000000000000009), (False, 'nice', None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_integer('-2.1'), to_integer('nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(value:str) -> (bool, float):\n",
    "    \"Try converting a str to float.\\nReturn success, and the value.\"\n",
    "    # TODO: check if 'inf', 'nan', ...?\n",
    "    try   : return True , float(value)\n",
    "    except: return False, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, -0.001), (True, nan), (False, 'nice'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_float('-1e-3'), to_float('nan'), to_float('nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bool(value:str) -> (bool, bool):\n",
    "    \"\"\"Try converting a str to bool.\n",
    "    'True' and 'False' are recognized, otherwise the value is cast to float, and then to bool.\n",
    "    Return success, and the value.\"\"\"\n",
    "    if value == 'True' : return True, True\n",
    "    if value == 'False': return True, False\n",
    "    try   : return True , bool(float(value))\n",
    "    except: return False, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, True), (True, False), (True, True), (True, False), (False, 'abc'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_bool('1'), to_bool('0'), to_bool('True'), to_bool('False'), to_bool('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_unbounded_array(args:list, cursor:int) -> (bool, int, list):\n",
    "    \"\"\"Consume any number of values until either reaching the end of args,\n",
    "    or until finding a value starting with '-', denoting the beginning of a new argument.\n",
    "    Return success, the cursor, and the list of values.\n",
    "    Currently this can't actually fail... don't use unbounded lists kids.\"\"\"\n",
    "    values = []\n",
    "    while True:\n",
    "        string_success, cursor, value = get_next_argument(args, None, cursor, suppress_error=True)\n",
    "        if string_success:\n",
    "            if value[0] != '-': values.append(value)\n",
    "            else: # value starting with '-' means it's the next command\n",
    "                cursor -= 1\n",
    "                break\n",
    "        else: break\n",
    "    return True, cursor, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, ['1', '2'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_unbounded_array(['-list', '1', '2', '-3'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typify(type_or_value:object) -> (type, object):\n",
    "    \"\"\"Takes a type or a value.\n",
    "    Returns a tuple of the type (or type of the value) and value (or None)\"\"\"\n",
    "    return (type_or_value, None) if isinstance(type_or_value, type) else (type(type_or_value), type_or_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, (int, int, int, int))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typify((int, int)*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments(command:dict, comment:str) -> (bool, dict, dict):\n",
    "    \"Finds, casts, and returns values from command, in the given comment.\"    \n",
    "    members = command.keys()\n",
    "    result  = command.copy() # copy needed?\n",
    "    args    = comment.split()\n",
    "    # TODO: check that the type of all commands is supported ahead of time?\n",
    "    # TODO: handle quoted arguments?\n",
    "    \n",
    "    is_set = {member : False for member in members}\n",
    "    \n",
    "    state = {'args': args, 'name': '', 'cursor': 0,\n",
    "             'inside_array': False,}\n",
    "    \n",
    "    success = True\n",
    "    while state['cursor'] < len(args): # for arg in args:\n",
    "        arg = args[state['cursor']]\n",
    "        if arg[0] != '-':\n",
    "            report_error(SyntaxError(f\"Argument {state['cursor']} does not start with a '-'.\"))\n",
    "            return False, result, is_set\n",
    "        arg = arg[1:] # remove '-'\n",
    "        state['name'] = arg # TODO: check that len(arg) > 0?\n",
    "        \n",
    "        for key in members: # loop over keys of command (the things we're supposed to find)\n",
    "            if key != arg: continue    \n",
    "            if is_set[key]: # TODO: improve error msg. maybe: \"this is the second time this argument was given\"?\n",
    "                report_error(SyntaxError(f\"Argument {state['cursor']} ('{arg}') was given multiple times.\"))\n",
    "                success = False\n",
    "            else:\n",
    "                arg_type, arg_default = typify(command[key])\n",
    "                member_success = handle_one_argument(result, state, arg_type, arg_default)\n",
    "                if member_success: is_set[key] = True\n",
    "                else: success = False\n",
    "            break # once we have found the correct struct member, stop!\n",
    "        else: # TODO: improve this msg. maybe: \"is not part of the command\"?\n",
    "            report_error(SyntaxError(f\"Argument {state['cursor']} ('{arg}') is not valid.\"))\n",
    "            success = False\n",
    "        if not success: break # stop at first error\n",
    "        state['cursor'] += 1\n",
    "        \n",
    "    if success: success = check_is_set(result, is_set)\n",
    "    return success, result, is_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_one_argument(result:dict, state:dict, arg_type:type, arg_default:object) -> bool:\n",
    "    \"Parse the input args based on arg_type, and set arg_name in result to that value.\"\n",
    "    # NOTE: state and result are modified from here and essentially treated as pointers\n",
    "    args     = state['args']\n",
    "    arg_name = state['name']\n",
    "    success  = True\n",
    "    if arg_type == str:\n",
    "        # get the next argument, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        # TODO: how to handle strings that start with a '-'\n",
    "        if string_success: result[arg_name] = value\n",
    "        else: success = False\n",
    "\n",
    "    elif arg_type == bool:\n",
    "        if state['inside_array']:\n",
    "            string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "            if string_success:\n",
    "                bool_success, value = to_bool(value)\n",
    "                if bool_success: result[arg_name] = value\n",
    "                else:\n",
    "                    report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                    was not convertable to bool. Please use 'True', 'False', '0', or '1'. (It was '{value}')\"))\n",
    "                    success = False\n",
    "            else: success = False\n",
    "        # special case where supplying the argument means True and not supplying it means use the default (False)\n",
    "        else: result[arg_name] = True\n",
    "\n",
    "    elif arg_type == int:\n",
    "        # get the next argument, cast to int, check for remainder, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        if not string_success: return False\n",
    "        int_success, value, remainder = to_integer(value)\n",
    "        if int_success:\n",
    "            result[arg_name] = value\n",
    "            if remainder:\n",
    "                report_warning(f\"Junk on the end of the value for int argument \\\n",
    "                               {state['cursor']-1} ('{arg_name}'): {remainder}\")\n",
    "        else:\n",
    "            report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                                    was not an int. (It was '{value}')\"))\n",
    "            success = False\n",
    "\n",
    "    elif arg_type == float:\n",
    "        # get the next argument, cast to float, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        if not string_success: return False\n",
    "        float_success, value = to_float(value)\n",
    "        if float_success: result[arg_name] = value\n",
    "        else:\n",
    "            report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                                    was not a float. (It was '{value}')\"))\n",
    "            success = False\n",
    "\n",
    "    elif arg_type == list or arg_type == tuple:\n",
    "        if arg_default is None: # unbounded list / tuple\n",
    "            if state['inside_array']:\n",
    "                report_error(SyntaxError(f\"Using an unbounded list or tuple inside an array is not supported.\"))\n",
    "                return False\n",
    "            \n",
    "            array_success, state['cursor'], value = to_unbounded_array(args, state['cursor'])\n",
    "            if array_success: # NOTE: currently this can't actually fail... don't use unbounded lists kids.\n",
    "                result[arg_name] = arg_type(value)\n",
    "            else: success = False\n",
    "            \n",
    "        else: # predefined list\n",
    "            s = {'args': args, 'name': 'v', 'cursor': state['cursor'],\n",
    "                 'inside_array': True}\n",
    "            value = []\n",
    "            for i, x in enumerate(arg_default):\n",
    "                t, d = typify(x)\n",
    "                n = f'{arg_name}[{i}]'\n",
    "                s['name'] = n\n",
    "                r = {n:d}\n",
    "                member_success = handle_one_argument(r, s, t, d)\n",
    "                if member_success: value.append(r[n])\n",
    "                else: # TODO: Improve error message\n",
    "                    # report_error(SyntaxError(f\"Array argument {state['cursor']} ('{arg_name}') was not passed correctly.\"))\n",
    "                    return False\n",
    "            state['cursor'] = s['cursor']\n",
    "            result[arg_name] = arg_type(value)\n",
    "\n",
    "    else:\n",
    "        report_error(TypeError(f\"Argument {state['cursor']} ('{arg_name}') is of unsupported type {arg_type}.\"))\n",
    "        success = False\n",
    "        \n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_set(result:dict, is_set:dict) -> bool:\n",
    "    \"Check if any required (no default) values, haven't been set yet\"\n",
    "    success = True\n",
    "    for member, v_is_set in is_set.items():\n",
    "        if v_is_set: continue\n",
    "        arg_type, arg_default = typify(result[member])\n",
    "        if arg_default is None: \n",
    "            if arg_type == bool: # NOTE: Special case, not setting a boolean means it's False.\n",
    "                result[member] = False # TODO: set is_set as well? what's the use-case here?\n",
    "                continue\n",
    "            report_error(ValueError(f\"Argument '{member}' has not been set, and no default value was given.\"))\n",
    "            success = False\n",
    "        elif (arg_type == list) or (arg_type == tuple): # this is a bounded list\n",
    "            name = [f'{member}[{i}]' for i in range(len(arg_default))]\n",
    "            r = {n:x for n, x in zip(name, arg_default)}\n",
    "            s = {n:False for n in r}\n",
    "            is_set_success = check_is_set(r, s)\n",
    "            if is_set_success: # re-set result\n",
    "                result[member] = arg_type([r[n] for n in name])\n",
    "                continue\n",
    "            else: success = False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This argument parser is largely inspired by these two videos by Jonathan Blow.\n",
    ">[Part 1](https://youtu.be/TwqXTf7VfZk)  \n",
    ">[Part 2](https://youtu.be/pgiVrhsGkKY)\n",
    "\n",
    "pt.1 @ 3:12:50 complete code sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module besically provides only one function:  \n",
    "```python\n",
    "def parse_arguments(command:dict, comment:str) -> (bool, dict, dict)\n",
    "```  \n",
    "\n",
    "It takes one __\"command\" dictionary__, and a __\"comment\" string__.  \n",
    "\n",
    "#### __The command__\n",
    "\n",
    "is a simple key-value collection of expected flags, where a attribute name maps to either a type, or a default value, from which the type is infered.  \n",
    "```python\n",
    "command = {\n",
    "    'arg1':bool,\n",
    "    'arg2':str,\n",
    "    'arg3':32,\n",
    "    'arg4':3.14,\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The comment__\n",
    "is just a list of space-separated arguments, with words starting with a minus (`'-'`) denoting a keyword, and anything without a minus as the first character being a value to the previous keyword.  \n",
    "```python\n",
    "'-name bob -age 99 -celsius 30.5 -thirsty'\n",
    "```  \n",
    "is a valid string for the command  \n",
    "```python\n",
    "{\n",
    "    'name'   : str,\n",
    "    'weather': 'sunny',\n",
    "    'celsius': float,\n",
    "    'age'    : int,\n",
    "    'thirsty': bool,\n",
    "    'tired'  : bool\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The primitive types:__\n",
    "Currently the following primitive types are supported:  \n",
    "- `str`\n",
    "    - a `str` argument requires one value.\n",
    "    - e.g.: `-weather sunny`\n",
    "- `bool`\n",
    "    - a `bool` argument requires no values. setting the flag automatically sets the value to `True`.\n",
    "    - writing `bool` is the same as using the default value `False`.\n",
    "    - e.g.: `-is_wet`\n",
    "- `int`\n",
    "    - a `int` argument requires one value.\n",
    "    - the value will first be cast to `float`, and then to `int`, partly due to how python works, and also to check for a remainder in case the provided value was actually in a float format.\n",
    "    - e.g.: `-age 99`, `-negative -1`\n",
    "- `float`\n",
    "    - a `float` argument requires one value.\n",
    "    - the value has to be castable to `float`. what is and what isn't a float can be suprising, so you should check the [casting rules](https://stackoverflow.com/a/20929983/) beforehand.\n",
    "    - e.g.: `-pi 3.14`, `-negative -1.0`, `-weird nan`, `-large inf`, `-small -inf`\n",
    "  \n",
    "Any of these types can be declared either by just using the `type` directly, or by giving a default value of the specific `type`. All arguments that use the `type` directly have to be passed in the comment. If a default value is specified, or if the `type` is `bool`, the argument does not have to be passed in the comment, and instead the `result` will simply contain the default value. This changes with composite types (see below). If an argument was passed in the comment or not, can be seen by looking at the `is_set` return value (see below).\n",
    "\n",
    "  \n",
    "##### __The composite types__\n",
    "`list` and `tuple` (referred to as 'array' when it can be either one of them) are also supported, however due to pythons lack of strong typing, they have slightly different semantics.  \n",
    "\n",
    "Specifying only the type `list` or `tuple`, will result in an 'unbounded array' of that type, meaning that all values following the keyword will be added to the array, until either the end of arguments is reached, or a value starts with a minus (`'-'`), which denotes the start of the next argument. All values or the array will be of type `str`. This kind of argument should be used with caution (e.g. negative values).  \n",
    "```python\n",
    "{\n",
    "    'unbounded_list' : list,\n",
    "    'unbounded_tuple': tuple,\n",
    "}\n",
    "```  \n",
    "\n",
    "The other, better way to use arrays is to actually create an array containing the types, default values, and ordering you want the values to have. This can get arbitrarily complex, mixing and matching any supported primitive type you want. The only thing not allowed, is using an unbounded array (see above).  \n",
    "All values will be cast to the corresponding type using all the same semantics as of they were single values (see above). The only exception to that is the `bool` type, where the value has to be either `'True'`, `'False'`, or interpretable as a `float`, which will then be cast to a `bool`. This means that e.g. `'0.0'` will result in `False`, and `'123'` will result in `'True'` (careful, check the [casting rules](https://docs.python.org/3.3/library/stdtypes.html?highlight=frozenset#truth-value-testing) first).\n",
    "```python\n",
    "{\n",
    "    'arg1': [int]*5,\n",
    "    'arg2': (3.14, 'pi', bool),\n",
    "    'arg3': (bool, str, 123)*2,\n",
    "    'arg4': [[0]*3, [1]*3, [str]*3],\n",
    "    'arg5': [str, int, bool, True, [1, '2', 3, bool], (2.1, float)]\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The return value__\n",
    "is a three-tuple of `(success, result, is_set)`.  \n",
    "- `success` is a `bool`, saying whether or not parsing was successful. If it is `False`, the other two arguments are not guarenteed to be valid. There will be an error message with details on what happened to help debugging.  \n",
    "- `result` is a `dict` with exactly the same keys as the input `command`, with the corresponding values set to whatever was extracted from the comment. In cases where `success` if `False`, this might only be partially filled out, so `success` should always be checked.\n",
    "- `is_set` is a `dict`, which also contains exactly the same keys as the input `command`, this time mapping to a `bool`, which is `True` if `comment` contains a value for the particular argument, and `False` otherwise. In cases where a default value is given in `command`, the same rule applies. Meaning that only if the default was overwritten by an argument in `comment` will the `is_set` value be `True`. This holds even for `bool`s, which default to `False` if no default was given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use-case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command(arg1:bool, arg2:str, arg2:bool=False)\n",
    "\n",
    "command = {\n",
    "    'arg1':bool,\n",
    "    'arg2':str,\n",
    "    'arg3':int,\n",
    "}\n",
    "\n",
    "+command\n",
    "    -boolean_argument\n",
    "    -string_arg value\n",
    "    -castable_arg value\n",
    "    -array_arg string_arg1 string_arg2 string_arg3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# +default_export -to export_file_v3.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# +export -internal -to export_file.py -show_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'test': True,\n",
       "  'sunny': True,\n",
       "  'toast': 'jelly',\n",
       "  'shots': 25,\n",
       "  'scale': 69105.1234,\n",
       "  'scoops': ['a', 1, False, [5, 6, 7, False], (3.0, 2.1)],\n",
       "  'valid': (1, 1.23, False, 'hi', [1, 2]),\n",
       "  'nah': 'boi',\n",
       "  'sweet': False,\n",
       "  'nr': 21,\n",
       "  'list': ['2']},\n",
       " {'test': True,\n",
       "  'sunny': True,\n",
       "  'toast': True,\n",
       "  'shots': True,\n",
       "  'scale': True,\n",
       "  'scoops': True,\n",
       "  'valid': False,\n",
       "  'nah': False,\n",
       "  'sweet': False,\n",
       "  'nr': True,\n",
       "  'list': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = {\n",
    "    'test'  : bool,\n",
    "    'sunny' : False,\n",
    "    'toast' : str,\n",
    "    'shots' : int,\n",
    "    'scale' : float,\n",
    "    'scoops': [str, int, bool, [1, 2, 3, bool], (float, float)],\n",
    "    # 'valid' : (bool, bool),\n",
    "    'valid' : (1, 1.23, bool, 'hi', [1, 2]),\n",
    "    'nah'   : 'boi',\n",
    "    'sweet' : bool,\n",
    "    'nr'    : int,\n",
    "    'list'  : list\n",
    "}\n",
    "\n",
    "comment = '-sunny -toast jelly -shots 25 -scale 69105.1234 -test -list 2 -scoops a 1 0 5 6 7 False 3.0 2.1 -nr 21'\n",
    "# comment = '-sunny -toast jelly -shots 25 -scale 69105.1234 -test -nr 1'\n",
    "parse_arguments(command, comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 µs ± 89.8 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit parse_arguments(command, comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_default_exp = {'scope': 'file' , 'to': str}\n",
    "kw_export      = {'internal': bool, 'to': ''}\n",
    "\n",
    "all_commands   = {'default_exp': kw_default_exp, 'export': kw_export}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, {'internal': True, 'to': 'file.py'}, {'internal': True, 'to': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_arguments(all_commands['export'], '-internal -to file.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_comment = re.compile(r\"\"\"\n",
    "        ^              # start of line\n",
    "        \\s?            # 0 or 1 whitespace\n",
    "        \\#+\\s?         # 1 or more literal \"#\", then 0 or 1 whitespace\n",
    "        (.*)           # group of arbitrary symbols (except new line)\n",
    "        $              # end of line\n",
    "        \"\"\",re.IGNORECASE | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='# hi'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_comment.search('# hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_comment(all_commands:dict, comment:str) -> (bool, str, dict, dict):\n",
    "    \"Finds command names and arguments in comments and parses them with parse_arguments()\"\n",
    "    res = re_match_comment.search(comment)\n",
    "    if not res:\n",
    "        report_error(SyntaxError('Not a valid comment syntax.'))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    all_args = res.groups()[0].split()\n",
    "    if len(all_args) == 0:\n",
    "        report_error(SyntaxError(f\"Need at least one argument in comment. Reveived: '{comment}'\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    cmd, *args = all_args\n",
    "    if cmd[0] != '+':\n",
    "        report_error(SyntaxError(f\"The first argument (the command to execute) does not start with a '+'. It was: '{cmd}'\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    cmd = cmd[1:] # remove '+'\n",
    "    if cmd not in all_commands:\n",
    "        report_error(KeyError(f\"'{cmd}' is not a recognized command. Available: {list(all_commands.keys())}\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    success, result, is_set = parse_arguments(all_commands[cmd], ' '.join(args))\n",
    "    if not success: return False, None, None, None\n",
    "    \n",
    "    return True, cmd, result, is_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 'export',\n",
       " {'internal': True, 'to': 'file.py'},\n",
       " {'internal': True, 'to': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_comment(all_commands, '# +export -internal -to file.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find / Iter comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(florian): Only look for 0 indent comments?\n",
    "def iter_comments(cell_nr:int, src:str, pure_comments_only:bool=True, line_limit=None):\n",
    "    \"Detect all comments in a piece of code, excluding those that are a part of a string.\"\n",
    "    in_lstr = in_sstr = False\n",
    "    count, quote = 1, ''\n",
    "    for i, line in enumerate(src.splitlines()[:line_limit]):\n",
    "        is_pure, escape, prev_c = True, False, '\\n'\n",
    "        for j, c in enumerate(line):\n",
    "            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns\n",
    "            if is_pure and (not (c.isspace() or c == '#')): is_pure = False\n",
    "            if (in_sstr or in_lstr):\n",
    "                # assert (in_sstr and not in_lstr) or (in_lstr and not in_sstr)\n",
    "                if escape: count = 0\n",
    "                else:\n",
    "                    if (c == quote):\n",
    "                        count = ((count + 1) if (c == prev_c) else 1)\n",
    "                        if in_sstr: in_sstr = False\n",
    "                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False\n",
    "                escape = False if escape else (c == '\\\\')\n",
    "            else:                    \n",
    "                if (c == '#'):\n",
    "                    if (pure_comments_only and is_pure): yield (line, (i, j))\n",
    "                    elif (not pure_comments_only):       yield (line[j:], (i, j))\n",
    "                    break\n",
    "                elif c == \"'\" or c == '\"':\n",
    "                    count = ((count + 1) if (c == prev_c) else 1)\n",
    "                    if count == 1: in_sstr = True\n",
    "                    elif count == 3: count, in_lstr = 0, True\n",
    "                    else: raise SyntaxError(f'Unexpected quote repetition count: {count} Should be either 1 or 3. Cell_nr: {cell_nr} Line:{i}/{j}')\n",
    "                    quote = c\n",
    "            prev_c = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The normal stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_config(lib_name='nbdev_rewrite', user='flpeters', nbs_path='.'):\n",
    "    \"create a config file, if it doesn't already exist\"\n",
    "    if not Config().config_file.exists(): create_config(lib_name, user, nbs_path=nbs_path)\n",
    "init_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lib():\n",
    "    \"initialize the module folder, if it's not initialized already\"\n",
    "    C = Config()\n",
    "    if (not C.lib_path.exists()) or (not (C.lib_path/'__init__.py').exists()):\n",
    "        C.lib_path.mkdir(parents=True, exist_ok=True)\n",
    "        with (C.lib_path/'__init__.py').open('w') as f:\n",
    "            f.write(f'__version__ = \"{C.version}\"\\n')\n",
    "    else: pass # module *should* already exists\n",
    "init_lib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/Projects/GitHub/nbdev_rewrite/00_export.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/01_helpers.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/02_export_v2.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/03_export_v3.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/99_index.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/sub/lalalala.ipynb')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_reserved_dirs = (Config().lib_path, Config().nbs_path, Config().doc_path)\n",
    "def crawl_nbs(path:Path=None, recurse:bool=True) -> list:\n",
    "    \"finds a list of ipynb files to convert\"\n",
    "    if path is None: path = Config().nbs_path\n",
    "    if isinstance(path, (list, tuple)):\n",
    "        for p in path: yield from crawl_nbs(p, recurse)\n",
    "    elif path.is_file(): yield path\n",
    "    else:\n",
    "        for p in path.iterdir():\n",
    "            f = p.name\n",
    "            if f.startswith('.') or f.startswith('_'): continue\n",
    "            if p.is_file():\n",
    "                if f.endswith('.ipynb'): yield p\n",
    "                else: continue\n",
    "            elif p.is_dir() and recurse:\n",
    "                if p in _reserved_dirs: continue\n",
    "                else: yield from crawl_nbs(p, recurse)\n",
    "            else: continue\n",
    "list(crawl_nbs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_nb(fname:Path) -> nbformat.notebooknode.NotebookNode:\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return nbformat.reads(f.read(), as_version=4)\n",
    "len(read_nb('03_export_v3.ipynb')['cells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test\\\\abc'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def module2path(module:str) -> str:\n",
    "    \"replaces the python module '.' seperator with os specific path seperator\"\n",
    "    return os.path.sep.join(module.split('.'))\n",
    "module2path('test.abc')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: add support for a scoped #default_exp. Support exporting cells under a specific heading to a seperate file.\n",
    "setting #default_exp on a per-heading / per-scope level, not on a once per file level."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: # file-documentation tag, for writing a doc string for an entire file, or for an entire module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _notebook2script(fname, silent=False):\n",
    "    fname = Path(fname)\n",
    "    print(fname.name)\n",
    "    nb = read_nb(fname)\n",
    "    cells = nb['cells']\n",
    "    C = Config()\n",
    "    sep = '\\n' * (max(int(C.get('cell_spacing', 1)), 0) + 1)\n",
    "    for cell in cells:\n",
    "        # scan for\n",
    "        # default_exp\n",
    "        # export\n",
    "        # hide\n",
    "        # put all the stuff in datastructure, which should be thread safe\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_export.ipynb\n",
      "01_helpers.ipynb\n",
      "02_export_v2.ipynb\n",
      "03_export_v3.ipynb\n",
      "99_index.ipynb\n",
      "lalalala.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def notebook2script(fname=None, silent=False, to_dict=False):\n",
    "    # init target module directory\n",
    "    init_lib()\n",
    "    files = crawl_nbs(fname)\n",
    "    exports = []\n",
    "    for file in files:\n",
    "        exports.append(_notebook2script(file, silent))\n",
    "    # merge_exports(exports)\n",
    "    # if fname is a file, convert only that file, if possible.\n",
    "    # if its None, use Config() directory\n",
    "    # if its a directory,\n",
    "        # crawl source directory recursively to find all files that should be converted\n",
    "    # create thread/process pool for processing all files in parallel\n",
    "    # execute compilation on each of the files, resulting in a dataformat representing the converted file.\n",
    "    # merge all files, based on cross-exporting stored in dataformat\n",
    "    # TODO: handle cross-exporting if the targeted file already exists, but wasn't compiled from scratch\n",
    "    # probably should force a recompile of that file as well\n",
    "    # write files to disk\n",
    "    return exports\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefetcher [working]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import BackgroundGenerator, prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@prefetch(max_prefetch=4)\n",
    "def file_generator():\n",
    "    for f in crawl_nbs(): yield read_nb(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "2\n",
      "100\n",
      "104\n",
      "31\n",
      "2\n",
      "0.023999\n"
     ]
    }
   ],
   "source": [
    "tt = 0\n",
    "t0 = time.time()\n",
    "for x in file_generator():\n",
    "    t1 = time.time()\n",
    "    tt += t1 - t0\n",
    "    time.sleep(.5) # work\n",
    "    print(len(x['cells']))\n",
    "    t0 = time.time()\n",
    "print(round(tt, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hello\n",
      "Hi\n",
      "Hi\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "import time\n",
    "  \n",
    "def print_hello():\n",
    "    for i in range(4):\n",
    "        time.sleep(0.5)\n",
    "        print(\"Hello\")\n",
    "        \n",
    "def print_hi(): \n",
    "    for i in range(4): \n",
    "        time.sleep(0.7)\n",
    "        print(\"Hi\") \n",
    "\n",
    "t1 = threading.Thread(target=print_hello)  \n",
    "t2 = threading.Thread(target=print_hi)  \n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for multiprocessing to work, the function thats supposed to be executed, has to be importable aka in a .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan for comments in all cells\n",
    "# check for `export`, `hide`, and `meta` comments\n",
    "# if any `meta`:\n",
    "#     execute `meta`\n",
    "#     if control inversion:\n",
    "#         pass for now\n",
    "#     check for potential new comments due to `meta` execution\n",
    "# parse or discard all remaining comments\n",
    "# execute commands\n",
    "# aggregate results back in main process\n",
    "# return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(x): return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = ProcessPoolExecutor(max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent.futures.ProcessPoolExecutor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "2\n",
      "100\n",
      "28\n",
      "31\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for file in file_generator():\n",
    "    print(len(file['cells']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor(max_workers=4) as pool:\n",
    "    print(list(pool.map(f, range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # start 4 worker processes\n",
    "    with Pool(processes=4) as pool:\n",
    "\n",
    "        # print \"[0, 1, 4,..., 81]\"\n",
    "        print(pool.map(f, range(10)))\n",
    "\n",
    "        # print same numbers in arbitrary order\n",
    "        for i in pool.imap_unordered(f, range(10)):\n",
    "            print(i)\n",
    "\n",
    "        # evaluate \"f(10)\" asynchronously\n",
    "        res = pool.apply_async(f, [10])\n",
    "        print(res.get(timeout=1))             # prints \"100\"\n",
    "\n",
    "        # make worker sleep for 10 secs\n",
    "        # res = pool.apply_async(sleep, [10])\n",
    "        # print(res.get(timeout=1))             # raises multiprocessing.TimeoutError\n",
    "\n",
    "    # exiting the 'with'-block has stopped the pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coroutines and generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From generator 1\n",
      "From user 2\n",
      "From generator 1\n",
      "From user 3\n",
      "From generator 1\n",
      "From user 4\n",
      "From generator 1\n",
      "From user 5\n",
      "From generator 1\n",
      "From user 6\n",
      "From generator 1\n",
      "From user 7\n",
      "From generator 1\n",
      "From user 8\n",
      "From generator 1\n",
      "From user 9\n",
      "From generator 1\n"
     ]
    }
   ],
   "source": [
    "def coroutine():\n",
    "    for i in range(1, 10): print(f'From generator {yield i}')\n",
    "c = coroutine()\n",
    "c.send(None)\n",
    "try:\n",
    "    while True: print(f'From user {c.send(1)}')\n",
    "except StopIteration: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# Unaffected by send\n",
    "def double_number(number):\n",
    "    while True:\n",
    "        number *=2 \n",
    "        yield number\n",
    "\n",
    "c = double_number(4)\n",
    "print(c.send(None))\n",
    "print(next(c))\n",
    "print(next(c))\n",
    "print(c.send(8))\n",
    "print(c.send(8))\n",
    "print(c.send(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "10\n",
      "3000\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Works with send\n",
    "def double_number(number):\n",
    "    while True:\n",
    "        number *= 2\n",
    "        number = yield number\n",
    "        \n",
    "c = double_number(4)\n",
    "print(c.send(None))\n",
    "print(c.send(5)) #10\n",
    "print(c.send(1500)) #3000\n",
    "print(c.send(3)) #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "20\n",
      "None\n",
      "12\n",
      "None\n",
      "188.6\n"
     ]
    }
   ],
   "source": [
    "def double_inputs():\n",
    "    while True:\n",
    "        x = yield\n",
    "        yield x * 2\n",
    "\n",
    "gen = double_inputs()\n",
    "print(next(gen))       # run up to the first yield\n",
    "print(gen.send(10))    # goes into 'x' variable\n",
    "\n",
    "print(next(gen))       # run up to the next yield\n",
    "print(gen.send(6))     # goes into 'x' again\n",
    "\n",
    "print(next(gen))       # run up to the next yield\n",
    "print(gen.send(94.3))  # goes into 'x' again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @defer.inlineCallbacks\n",
    "# def doStuff():\n",
    "#     result = yield takesTwoSeconds()\n",
    "#     nextResult = yield takesTenSeconds(result * 10)\n",
    "#     defer.returnValue(nextResult / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def doStuff():\n",
    "#     returnDeferred = defer.Deferred()\n",
    "#     def gotNextResult(nextResult):\n",
    "#         returnDeferred.callback(nextResult / 10)\n",
    "#     def gotResult(result):\n",
    "#         takesTenSeconds(result * 10).addCallback(gotNextResult)\n",
    "#     takesTwoSeconds().addCallback(gotResult)\n",
    "#     return returnDeferred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multithreading, multiprocessing and generators"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "global settings:\n",
    "- seperation amount (vertical whitespace) between cells\n",
    "- how to look for comments\n",
    "- command syntax\n",
    "- \n",
    "\n",
    "all cell data:  \n",
    "- meta cells\n",
    "- default export target\n",
    "- file name\n",
    "\n",
    "per cell data:  \n",
    "- source code\n",
    "- variable, function and class names\n",
    "- export yes/no\n",
    "- internal (export names) yes/no\n",
    "- cell number / order\n",
    "\n",
    "Things that need to be aggregated before return:\n",
    "- union of all names\n",
    "- ordered list of source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell:\n",
    "    def __init__(self, cell_nr:int, cell:dict):\n",
    "        # cell data\n",
    "        self.cell_nr     = cell_nr\n",
    "        self.source_code = cell['source']\n",
    "        self.cell_type   = cell['cell_type']\n",
    "        # cell state\n",
    "        self.names , self._comments = set(), None\n",
    "        self.internal  = False\n",
    "        \n",
    "    def __repr__(self): return f'{self.cell_nr}, {self.cell_type}:\\n{self.source_code}\\n\\n'\n",
    "        \n",
    "    def _cache_iter_comments(self): # TODO: is this even needed?\n",
    "        \"cache the result of iter_comments for faster repeated access\"\n",
    "        agg = []\n",
    "        # NOTICE: if pure_comments_only is False, then comment removal will also have to change.\n",
    "        for x in iter_comments(self.cell_nr, self.source_code, pure_comments_only=True):\n",
    "            agg.append(x)\n",
    "            yield x\n",
    "        self._comments = agg\n",
    "        \n",
    "        # TODO: what if this is called during iteration?\n",
    "        # -> cache invalidation doesnt work during iter, bacause the cache is only set at the end of iter.\n",
    "        # -> iter_comments continues to work, because strings are immutable and it has it's own copy of the source.\n",
    "        # -> this should really store all the line to be removed, and only do it once it's safe.\n",
    "    def remove_comment(self, loc_line:int, loc_char:int=None) -> str:\n",
    "        \"pass loc_char to only remove part of the line and keep the rest\"\n",
    "        lines = self.source_code.splitlines()\n",
    "        if (loc_char is None): lines.pop(loc_line) # (loc_char is None) or (loc_char <= 1) ?\n",
    "        else: lines[loc_line] = lines[loc_line][:loc_char]\n",
    "        self._comments = None # invalidate cached comments\n",
    "        self.source_code = '\\n'.join(lines)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self._comments is None: return self._cache_iter_comments() # TODO: is this even needed?\n",
    "        else:                      return iter(self._comments)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "default_export -> default file | None\n",
    "\n",
    "cell X export -to cell_X -> cell_X file\n",
    "cell Y export -to cell_X -> cell_X file\n",
    "cell Z export -> default file\n",
    "\n",
    "scope A default_export -> scope_A file\n",
    "    cell A_Y export -to cell_X -> cell_X file\n",
    "    cell A_Z export -> scope_A file\n",
    "\n",
    "scope B default_export -> scope_B file\n",
    "    cell B_Z export -> scope_B file\n",
    "    \n",
    "cell K export -> default file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        self.before, self.normal, self.after = [], [], []\n",
    "    def __repr__(self): return f'File Name: {self.fname}\\n{self.before+self.normal+self.after}'\n",
    "    def prepend(self, cell): self.before.append(cell)\n",
    "    def add    (self, cell): self.normal.append(cell)\n",
    "    def append (self, cell): self.after .append(cell)\n",
    "    def export(self): raise NotImplementedError()\n",
    "    def __len__(self): return (len(self.before) + len(self.normal) + len(self.after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name: None\n",
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "File(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileDict():\n",
    "    def __init__(self): self.d = {}  \n",
    "    def __repr__(self): return self.d.__repr__()\n",
    "    def __getitem__(self, name):\n",
    "        if name in self.d: return self.d[name]\n",
    "        else:\n",
    "            f = File(name)\n",
    "            self.d[name] = f\n",
    "            return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None: File Name: None\n",
       "[]\n",
       "[1]\n",
       "[]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = FileDict()\n",
    "X[None].add(1); X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    def __init__(self, nb):\n",
    "        # notebook data\n",
    "        self.nb_version = (nb['nbformat'], nb['nbformat_minor'])\n",
    "        self.metadata = nb['metadata']\n",
    "        self.cells = [Cell(cell_nr, cell) for cell_nr, cell in enumerate(nb['cells'])]\n",
    "        # notebook state\n",
    "        self.scopes = {'file': None} # TODO: This is work in progress\n",
    "        self.files = FileDict()\n",
    "        \n",
    "    def __repr__(self): return self.cells.__repr__()\n",
    "    \n",
    "    def process_cmd(self, cell, cmd, result, is_set):\n",
    "        if cmd == 'export':\n",
    "            if result['internal']: cell.internal = True\n",
    "            if is_set['to']: self.files[result['to']].add(cell)\n",
    "            else:            self.files[None        ].add(cell)\n",
    "\n",
    "        elif cmd == 'default_exp':\n",
    "            assert is_set['to']\n",
    "            if is_set['scope']: # TODO: This is work in progress and is neither safe nor done atm\n",
    "                self.files[result['to']]\n",
    "                self.scopes[result['scope']] = result['to']\n",
    "            else:\n",
    "                default_file = self.files[None]\n",
    "                if default_file.fname is None: default_file.fname = result['to']\n",
    "                else:\n",
    "                    raise Exception(f\"Setting default export multiple times is not allowed. (was: '{default_file.fname}', new: '{fname}')\")\n",
    "\n",
    "        else: raise NotImplementedError(f\"The command '{cmd}' is missing a corresponding action.\")\n",
    "    \n",
    "    def process_stage_1(self):\n",
    "        \"parse comments and move cells into a struct for further processing based on options set in the comments\"\n",
    "        for cell in self.cells:\n",
    "            if cell.cell_type != 'code': continue\n",
    "            cell_nr = cell.cell_nr\n",
    "            for comment, (line_nr, char_nr) in cell:\n",
    "                success, cmd, result, is_set = parse_comment(all_commands, comment)\n",
    "                if not success: continue\n",
    "                # TODO: This is for debugging only. remove later!\n",
    "                print(f'Found: {cmd} @ ({cell_nr}, {line_nr}, {char_nr}) with args: {result}')\n",
    "                \n",
    "                self.process_cmd(cell, cmd, result, is_set)\n",
    "                cell.remove_comment(line_nr) # NOTICE: care whether char_nr is passed or not\n",
    "                \n",
    "        if (self.files[None].fname is None) and (len(self.files[None]) > 0):\n",
    "            raise Exception(f\"No default export target has been set, but there are cells without a target.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default_exp': {'scope': 'file', 'to': str},\n",
       " 'export': {'internal': bool, 'to': ''}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_ERROR:bool   = False\n",
    "REPORT_WARNING:bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = Notebook(read_nb('03_export_v3.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: default_exp @ (104, 0, 0) with args: {'scope': 'file', 'to': 'et_is_real.py'}\n",
      "Found: export @ (104, 1, 0) with args: {'internal': False, 'to': ''}\n",
      "Found: export @ (105, 0, 0) with args: {'internal': True, 'to': ''}\n",
      "Found: export @ (106, 0, 0) with args: {'internal': False, 'to': ''}\n",
      "Found: export @ (107, 0, 0) with args: {'internal': False, 'to': 'abc_test.py'}\n"
     ]
    }
   ],
   "source": [
    "test_nb.process_stage_1()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is an error. TODO: fix cell.remove_comment !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# +export'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb.files[None].normal[0].source_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb.process_stage_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96, 97]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb.default_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +default_exp -to et_is_real.py\n",
    "# +export\n",
    "\"This is a tricky case\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "2+2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "1+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -to abc_test.py\n",
    "3+3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### per file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Needs a non-parallel, and a parallel path.\n",
    "To bootstrap the compiler, multiprocessing can't be used, because of the interactive nature of notebooks.\n",
    "Once the code is exported to a .py file, multiprocessing should be possible, but also optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_file(file):\n",
    "    processes = []\n",
    "    for chunk in chunkify(file['cells']):\n",
    "        processes.append(partial_cells(chunk))\n",
    "    dist_data = {}\n",
    "    for p in processes:\n",
    "        dist_data.set_data(p.get_dist())\n",
    "    for p in processes: p.push_dist(dist_data)\n",
    "    return [p.complete() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in cells:\n",
    "    cell = Cell(cell)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### per run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Files are loaded into memory by a background thread and are then yielded to us from the generator.\n",
    "Per file parallelism is possible, but might not be best idea, because while files are mostly independent from one another, so are the individual cells, and that is probably a better target for parallelisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_file(file): print(len(file['cells']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "2\n",
      "100\n",
      "48\n",
      "31\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for file in file_generator(): do_file(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
