{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from collections import namedtuple, defaultdict\n",
    "import os\n",
    "import re\n",
    "from nbdev_rewrite.imports import *\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "import ast\n",
    "from ast import iter_fields, AST\n",
    "import _ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The normal stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_config(lib_name='nbdev_rewrite', user='flpeters', nbs_path='.'):\n",
    "    \"create a config file, if it doesn't already exist\"\n",
    "    if not Config().config_file.exists(): create_config(lib_name, user, nbs_path=nbs_path)\n",
    "init_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lib():\n",
    "    \"initialize the module folder, if it's not initialized already\"\n",
    "    C = Config()\n",
    "    if (not C.lib_path.exists()) or (not (C.lib_path/'__init__.py').exists()):\n",
    "        C.lib_path.mkdir(parents=True, exist_ok=True)\n",
    "        with (C.lib_path/'__init__.py').open('w') as f:\n",
    "            f.write(f'__version__ = \"{C.version}\"\\n')\n",
    "    else: pass # module *should* already exists\n",
    "init_lib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/Projects/GitHub/nbdev_rewrite/00_export.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/01_helpers.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/02_export_v2.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/03_export_v3.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/99_index.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/sub/lalalala.ipynb')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_reserved_dirs = (Config().lib_path, Config().nbs_path, Config().doc_path)\n",
    "def crawl_nbs(path:Path=None, recurse:bool=True) -> list:\n",
    "    \"finds a list of ipynb files to convert\"\n",
    "    if path is None: path = Config().nbs_path\n",
    "    files = []\n",
    "    if isinstance(path, (list, tuple)):\n",
    "        for p in path: files.extend(crawl_nbs(p))\n",
    "    elif path.is_file(): return [path]\n",
    "    else:\n",
    "        for p in path.iterdir():\n",
    "            f = p.name\n",
    "            if f.startswith('.') or f.startswith('_'): continue\n",
    "            if p.is_file():\n",
    "                if f.endswith('.ipynb'): files.append(p)\n",
    "                else: continue\n",
    "            elif p.is_dir() and recurse:\n",
    "                if p in _reserved_dirs: continue\n",
    "                else: files.extend(crawl_nbs(p))\n",
    "            else: pass\n",
    "    return files\n",
    "crawl_nbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_nb(fname:Path) -> nbformat.notebooknode.NotebookNode:\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return nbformat.reads(f.read(), as_version=4)\n",
    "len(read_nb('03_export_v3.ipynb')['cells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test\\\\abc'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def module2path(module:str) -> str:\n",
    "    \"replaces the python module '.' seperator with os specific path seperator\"\n",
    "    return os.path.sep.join(module.split('.'))\n",
    "module2path('test.abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _notebook2script(fname, silent=False):\n",
    "    fname = Path(fname)\n",
    "    print(fname.name)\n",
    "    nb = read_nb(fname)\n",
    "    cells = nb['cells']\n",
    "    C = Config()\n",
    "    sep = '\\n' * (max(int(C.get('cell_spacing', 1)), 0) + 1)\n",
    "    for cell in cells:\n",
    "        # scan for\n",
    "        # default_exp\n",
    "        # export\n",
    "        # hide\n",
    "        # put all the stuff in datastructure, which should be thread safe\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_export.ipynb\n",
      "01_helpers.ipynb\n",
      "02_export_v2.ipynb\n",
      "03_export_v3.ipynb\n",
      "99_index.ipynb\n",
      "lalalala.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def notebook2script(fname=None, silent=False, to_dict=False):\n",
    "    # init target module directory\n",
    "    init_lib()\n",
    "    files = crawl_nbs(fname)\n",
    "    exports = []\n",
    "    for file in files:\n",
    "        exports.append(_notebook2script(file, silent))\n",
    "    # merge_exports(exports)\n",
    "    # if fname is a file, convert only that file, if possible.\n",
    "    # if its None, use Config() directory\n",
    "    # if its a directory,\n",
    "        # crawl source directory recursively to find all files that should be converted\n",
    "    # create thread/process pool for processing all files in parallel\n",
    "    # execute compilation on each of the files, resulting in a dataformat representing the converted file.\n",
    "    # merge all files, based on cross-exporting stored in dataformat\n",
    "    # TODO: handle cross-exporting if the targeted file already exists, but wasn't compiled from scratch\n",
    "    # probably should force a recompile of that file as well\n",
    "    # write files to disk\n",
    "    return exports\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefetcher [working]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import BackgroundGenerator, prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@prefetch(max_prefetch=4)\n",
    "def file_generator():\n",
    "    for f in crawl_nbs(): yield read_nb(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "2\n",
      "100\n",
      "24\n",
      "31\n",
      "2\n",
      "0.022999\n"
     ]
    }
   ],
   "source": [
    "tt = 0\n",
    "t0 = time.time()\n",
    "for x in file_generator():\n",
    "    t1 = time.time()\n",
    "    tt += t1 - t0\n",
    "    time.sleep(.5) # work\n",
    "    print(len(x['cells']))\n",
    "    t0 = time.time()\n",
    "print(round(tt, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hello\n",
      "Hi\n",
      "Hi\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "import time\n",
    "  \n",
    "def print_hello():\n",
    "    for i in range(4):\n",
    "        time.sleep(0.5)\n",
    "        print(\"Hello\")\n",
    "        \n",
    "def print_hi(): \n",
    "    for i in range(4): \n",
    "        time.sleep(0.7)\n",
    "        print(\"Hi\") \n",
    "\n",
    "t1 = threading.Thread(target=print_hello)  \n",
    "t2 = threading.Thread(target=print_hi)  \n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for multiprocessing to work, the function thats supposed to be executed, has to be importable aka in a .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan for comments in all cells\n",
    "# check for `export`, `hide`, and `meta` comments\n",
    "# if any `meta`:\n",
    "#     execute `meta`\n",
    "#     if control inversion:\n",
    "#         pass for now\n",
    "#     check for potential new comments due to `meta` execution\n",
    "# parse or discard all remaining comments\n",
    "# execute commands\n",
    "# aggregate results back in main process\n",
    "# return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(x): return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = ProcessPoolExecutor(max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ProcessPoolExecutor' object has no attribute 'super'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-04bd70163727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ProcessPoolExecutor' object has no attribute 'super'"
     ]
    }
   ],
   "source": [
    "pool.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor(max_workers=4) as pool:\n",
    "    print(list(pool.map(f, range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # start 4 worker processes\n",
    "    with Pool(processes=4) as pool:\n",
    "\n",
    "        # print \"[0, 1, 4,..., 81]\"\n",
    "        print(pool.map(f, range(10)))\n",
    "\n",
    "        # print same numbers in arbitrary order\n",
    "        for i in pool.imap_unordered(f, range(10)):\n",
    "            print(i)\n",
    "\n",
    "        # evaluate \"f(10)\" asynchronously\n",
    "        res = pool.apply_async(f, [10])\n",
    "        print(res.get(timeout=1))             # prints \"100\"\n",
    "\n",
    "        # make worker sleep for 10 secs\n",
    "        # res = pool.apply_async(sleep, [10])\n",
    "        # print(res.get(timeout=1))             # raises multiprocessing.TimeoutError\n",
    "\n",
    "    # exiting the 'with'-block has stopped the pool"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
