{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parsing [Module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_ERROR:bool   = True\n",
    "REPORT_WARNING:bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_error(err:Exception):\n",
    "    if REPORT_ERROR:\n",
    "        err_type = err.__class__.__name__\n",
    "        print(f'[{err_type}]: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_warning(warn:str):\n",
    "    if REPORT_WARNING: print(f'[Warning]: {warn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a fancy way of advancing the cursor and checking for out of bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_argument(args:list, name:str, cursor:int, suppress_error:bool=False) -> (bool, int, str):\n",
    "    \"Gets the next argument from the list.\\nReturns success, the cursor, and the next argument\"\n",
    "    cursor_1 = cursor + 1\n",
    "    try: return True, cursor_1, args[cursor_1]\n",
    "    except IndexError:\n",
    "        if not suppress_error:\n",
    "            report_error(SyntaxError(f\"End of arguments reached. Missing a value for argument '{name}' at position {cursor_1}\"))\n",
    "        return False, cursor, ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, 'c')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'b', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SyntaxError]: End of arguments reached. Missing a value for argument 'c' at position 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, 2, '')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'c', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 2, '')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'c', 2, suppress_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to Argument Parsing is just a string, so values have to be converted based on the information provided by the caller.  These function help to do that in a safe way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_integer(value:str) -> (bool, int, float):\n",
    "    \"Try converting a str to int.\\nReturn success, the value, and possibly a float remainder.\"\n",
    "    try:\n",
    "        f_value = float(value)\n",
    "        int_value = int(f_value)\n",
    "        remainder = f_value - int_value\n",
    "    except: return False, value, None\n",
    "    return True, int_value, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, -2, -0.10000000000000009), (False, 'nice', None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_integer('-2.1'), to_integer('nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(value:str) -> (bool, float):\n",
    "    \"Try converting a str to float.\\nReturn success, and the value.\"\n",
    "    # TODO: check if 'inf', 'nan', ...?\n",
    "    try   : return True , float(value)\n",
    "    except: return False, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, -0.001), (True, nan), (False, 'nice'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_float('-1e-3'), to_float('nan'), to_float('nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bool(value:str) -> (bool, bool):\n",
    "    \"\"\"Try converting a str to bool.\n",
    "    'True' and 'False' are recognized, otherwise the value is cast to float, and then to bool.\n",
    "    Return success, and the value.\"\"\"\n",
    "    if value == 'True' : return True, True\n",
    "    if value == 'False': return True, False\n",
    "    try   : return True , bool(float(value))\n",
    "    except: return False, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, True), (True, False), (True, True), (True, False), (False, 'abc'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_bool('1'), to_bool('0'), to_bool('True'), to_bool('False'), to_bool('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_unbounded_array(args:list, cursor:int) -> (bool, int, list):\n",
    "    \"\"\"Consume any number of values until either reaching the end of args,\n",
    "    or until finding a value starting with '-', denoting the beginning of a new argument.\n",
    "    Return success, the cursor, and the list of values.\n",
    "    Currently this can't actually fail... don't use unbounded lists kids.\"\"\"\n",
    "    values = []\n",
    "    while True:\n",
    "        string_success, cursor, value = get_next_argument(args, None, cursor, suppress_error=True)\n",
    "        if string_success:\n",
    "            if value[0] != '-': values.append(value)\n",
    "            else: # value starting with '-' means it's the next command\n",
    "                cursor -= 1\n",
    "                break\n",
    "        else: break\n",
    "    return True, cursor, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, ['1', '2'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_unbounded_array(['-list', '1', '2', '-3'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typify(type_or_value:object) -> (type, object):\n",
    "    \"\"\"Takes a type or a value.\n",
    "    Returns a tuple of the type (or type of the value) and value (or None)\"\"\"\n",
    "    return (type_or_value, None) if isinstance(type_or_value, type) else (type(type_or_value), type_or_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, (int, int, int, int))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typify((int, int)*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments(command:dict, comment:str) -> (bool, dict, dict):\n",
    "    \"Finds, casts, and returns values from command, in the given comment.\"    \n",
    "    members = command.keys()\n",
    "    result  = command.copy() # copy needed?\n",
    "    args    = comment.split()\n",
    "    # TODO: check that the type of all commands is supported ahead of time?\n",
    "    # TODO: handle quoted arguments?\n",
    "    \n",
    "    is_set = {member : False for member in members}\n",
    "    \n",
    "    state = {'args': args, 'name': '', 'cursor': 0,\n",
    "             'inside_array': False,}\n",
    "    \n",
    "    success = True\n",
    "    while state['cursor'] < len(args): # for arg in args:\n",
    "        arg = args[state['cursor']]\n",
    "        if arg[0] != '-':\n",
    "            report_error(SyntaxError(f\"Argument {state['cursor']} does not start with a '-'.\"))\n",
    "            return False, result, is_set\n",
    "        arg = arg[1:] # remove '-'\n",
    "        state['name'] = arg # TODO: check that len(arg) > 0?\n",
    "        \n",
    "        for key in members: # loop over keys of command (the things we're supposed to find)\n",
    "            if key != arg: continue    \n",
    "            if is_set[key]: # TODO: improve error msg. maybe: \"this is the second time this argument was given\"?\n",
    "                report_error(SyntaxError(f\"Argument {state['cursor']} ('{arg}') was given multiple times.\"))\n",
    "                success = False\n",
    "            else:\n",
    "                arg_type, arg_default = typify(command[key])\n",
    "                member_success = handle_one_argument(result, state, arg_type, arg_default)\n",
    "                if member_success: is_set[key] = True\n",
    "                else: success = False\n",
    "            break # once we have found the correct struct member, stop!\n",
    "        else: # TODO: improve this msg. maybe: \"is not part of the command\"?\n",
    "            report_error(SyntaxError(f\"Argument {state['cursor']} ('{arg}') is not valid.\"))\n",
    "            success = False\n",
    "        if not success: break # stop at first error\n",
    "        state['cursor'] += 1\n",
    "        \n",
    "    if success: success = check_is_set(result, is_set)\n",
    "    return success, result, is_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_one_argument(result:dict, state:dict, arg_type:type, arg_default:object) -> bool:\n",
    "    \"Parse the input args based on arg_type, and set arg_name in result to that value.\"\n",
    "    # NOTE: state and result are modified from here and essentially treated as pointers\n",
    "    args     = state['args']\n",
    "    arg_name = state['name']\n",
    "    success  = True\n",
    "    if arg_type == str:\n",
    "        # get the next argument, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        # TODO: how to handle strings that start with a '-'\n",
    "        if string_success: result[arg_name] = value\n",
    "        else: success = False\n",
    "\n",
    "    elif arg_type == bool:\n",
    "        if state['inside_array']:\n",
    "            string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "            if string_success:\n",
    "                bool_success, value = to_bool(value)\n",
    "                if bool_success: result[arg_name] = value\n",
    "                else:\n",
    "                    report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                    was not convertable to bool. Please use 'True', 'False', '0', or '1'. (It was '{value}')\"))\n",
    "                    success = False\n",
    "            else: success = False\n",
    "        # special case where supplying the argument means True and not supplying it means use the default (False)\n",
    "        else: result[arg_name] = True\n",
    "\n",
    "    elif arg_type == int:\n",
    "        # get the next argument, cast to int, check for remainder, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        if not string_success: return False\n",
    "        int_success, value, remainder = to_integer(value)\n",
    "        if int_success:\n",
    "            result[arg_name] = value\n",
    "            if remainder:\n",
    "                report_warning(f\"Junk on the end of the value for int argument \\\n",
    "                               {state['cursor']-1} ('{arg_name}'): {remainder}\")\n",
    "        else:\n",
    "            report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                                    was not an int. (It was '{value}')\"))\n",
    "            success = False\n",
    "\n",
    "    elif arg_type == float:\n",
    "        # get the next argument, cast to float, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        if not string_success: return False\n",
    "        float_success, value = to_float(value)\n",
    "        if float_success: result[arg_name] = value\n",
    "        else:\n",
    "            report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                                    was not a float. (It was '{value}')\"))\n",
    "            success = False\n",
    "\n",
    "    elif arg_type == list or arg_type == tuple:\n",
    "        if arg_default is None: # unbounded list / tuple\n",
    "            if state['inside_array']:\n",
    "                report_error(SyntaxError(f\"Using an unbounded list or tuple inside an array is not supported.\"))\n",
    "                return False\n",
    "            \n",
    "            array_success, state['cursor'], value = to_unbounded_array(args, state['cursor'])\n",
    "            if array_success: # NOTE: currently this can't actually fail... don't use unbounded lists kids.\n",
    "                result[arg_name] = arg_type(value)\n",
    "            else: success = False\n",
    "            \n",
    "        else: # predefined list\n",
    "            s = {'args': args, 'name': 'v', 'cursor': state['cursor'],\n",
    "                 'inside_array': True}\n",
    "            value = []\n",
    "            for i, x in enumerate(arg_default):\n",
    "                t, d = typify(x)\n",
    "                n = f'{arg_name}[{i}]'\n",
    "                s['name'] = n\n",
    "                r = {n:d}\n",
    "                member_success = handle_one_argument(r, s, t, d)\n",
    "                if member_success: value.append(r[n])\n",
    "                else: # TODO: Improve error message\n",
    "                    # report_error(SyntaxError(f\"Array argument {state['cursor']} ('{arg_name}') was not passed correctly.\"))\n",
    "                    return False\n",
    "            state['cursor'] = s['cursor']\n",
    "            result[arg_name] = arg_type(value)\n",
    "\n",
    "    else:\n",
    "        report_error(TypeError(f\"Argument {state['cursor']} ('{arg_name}') is of unsupported type {arg_type}.\"))\n",
    "        success = False\n",
    "        \n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_set(result:dict, is_set:dict) -> bool:\n",
    "    \"Check if any required values (those without defaults), haven't been set yet\"\n",
    "    success = True\n",
    "    for member, v_is_set in is_set.items():\n",
    "        if v_is_set: continue\n",
    "        arg_type, arg_default = typify(result[member])\n",
    "        if arg_default is None: \n",
    "            if arg_type == bool: # NOTE: Special case, not setting a boolean means it's False.\n",
    "                result[member] = False # TODO: set is_set as well? what's the use-case here?\n",
    "                continue\n",
    "            report_error(ValueError(f\"Argument '{member}' has not been set, and no default value was given.\"))\n",
    "            success = False\n",
    "        elif (arg_type == list) or (arg_type == tuple): # this is a bounded list\n",
    "            name = [f'{member}[{i}]' for i in range(len(arg_default))]\n",
    "            r = {n:x for n, x in zip(name, arg_default)}\n",
    "            s = {n:False for n in r}\n",
    "            is_set_success = check_is_set(r, s)\n",
    "            if is_set_success: # re-set result\n",
    "                result[member] = arg_type([r[n] for n in name])\n",
    "                continue\n",
    "            else: success = False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This argument parser is largely inspired by these two videos by Jonathan Blow.\n",
    ">[Part 1](https://youtu.be/TwqXTf7VfZk)  \n",
    ">[Part 2](https://youtu.be/pgiVrhsGkKY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module besically provides only one function:  \n",
    "```python\n",
    "def parse_arguments(command:dict, comment:str) -> (bool, dict, dict)\n",
    "```  \n",
    "\n",
    "It takes one __\"command\" dictionary__, and a __\"comment\" string__.  \n",
    "\n",
    "#### __The command__\n",
    "\n",
    "is a simple key-value collection of expected flags, where a attribute name maps to either a type, or a default value, from which the type is infered.  \n",
    "```python\n",
    "command = {\n",
    "    'arg1':bool,\n",
    "    'arg2':str,\n",
    "    'arg3':32,\n",
    "    'arg4':3.14,\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The comment__\n",
    "is just a list of space-separated arguments, with words starting with a minus (`'-'`) denoting a keyword, and anything without a minus as the first character being a value to the previous keyword.  \n",
    "```python\n",
    "'-name bob -age 99 -celsius 30.5 -thirsty'\n",
    "```  \n",
    "is a valid string for the command  \n",
    "```python\n",
    "{\n",
    "    'name'   : str,\n",
    "    'weather': 'sunny',\n",
    "    'celsius': float,\n",
    "    'age'    : int,\n",
    "    'thirsty': bool,\n",
    "    'tired'  : bool\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The primitive types:__\n",
    "Currently the following primitive types are supported:  \n",
    "- `str`\n",
    "    - a `str` argument requires one value.\n",
    "    - e.g.: `-weather sunny`\n",
    "- `bool`\n",
    "    - a `bool` argument requires no values. setting the flag automatically sets the value to `True`.\n",
    "    - writing `bool` is the same as using the default value `False`.\n",
    "    - e.g.: `-is_wet`\n",
    "- `int`\n",
    "    - a `int` argument requires one value.\n",
    "    - the value will first be cast to `float`, and then to `int`, partly due to how python works, and also to check for a remainder in case the provided value was actually in a float format.\n",
    "    - e.g.: `-age 99`, `-negative -1`\n",
    "- `float`\n",
    "    - a `float` argument requires one value.\n",
    "    - the value has to be castable to `float`. what is and what isn't a float can be suprising, so you should check the [casting rules](https://stackoverflow.com/a/20929983/) beforehand.\n",
    "    - e.g.: `-pi 3.14`, `-negative -1.0`, `-weird nan`, `-large inf`, `-small -inf`\n",
    "  \n",
    "Any of these types can be declared either by just using the `type` directly, or by giving a default value of the specific `type`. All arguments that use the `type` directly have to be passed in the comment. If a default value is specified, or if the `type` is `bool`, the argument does not have to be passed in the comment, and instead the `result` will simply contain the default value. This changes with composite types (see below). If an argument was passed in the comment or not, can be seen by looking at the `is_set` return value (see below).\n",
    "\n",
    "  \n",
    "##### __The composite types__\n",
    "`list` and `tuple` (referred to as 'array' when it can be either one of them) are also supported, however due to pythons lack of strong typing, they have slightly different semantics.  \n",
    "\n",
    "Specifying only the type `list` or `tuple`, will result in an 'unbounded array' of that type, meaning that all values following the keyword will be added to the array, until either the end of arguments is reached, or a value starts with a minus (`'-'`), which denotes the start of the next argument. All values or the array will be of type `str`. This kind of argument should be used with caution, because, for instance, negative values will be treated as the start of a new argument.  \n",
    "```python\n",
    "{\n",
    "    'unbounded_list' : list,\n",
    "    'unbounded_tuple': tuple,\n",
    "}\n",
    "```  \n",
    "\n",
    "The other, better way to use arrays is to actually create an array containing the types, default values, and ordering you want the values to have. This can get arbitrarily complex, mixing and matching any supported primitive type you want. The only thing not allowed, is using an unbounded array (see above).  \n",
    "All values will be cast to the corresponding type using all the same semantics as of they were single values (see above). The only exception to that is the `bool` type, where the value has to be either `'True'`, `'False'`, or interpretable as a `float`, which will then be cast to a `bool`. This means that e.g. `'0.0'` will result in `False`, and `'123'` will result in `'True'` (careful, check the [casting rules](https://docs.python.org/3.3/library/stdtypes.html?highlight=frozenset#truth-value-testing) first).\n",
    "```python\n",
    "{\n",
    "    'arg1': [int]*5,\n",
    "    'arg2': (3.14, 'pi', bool),\n",
    "    'arg3': (bool, str, 123)*2,\n",
    "    'arg4': [[0]*3, [1]*3, [str]*3],\n",
    "    'arg5': [str, int, bool, True, [1, '2', 3, bool], (2.1, float)]\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The return value__\n",
    "is a three-tuple of `(success, result, is_set)`.  \n",
    "- `success` is a `bool`, saying whether or not parsing was successful. If it is `False`, the other two arguments are not guaranteed to be valid. There will be an error message with details on what happened to help debugging.  \n",
    "- `result` is a `dict` with exactly the same keys as the input `command`, with the corresponding values set to whatever was extracted from the comment. In cases where `success` if `False`, this might only be partially filled out, so `success` should always be checked.\n",
    "- `is_set` is a `dict`, which also contains exactly the same keys as the input `command`, this time mapping to a `bool`. It is `True` if `comment` contains a value for the particular argument, and `False` otherwise. In cases where a default value is given in `command`, the same rule applies. Meaning that only if the default was overwritten by an argument in `comment` will the `is_set` value be `True`. This holds even for `bool`s, which default to `False` even if no explicit default was given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'test': True,\n",
       "  'sunny': True,\n",
       "  'toast': 'jelly',\n",
       "  'shots': 25,\n",
       "  'scale': 69105.1234,\n",
       "  'scoops': ['a', 1, False, [5, 6, 7, False], (3.0, 2.1)],\n",
       "  'valid': (1, 1.23, False, 'hi', [1, 2]),\n",
       "  'nah': 'boi',\n",
       "  'sweet': False,\n",
       "  'nr': 21,\n",
       "  'list': ['2']},\n",
       " {'test': True,\n",
       "  'sunny': True,\n",
       "  'toast': True,\n",
       "  'shots': True,\n",
       "  'scale': True,\n",
       "  'scoops': True,\n",
       "  'valid': False,\n",
       "  'nah': False,\n",
       "  'sweet': False,\n",
       "  'nr': True,\n",
       "  'list': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = {\n",
    "    'test'  : bool,\n",
    "    'sunny' : False,\n",
    "    'toast' : str,\n",
    "    'shots' : int,\n",
    "    'scale' : float,\n",
    "    'scoops': [str, int, bool, [1, 2, 3, bool], (float, float)],\n",
    "    # 'valid' : (bool, bool),\n",
    "    'valid' : (1, 1.23, bool, 'hi', [1, 2]),\n",
    "    'nah'   : 'boi',\n",
    "    'sweet' : bool,\n",
    "    'nr'    : int,\n",
    "    'list'  : list\n",
    "}\n",
    "\n",
    "comment = '-sunny -toast jelly -shots 25 -scale 69105.1234 -test -list 2 -scoops a 1 0 5 6 7 False 3.0 2.1 -nr 21'\n",
    "# comment = '-sunny -toast jelly -shots 25 -scale 69105.1234 -test -nr 1'\n",
    "parse_arguments(command, comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit parse_arguments(command, comment)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit parse_arguments(command, comment)\n",
    ">>> 44 µs ± 98.9 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main [Module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "import os\n",
    "import re\n",
    "from nbdev_rewrite.imports import *\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "import functools\n",
    "from types import MethodType,FunctionType\n",
    "\n",
    "import ast\n",
    "from ast import iter_fields, AST\n",
    "import _ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Parse Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding comments in source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Only look for 0 indent comments?\n",
    "def iter_comments(src:str, pure_comments_only:bool=True, line_limit:int=None) -> (str, (int, int)):\n",
    "    \"Detect all comments in a piece of code, excluding those that are a part of a string.\"\n",
    "    in_lstr = in_sstr = False\n",
    "    count, quote = 1, ''\n",
    "    for i, line in enumerate(src.splitlines()[:line_limit]):\n",
    "        is_pure, escape, prev_c = True, False, '\\n'\n",
    "        for j, c in enumerate(line):\n",
    "            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns\n",
    "            if is_pure and (not (c.isspace() or c == '#')): is_pure = False\n",
    "            if (in_sstr or in_lstr):\n",
    "                # assert in_sstr ^ in_lstr # XOR\n",
    "                if escape: count = 0\n",
    "                else:\n",
    "                    if (c == quote):\n",
    "                        count = ((count + 1) if (c == prev_c) else 1)\n",
    "                        if in_sstr: in_sstr = False\n",
    "                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False\n",
    "                escape = False if escape else (c == '\\\\')\n",
    "            else:                    \n",
    "                if (c == '#'):\n",
    "                    if (pure_comments_only and is_pure): yield (line, (i, j))\n",
    "                    elif (not pure_comments_only):       yield (line[j:], (i, j))\n",
    "                    break\n",
    "                elif c == \"'\" or c == '\"':\n",
    "                    count = ((count + 1) if (c == prev_c) else 1)\n",
    "                    if count == 1: in_sstr = True\n",
    "                    elif count == 3: count, in_lstr = 0, True\n",
    "                    else: assert False, 'If this code path happens, then the code keeping track of quotes is broken.'\n",
    "                    quote = c\n",
    "            prev_c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('# this is a zero indented comment', (0, 0))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iter_comments('# this is a zero indented comment'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This regex is used to remove whitespace and the '#' of python comments.  \n",
    "The content of the comment will be added to a group, which can be extracted afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_comment = re.compile(r\"\"\"\n",
    "        ^              # start of the string\n",
    "        \\s?            # 0 or 1 whitespace\n",
    "        \\#+\\s?         # 1 or more literal \"#\", then 0 or 1 whitespace\n",
    "        (.*)           # group of arbitrary symbols (except new line)\n",
    "        $              # end of the string\n",
    "        \"\"\",re.IGNORECASE | re.VERBOSE) # re.MULTILINE is not passed, since this regex is used on each line separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='# hi'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_comment.search('# hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_match_comment.search('a\\n# hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('# hi',)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_comment.search('# # hi').groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specifies what a valid nbdev comment has to look like, and filters out everything whose syntax does not fit with any of the registered commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_comment(all_commands:dict, comment:str) -> (bool, str, dict, dict):\n",
    "    \"Finds command names and arguments in comments and parses them with parse_arguments()\"\n",
    "    res = re_match_comment.search(comment)\n",
    "    if not res:\n",
    "        report_error(SyntaxError('Not a valid comment syntax.'))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    all_args = res.groups()[0].split()\n",
    "    if len(all_args) == 0:\n",
    "        report_error(SyntaxError(f\"Need at least one argument in comment. Reveived: '{comment}'\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    cmd, *args = all_args\n",
    "    if cmd[0] != '+':\n",
    "        report_error(SyntaxError(f\"The first argument (the command to execute) does not start with a '+'. It was: '{cmd}'\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    cmd = cmd[1:] # remove the '+'\n",
    "    if cmd not in all_commands:\n",
    "        report_error(KeyError(f\"'{cmd}' is not a recognized command. Available: {list(all_commands.keys())}\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    success, result, is_set = parse_arguments(all_commands[cmd], ' '.join(args))\n",
    "    if not success: return False, None, None, None\n",
    "    \n",
    "    return True, cmd, result, is_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_default_exp = {'scope': 'file' , 'to': str}\n",
    "kw_export      = {'internal': bool, 'to': ''}\n",
    "\n",
    "all_commands   = {'default_exp': kw_default_exp, 'export': kw_export}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, {'internal': True, 'to': 'file.py'}, {'internal': True, 'to': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_arguments(all_commands['export'], '-internal -to file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 'export',\n",
       " {'internal': True, 'to': 'file.py'},\n",
       " {'internal': True, 'to': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_comment(all_commands, '# +export -internal -to file.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find function, class and variable Names in Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is using pythons builtin `ast` module to parse source code into an abstract syntax tree, from which the set of all variable-, function-, and classnames is extracted.  \n",
    "All names found, that are not private (prefixed with a single underscore), are added to a set to get rid of duplicate names.  \n",
    "It also seperately parses the nbdev-reserved special variable name `_all_` and adds all assignments to it to the set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some special cases (like fastai specific python extensions) are also handled here, although this will probably change in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debug help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(self, cell_nr=None, export_nr=None):\n",
    "        self.cell_nr   = cell_nr\n",
    "        self.export_nr = export_nr\n",
    "    def __repr__(self):\n",
    "        return f'cell_nr: {self.cell_nr}, export_nr: {self.export_nr}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineno(node):\n",
    "    \"Format a string containing location information on ast nodes. Used for Debugging only.\"\n",
    "    if hasattr(node, 'lineno') and hasattr(node, 'col_offset'):\n",
    "        return f'line_nr: {node.lineno} col_offset: {node.col_offset}'\n",
    "    else: return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(context, node):\n",
    "    \"Format a string with available information on a ast node. Used for Debugging only.\"\n",
    "    return f'\\nLocation: {context} | {lineno(node)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_attr(node:_ast.Attribute) -> str:\n",
    "    \"Joins a sequance of Attribute accesses together in a single string. e.g. numpy.array\"\n",
    "    if isinstance(node.value, _ast.Attribute): return '.'.join((unwrap_attr(node.value), node.attr))\n",
    "    else: return '.'.join((node.value.id, node.attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_from_all_(node, names, c):\n",
    "    \"inplace, recursive update of set of names, by parsing the right side of a _all_ variable\"\n",
    "    if   isinstance(node, _ast.Str): names.add(node.s)\n",
    "    elif isinstance(node, _ast.Name): names.add(node.id)\n",
    "    elif isinstance(node, _ast.Attribute): names.add(unwrap_attr(node))\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "        for x in node.elts: update_from_all_(x, names, c)\n",
    "    elif isinstance(node, _ast.Starred):\n",
    "        raise SyntaxError(f'Starred expression *{node.value.id} not allowed in _all_. {info(c, node)}')\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type. {info(c, node)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_assign(node, names, c):\n",
    "    \"inplace, recursive update of list of names\"\n",
    "    if   isinstance(node, _ast.Name)      : names.append(node.id)\n",
    "    elif isinstance(node, _ast.Starred)   : names.append(node.value.id)\n",
    "    elif isinstance(node, _ast.Attribute) : names.append(unwrap_attr(node))\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple)):\n",
    "        for x in node.elts: unwrap_assign(x, names, c)\n",
    "    elif isinstance(node, list):\n",
    "        for x in node: unwrap_assign(x, names, c)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type. {info(c, node)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_private(name): return not (name.startswith('_') and (not name.startswith('__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_names_A(node, names, c):\n",
    "    \"Handle Assignments to variables\"\n",
    "    tmp_names = list()\n",
    "    unwrap_assign(node.targets, tmp_names, c)\n",
    "    for name in tmp_names:\n",
    "        if not_private(name): names.add(name)\n",
    "        # NOTE: special cases below can only use private variable names\n",
    "        elif name == '_all_': # NOTE: _all_ is a keyword reserved by nbdev.\n",
    "            if len(tmp_names) != 1:\n",
    "                raise SyntaxError(f'Reserved keyword \"_all_\" can only be used in simple assignments. {info(c, node)}')\n",
    "            update_from_all_(node.value, names, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorators(node ): yield from [d.id for d in node.decorator_list]\n",
    "\n",
    "def fastai_patch(cls, node, names, c):\n",
    "    if   isinstance(cls, _ast.Name):\n",
    "        if not_private(cls.id): names.add(f'{cls.id}.{node.name}')\n",
    "    elif isinstance(cls, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "            for x in cls.elts: fastai_patch(x, node, names, c)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {cls} to @patch annotation, unknown type. {info(c, node)}')\n",
    "\n",
    "# ignoring `@typedispatch` might not even be neccesarry,\n",
    "# since all names are added to a single set before being exported.\n",
    "def add_names_FC(node, names, c, fastai_decorators=True):\n",
    "    \"Handle Function and Class Definitions\"\n",
    "    if fastai_decorators and ('patch' in decorators(node)):\n",
    "        if not (len(node.args.args) >= 1): raise SyntaxError(f'fastai\\'s @patch decorator requires at least one parameter. {info(c, node)}')\n",
    "        cls = node.args.args[0].annotation\n",
    "        if cls is None: raise SyntaxError(f'fastai\\'s @patch decorator requires a type annotation on the first parameter. {info(c, node)}')\n",
    "        fastai_patch(cls, node, names, c)\n",
    "    elif fastai_decorators and ('typedispatch' in decorators(node)): return # ignore @typedispatch\n",
    "    elif not_private(node.name): names.add(node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_names(code:str, context:Context=None) -> list:\n",
    "    \"Find all function, class and variable names in the given source code.\"\n",
    "    tree = ast.parse(code)\n",
    "    names = set()\n",
    "    for node in tree.body:\n",
    "        if   isinstance(node,  _ast.Assign                     ): add_names_A (node, names, context)\n",
    "        elif isinstance(node, (_ast.FunctionDef, _ast.ClassDef)): add_names_FC(node, names, context)\n",
    "        else: pass\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_names('x = 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O and Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_config(lib_name='nbdev_rewrite', user='flpeters', nbs_path='.'):\n",
    "    \"create a config file, if it doesn't already exist\"\n",
    "    if not Config().config_file.exists(): create_config(lib_name=lib_name, user=user, nbs_path=nbs_path)\n",
    "init_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lib():\n",
    "    \"initialize the module folder, if it's not initialized already\"\n",
    "    C = Config()\n",
    "    if (not C.lib_path.exists()) or (not (C.lib_path/'__init__.py').exists()):\n",
    "        C.lib_path.mkdir(parents=True, exist_ok=True)\n",
    "        with (C.lib_path/'__init__.py').open('w') as f:\n",
    "            f.write(f'__version__ = \"{C.version}\"\\n')\n",
    "    else: pass # module *should* already exists\n",
    "init_lib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/Projects/GitHub/nbdev_rewrite/00_export.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/01_helpers.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/02_export_v2.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/03_export_v3.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/99_index.ipynb'),\n",
       " WindowsPath('D:/Projects/GitHub/nbdev_rewrite/sub/lalalala.ipynb')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_reserved_dirs = (Config().lib_path, Config().nbs_path, Config().doc_path)\n",
    "def crawl_directory(path:Path, recurse:bool=True) -> list:\n",
    "    \"finds a list of ipynb files to convert\"\n",
    "    # TODO: Handle symlinks?\n",
    "    if isinstance(path, (list, tuple)):\n",
    "        for p in path: yield from crawl_directory(p, recurse)\n",
    "    elif path.is_file(): yield path\n",
    "    else:\n",
    "        for p in path.iterdir():\n",
    "            f = p.name\n",
    "            if f.startswith('.') or f.startswith('_'): continue\n",
    "            if p.is_file():\n",
    "                if f.endswith('.ipynb'): yield p\n",
    "                else: continue\n",
    "            elif p.is_dir() and recurse:\n",
    "                if p in _reserved_dirs: continue\n",
    "                else: yield from crawl_directory(p, recurse)\n",
    "            else: continue\n",
    "list(crawl_directory(Config().nbs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_nb(fname:Path) -> dict:\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return dict(nbformat.reads(f.read(), as_version=4))\n",
    "len(read_nb('03_export_v3.ipynb')['cells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90, 2, 100, 174, 31, 2]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@prefetch(max_prefetch=4)\n",
    "def file_generator(path:Path=Config().nbs_path) -> (Path, dict):\n",
    "    for file_path in crawl_directory(path): yield (file_path, read_nb(file_path))\n",
    "[len(x[1]['cells']) for x in file_generator()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Path Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identify modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use pattern matching to identify valid module names."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://docs.python.org/2.0/ref/identifiers.html\n",
    "identifier:     (letter|\"_\") (letter|digit|\"_\")*\n",
    "letter:         lowercase | uppercase\n",
    "lowercase:      \"a\"...\"z\"\n",
    "uppercase:      \"A\"...\"Z\"\n",
    "digit:          \"0\"...\"9\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://docs.python.org/2.0/ref/import.html\n",
    "import_stmt:    \"import\" module [\"as\" name] (\",\" module [\"as\" name] )* \n",
    "              | \"from\" module \"import\" identifier [\"as\" name]\n",
    "                (\",\" identifier [\"as\" name] )*\n",
    "              | \"from\" module \"import\" \"*\" \n",
    "module:         (identifier \".\")* identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "letter = 'a-zA-Z'\n",
    "identifier = f'[{letter}_][{letter}0-9_]*'\n",
    "module = fr'(?:{identifier}\\.)*{identifier}'\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_module = re.compile(fr\"\"\"\n",
    "        ^              # start of the string\n",
    "        {module}       # definition for matching a module \n",
    "        $              # end of the string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 16), match='module.main.test'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_module.search('module.main.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_to_path(m:str)->Path:\n",
    "    \"Turn a module name into a path such that the exported file can be imported from the library \"\\\n",
    "    \"using the same expression.\"\n",
    "    if re_match_module.search(m) is not None:\n",
    "        if m.endswith('.py'):\n",
    "            raise ValueError(f\"The module name '{m}' is not valid, because ending on '.py' \"\\\n",
    "                             f\"would produce a file called 'py.py' in the folder '{m.split('.')[-2]}', \"\\\n",
    "                              \"which is most likely not what was intended.\\nTo name a file 'py.py', use the \"\\\n",
    "                              \"'-to_path' argument instead of '-to'.\")\n",
    "        return Config().path_to('lib')/f\"{os.path.sep.join(m.split('.'))}.py\"\n",
    "    else: raise ValueError(f\"'{m}' is not a valid module name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/module/sub/file.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_to_path('module.sub.file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/main/main.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_to_path('main')\n",
    "module_to_path('main.main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions might come in handy late on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??importlib.util._resolve_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.util.resolve_name??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'module.export'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.util.resolve_name('..export', 'module.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identify paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the user explicitly passes a path, then this code is tasked with checking it for correctness and converting it to an absolute path from the perspective of the library path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commonpath(*paths)->Path:\n",
    "    \"Given a sequence of path names, returns the longest common sub-path.\"\n",
    "    return Path(os.path.commonpath(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/abc/fgh')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonpath(Path('c:/abc/fgh/a'), Path('c:/abc/fgh/b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_directory(p:Path, d:Path)->bool:\n",
    "    \"Tests if `p` is pointing to something in the directory `d`.\\n\"\\\n",
    "    \"Expects both `p` and `d` to be fully resolved and absolute paths.\"\n",
    "    return p.as_posix().startswith(d.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_directory_slow_1(p, d)->bool:\n",
    "    try: p.relative_to(d)\n",
    "    except: return False\n",
    "    else: return True\n",
    "def in_directory_slow_2(p, d)->bool:\n",
    "    return len(commonpath(p, d).parts) >= len(d.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_directory(p=Path('C:/abc/fgh/abc.txt'), d=Path('C:/abc/fgh/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_valid_path(s:str)->Path:\n",
    "    \"Turn a export path argument into a valid path, resolving relative paths and checking for mistakes.\"\n",
    "    p, lib = Path(s), Config().path_to('lib')\n",
    "    is_abs = p.is_absolute()\n",
    "    p = (p if is_abs else (lib/p)).resolve()\n",
    "    if (not is_abs) and (not in_directory(p, lib)):\n",
    "        raise ValueError(\"Relative export path beyond top level directory of library is not allowed by default. \"\\\n",
    "                        f\"Use an absolute path, or set <NOT IMPLEMENTED YET> flag on the command. ('{s}')\")\n",
    "    if not p.suffix: raise ValueError(f\"The path '{s}' is missing a file type suffix like '.py'.\")\n",
    "    if p.suffix == '.py': return p\n",
    "    else: raise ValueError(f\"'{p.suffix}' is not a valid file ending. ('{s}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/hi.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path(Path('./module/../hi.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/main.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path('main.py')\n",
    "make_valid_path('./main.py')\n",
    "make_valid_path('../../nbdev_rewrite/nbdev_rewrite/main.py')\n",
    "make_valid_path('d:/main.py')\n",
    "make_valid_path('main/main.py')\n",
    "make_valid_path('../nbdev_rewrite/main.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Writing [old]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_py(code:[str], names:{str}, py_fname:str, nb_fname:str, sep:str='\\n\\n'):\n",
    "    config = Config()\n",
    "    py_path     = config.lib_path/f'{py_fname}.py'\n",
    "    nb_path     = config.nbs_path/f'{nb_fname}'\n",
    "    proj_path   = config.config_file.parent\n",
    "    rel_nb_path = os.path.relpath(nb_path, proj_path).replace('\\\\', '/')\n",
    "    warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {rel_nb_path} (unless otherwise specified).'\n",
    "    names = sep + \"__all__ = ['\" + \"', '\".join(sorted(s.names)) + \"']\" # TODO(florian): add line breaks at regular intervals\n",
    "    code  = ''.join(s.code)\n",
    "    file_content = warning + names + code\n",
    "    py_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(py_path, 'w', encoding='utf8') as f: f.write(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Wrapper [old]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        self.before, self.normal, self.after = [], [], []\n",
    "    def __repr__(self): return f'File Name: {self.fname}\\n{self.all_cells}'\n",
    "    def __len__ (self): return (len(self.before) + len(self.normal) + len(self.after))\n",
    "    def prepend(self, cell): self.before.append(cell)\n",
    "    def add    (self, cell): self.normal.append(cell)\n",
    "    def append (self, cell): self.after .append(cell)\n",
    "    def sort   (self, cells): return sorted(cells, key=lambda c: c.cell_nr)\n",
    "    @property\n",
    "    def all_cells(self): return (self.sort(self.before) + self.sort(self.normal) + self.sort(self.after))\n",
    "    @property\n",
    "    def code(self):\n",
    "        return [f\"# {cell.origin}\\n{cell.source_code}\" for cell in self.all_cells]\n",
    "    @property\n",
    "    def names(self):\n",
    "        names = set()\n",
    "        names.update(*[cell.names for cell in self.all_cells])\n",
    "        return names \n",
    "    def export(self):\n",
    "        cells = self.all_cells\n",
    "        code  = [f\"# {cell.origin}\\n{cell.source_code}\" for cell in cells]\n",
    "        names = set()\n",
    "        names.update(*[cell.names for cell in cells])\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileDict():\n",
    "    def __init__(self, default=None):\n",
    "        self.d = {}  \n",
    "        self[default]\n",
    "    def __repr__(self): return self.d.__repr__()\n",
    "    def __getitem__(self, name):\n",
    "        if name in self.d: return self.d[name]\n",
    "        else:\n",
    "            f = File(name)\n",
    "            self.d[name] = f\n",
    "            return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None: File Name: None\n",
       "[]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = FileDict(); X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command registration via Decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @register_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@register_command` stores argument information about the registered function in the global variables `all_commands`, and a reference to the function in `cmd2func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_commands = {}\n",
    "cmd2func     = {}\n",
    "\n",
    "def register_command(cmd, args, active=True):\n",
    "    \"Store mapping from command name to args, and command name to reference to the decorated function in globals.\"\n",
    "    if not active: return lambda f: f\n",
    "    all_commands[cmd] = args\n",
    "    def _reg(f):\n",
    "        cmd2func[cmd] = f\n",
    "        return f\n",
    "    return _reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: add support for a scoped #default_exp. Support exporting cells under a specific heading to a seperate file.\n",
    "setting #default_exp on a per-heading / per-scope level, not on a once per file level."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: # file-documentation tag, for writing a doc string for an entire file, or for an entire module"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "global settings:\n",
    "- seperation amount (vertical whitespace) between cells\n",
    "- how to look for comments\n",
    "- command syntax\n",
    "- \n",
    "\n",
    "all cell data:  \n",
    "- meta cells\n",
    "- default export target\n",
    "- file name\n",
    "\n",
    "per cell data:  \n",
    "- source code\n",
    "- variable, function and class names\n",
    "- export yes/no\n",
    "- internal (export names) yes/no\n",
    "- cell number / order\n",
    "\n",
    "Things that need to be aggregated before return:\n",
    "- union of all names\n",
    "- ordered list of source code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "default_export -> default file | None\n",
    "\n",
    "cell X export -to cell_X -> cell_X file\n",
    "cell Y export -to cell_X -> cell_X file\n",
    "cell Z export -> default file\n",
    "\n",
    "scope A default_export -> scope_A file\n",
    "    cell A_Y export -to cell_X -> cell_X file\n",
    "    cell A_Z export -> scope_A file\n",
    "\n",
    "scope B default_export -> scope_B file\n",
    "    cell B_Z export -> scope_B file\n",
    "    \n",
    "cell K export -> default file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackTrace for Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a class for passing along contextual information during execution.  \n",
    "The class is a linked list, which can be extended each time a new function is called.  \n",
    "Everytime a function is called, create a new StackTrace instance, and pass the current instance to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackTrace: pass # only for :StackTrace annotations to work\n",
    "class StackTrace:\n",
    "    up  :StackTrace = None\n",
    "    context = None # TODO: File origin and other data important for debugging should be carried along as well\n",
    "    namespace:str = None\n",
    "    lineno:int = None\n",
    "    charno:int = None\n",
    "        \n",
    "    def __init__(self, namespace:str,\n",
    "                 up:StackTrace=None,\n",
    "                 lineno:int=None, charno:int=None):\n",
    "        self.namespace = namespace\n",
    "        self.up = up\n",
    "        self.lineno, self.charno = lineno, charno\n",
    "        \n",
    "    def __repr__(self):\n",
    "        s = f'<{self.namespace}> ({self.lineno}, {self.charno})'\n",
    "        if (self.up is None): return s\n",
    "        else: return f'{self.up.__repr__()}\\n\\n{s}'\n",
    "    \n",
    "    def report_error(self, err:Exception):\n",
    "        err_type = err.__class__.__name__\n",
    "        s = f\"{'-'*75}\\n{err_type}\\t\\t\\t\\tStacktrace (most recent call last)\\n\"\\\n",
    "        f\"{self.__repr__()}\\n\\n\"\\\n",
    "        f\"[{err_type}]: {err}\"\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SyntaxError\t\t\t\tStacktrace (most recent call last)\n",
      "<main> (None, None)\n",
      "\n",
      "<load_and_parse_all> (None, None)\n",
      "\n",
      "[SyntaxError]: Failed to parse\n"
     ]
    }
   ],
   "source": [
    "StackTrace('load_and_parse_all', up=StackTrace(namespace='main')).report_error(SyntaxError('Failed to parse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _part(st):\n",
    "    success = True\n",
    "    st.report_error(Exception('Failed doing the thing'))\n",
    "    success = False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _start():\n",
    "    st = StackTrace('start')\n",
    "    success = True\n",
    "    success_part = _part(StackTrace('part', up=st))\n",
    "    if not success_part:\n",
    "        success = False\n",
    "        return 0\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Exception\t\t\t\tStacktrace (most recent call last)\n",
      "<start> (None, None)\n",
      "\n",
      "<part> (None, None)\n",
      "\n",
      "[Exception]: Failed doing the thing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference of Python Tracebacks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> (lambda: 1/0)()\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \"<stdin>\", line 1, in <lambda>\n",
    "ZeroDivisionError: division by zero"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(lambda: 1/0)()\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "ZeroDivisionError                         Traceback (most recent call last)\n",
    "<ipython-input-200-e700a98730a6> in <module>\n",
    "----> 1 (lambda: 1/0)()\n",
    "\n",
    "<ipython-input-200-e700a98730a6> in <lambda>()\n",
    "----> 1 (lambda: 1/0)()\n",
    "\n",
    "ZeroDivisionError: division by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Wrapper [old]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell:\n",
    "    def __init__(self, cell_nr:int, cell:dict):\n",
    "        # cell data\n",
    "        self.cell_nr     = cell_nr\n",
    "        self.source_code = cell['source']\n",
    "        self.cell_type   = cell['cell_type']\n",
    "        # cell state\n",
    "        self.origin = ''\n",
    "        self.names , self._comments = set(), None\n",
    "        self.source_to_remove = []\n",
    "        self.internal  = False\n",
    "        \n",
    "    def __repr__(self): return f'{self.cell_nr}, {self.cell_type}:\\n{self.source_code}\\n\\n'    \n",
    "    \n",
    "    def remove_comment(self, loc_line:int, loc_char:int=None):\n",
    "        self.source_to_remove.append((loc_line, loc_char))\n",
    "        \n",
    "        # NOTICE: calling this during iteration CAN lead to false results\n",
    "    def _remove_source_at(self, loc_line:int, loc_char:int=None) -> str:\n",
    "        \"pass loc_char to only remove part of the line and keep the rest\"\n",
    "        lines = self.source_code.splitlines()\n",
    "        if (loc_char is None): lines.pop(loc_line) # (loc_char is None) or (loc_char <= 1) ?\n",
    "        else                 : lines[loc_line] = lines[loc_line][:loc_char]\n",
    "        self.source_code = '\\n'.join(lines)\n",
    "        \n",
    "    def _cache_iter_comments(self): # TODO: is this even needed?\n",
    "        \"cache the result of iter_comments for faster repeated access\"\n",
    "        agg = []\n",
    "        for x in iter_comments(self.cell_nr, self.source_code, pure_comments_only=True):\n",
    "            agg.append(x)\n",
    "            yield x\n",
    "        self._comments = agg\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self._comments is None: yield from self._cache_iter_comments() # TODO: is this even needed?\n",
    "        else:                      yield from iter(self._comments)\n",
    "            \n",
    "        if len(self.source_to_remove) > 0:\n",
    "            # important to sort reversed, because removing comments changes later line numbers\n",
    "            for line_and_char_location in sorted(self.source_to_remove, reverse=True):\n",
    "                self._remove_source_at(*line_and_char_location)\n",
    "            self.source_to_remove = []   # reset list\n",
    "            self._comments        = None # invalidate cached comments\n",
    "            \n",
    "    def find_names(self): self.names = find_names(self.source_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Wrapper [old]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    def __init__(self, fname:str):\n",
    "        # notebook data\n",
    "        self.origin_fname = Path(fname)\n",
    "        nb                = read_nb(fname)\n",
    "        self.nb_version   = (nb['nbformat'], nb['nbformat_minor'])\n",
    "        self.metadata     = nb['metadata']\n",
    "        self.cells        = [Cell(cell_nr, cell) for cell_nr, cell in enumerate(nb['cells'])]\n",
    "        # notebook state\n",
    "        self.scopes = {'file': None} # TODO: This is work in progress\n",
    "        self.to = FileDict(default=None)\n",
    "    \n",
    "    def __repr__(self): return self.cells.__repr__()    \n",
    "    \n",
    "    def process_code_cells(self):\n",
    "        \"parse comments and move cells into a struct for further processing based on options set in the comments\"\n",
    "        while True:\n",
    "            meta_present = False\n",
    "            for cell in self.cells:\n",
    "                if cell.cell_type != 'code': continue\n",
    "                for comment, (line_nr, char_nr) in cell:\n",
    "                    success, cmd, result, is_set = parse_comment(all_commands, comment)\n",
    "                    if not success: continue\n",
    "                    print(f'Found: {cmd} @ ({cell.cell_nr}, {line_nr}, {char_nr}) with args: {result}')\n",
    "                    self.process_cmd(cmd, cell, result, is_set)\n",
    "                    cell.remove_comment(loc_line=line_nr, loc_char=None)\n",
    "            if (self.to[None].fname is None) and (len(self.to[None]) > 0):\n",
    "                raise Exception(f\"No default export target has been set, but there are cells without a target.\")\n",
    "            if meta_present: continue\n",
    "            else: break\n",
    "    \n",
    "    def process_cmd(self, cmd, cell, result, is_set):\n",
    "        if cmd in cmd2func: getattr(self, cmd2func[cmd])(cell, result, is_set)\n",
    "        else: raise NameError(f\"The command '{cmd}' is missing a corresponding action '{kw_func}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_commands = {}\n",
    "cmd2func     = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_command(cmd='default_exp', # allow custom scope name that can be referenced in export?\n",
    "                  args={'to': '', 'to_path': '', 'use_scope': False})\n",
    "def kw_default_exp(file_info, cell_info, result, is_set):\n",
    "    \"Set the default file that cells of this notebook will be exported to.\"\n",
    "    if not (is_set['to'] ^ is_set['to_path']): # NOTE: XOR\n",
    "        raise ValueError(\"The `default_exp` command expects exactly one of the arguments \"\\\n",
    "                         f\"'-to' or '-to_path' to be set, but recieved was: {result}\")\n",
    "    # NOTE: use this cells indentation level, or the default tuple([0]) as key to identify scope\n",
    "    scope:tuple     = cell_info['scope'] if result['use_scope'] else tuple([0])\n",
    "    old_target:Path = file_info['export_scopes'].get(scope, None)\n",
    "    new_target:Path = (module_to_path(result['to'])\n",
    "                       if is_set['to'] else\n",
    "                       make_valid_path(result['to_path']))\n",
    "    if old_target is not None:\n",
    "        raise ValueError(f\"Overwriting an existing export target is not allowed. (cell nr. {cell_info['cell_nr']})\"\\\n",
    "                        f\"\\n\\t\\t->(was: '{old_target}', new: '{new_target}')\")\n",
    "    file_info['export_scopes'][scope] = new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_command(cmd='export',\n",
    "                  args={'internal': False, 'to': '', 'to_path':'', 'cell_nr': 0, 'prepend': False, 'append': False})\n",
    "def kw_export(file_info, cell_info, result, is_set):\n",
    "    \"This cell will be exported from the notebook to a .py file.\"\n",
    "    if (is_set['to'] and is_set['to_path']):\n",
    "        raise ValueError(\"The `export` command does not accept the '-to' and '-to_path' argument at the same time. \"\\\n",
    "                         f\"They are mutually exclusive. Recieved: {result}\")\n",
    "    cell_info['export_to_py'] = True # Using this command implicitly means to export this cell\n",
    "    if is_set['cell_nr']: cell_info['cell_nr'] = result['cell_nr'] # overwrite the cell_nr of this cell\n",
    "    is_internal = cell_info['is_internal'] = result['internal']\n",
    "    if is_internal: pass # no contained names will be added to __all__ for importing\n",
    "    else: cell_info['names'] = find_names(cell_info['original_source_code'])\n",
    "    info_string = f\"{'Internal ' if is_internal else ''}Cell nr. {cell_info['cell_nr']}\"\n",
    "    export_target = None\n",
    "    if is_set['to'     ]: export_target = module_to_path (result['to'])\n",
    "    if is_set['to_path']: export_target = make_valid_path(result['to_path'])\n",
    "    if export_target is not None:\n",
    "        cell_info['export_to'] = export_target # Set a new export target just for this cell.\n",
    "        info_string += f\"; Comes from {file_info['origin_file'].name}\"\n",
    "    cell_info['info_string'] = info_string\n",
    "    \n",
    "    # TODO: support setting append or prepend\n",
    "#     append, prepend = result['append'], result['prepend']\n",
    "#     if append : cls.to[targ].append(cell)\n",
    "#     if prepend: cls.to[targ].prepend(cell)\n",
    "#     if (append and prepend):\n",
    "#         report_warning(f'Cell nr. {cell.cell_nr} is being appended AND prepended to the output file.')\n",
    "#     else: cls.to[targ].add(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_command(cmd='set',\n",
    "                  args={'file': '', 'use_names': True},\n",
    "                  active=False)\n",
    "def kw_set(file_info, cell_info, result, is_set):\n",
    "    \"set some predefined variables that control execution behaviour\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `default_exp`  \n",
    "Set the default file that cells of this notebook will be exported to.  \n",
    "Args:\n",
    "- `to`: The target file name. \n",
    "- `scope`: Set a scope for which this default value is valid. The default is 'file' level. Smaller scopes overwrite larger ones. Other options are: 'heading' (Not Implemented Yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `export`  \n",
    "This cell will be exported from the notebook to a .py file.  \n",
    "Args:  \n",
    "- `internal`: The variable, function and class names of this cell will not be added to `__all__` in the exported file, making them hidden from any `import *`.\n",
    "- `to`: Instead of exporting to the notebook or scope wide default file, this cell is exported to the file specified in this argument.\n",
    "- `cell_nr`: Overwrite the cell_nr of this cell. every cell has this number, based on it's position in the notebook file. Overwriting it has the effect of repositioning this cell in the output .py file, since cells are sorted by cell_nr.\n",
    "- `prepend`: Every file has three \"buckets\" that cells can be added to. The 'before', 'normal', and 'after' Bucket. Setting `prepend` to `True`, means this cell will be added to the 'before' Bucket. Cells in the 'before' Bucket will appear before all cells in both the 'normal' and 'after' Bucket in the output .py file.\n",
    "- `append`: Setting `append` to `True`, means this cell will be added to the 'after' Bucket. Cells in the 'after' Bucket will appear after all cells in both the 'before' and 'normal' Bucket in the output .py file. Setting neither `prepend` nor `append`, means this cell will be added to the 'normal' Bucket. Use cases for these two arguments might be sending all imports in a notebook to the top of the .py file, or helping with correctly ordering cells exported to a different file (e.g. using the `to` arg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `set`  \n",
    "Set some predefined variables that control execution behaviour.  \n",
    "Args:  \n",
    "- `file`: If this is set, the variables will only be set on this specific file.\n",
    "- `use_names`: Control whether or not a `__all__` with all (non internal) variable, function and class names should be inserted at the top of the file. Default is `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changelog:  \n",
    "- remove cell_nr argument from iter_comments, and replace Exception with an assert, to make it clear that that code path can only happen if there is a bug in the iter_comments itself.\n",
    "- improve error messages, and make the distinction between nbdev errors, and errors in how the user uses nbdev more clear.\n",
    "- implement file merging, and scope matching for cells in write_out_all()\n",
    "- improve Argument Parsing documentation\n",
    "- Add export path parsing\n",
    "- Add '-to_path' argument to 'default_exp' and 'export' command, as an alternative to '-to'\n",
    "- The '-to' argument now expects a export target in the form of a python module name e.g. 'module.test'\n",
    "- The '-to_path' argument expects a export target in the from of a Path. It supports relative paths e.g. './module/test.py', which are interpreted as being relative to the library directory, and it supports absolute paths e.g. 'C:/test.py', which can be used to export to anywhere on the system.\n",
    "- Temporarily add some code that's copied from original nbdev project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Use the StackTrace class for error reporting in registered commands, when interacting with other files.\n",
    "- Allow for exporting the same cell multiple times, even to different files.\n",
    "- Convert paths passed to commands to absolute paths.\n",
    "- Make sure that if `cell_info['export_to']` is set, its value is respected. This could mess with exports to multiple files.\n",
    "- Remove command comments from source code.\n",
    "- Fix relative import paths.\n",
    "- Support Automatic / Explicit Versioning\n",
    "- Add better debugging information. e.g. default_exp should show the previous occurence in case it is defined multiple times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = read_nb('03_export_v3.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_heading = re.compile(r\"\"\"\n",
    "        ^              # start of the string\n",
    "        (\\#+)\\s+       # 1 or more literal \"#\", then 1 or more whitespace\n",
    "        (.*)           # group of arbitrary symbols (including new line)\n",
    "        $              # end of the string\n",
    "        \"\"\",re.IGNORECASE | re.VERBOSE | re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('##', 'test')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = re_match_heading.search('## test')\n",
    "res.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path:Path, file:dict, st:StackTrace) -> (bool, dict):\n",
    "    success = True\n",
    "    nb_version:(int, int) = (file['nbformat'], file['nbformat_minor'])\n",
    "    metadata  :dict       =  file['metadata']\n",
    "    file_info = {\n",
    "        'origin_file' : file_path,\n",
    "        'nb_version' : nb_version,\n",
    "        'export_scopes' : {\n",
    "            tuple([0]) : None, # This is the default for an entire file.\n",
    "        }\n",
    "    }\n",
    "    scope_count :int = [0]\n",
    "    scope_level :int = 0\n",
    "    \n",
    "    cells:list = []\n",
    "        \n",
    "    for i, cell in enumerate(file['cells']):\n",
    "        cell_type   = cell['cell_type']\n",
    "        cell_source = cell['source']\n",
    "        cell_info = {\n",
    "            'cell_nr' : i,\n",
    "            'cell_type' : cell_type,\n",
    "            'original_source_code' : cell_source,\n",
    "            'scope' : tuple(scope_count),\n",
    "            'export_to_py' : False,\n",
    "            'is_internal' : None,\n",
    "            'export_to' : None,\n",
    "            'names' : None,\n",
    "            'comments' : [] # append comments to this list\n",
    "        }\n",
    "        if cell_type == 'code':\n",
    "            for comment, (lineno, charno) in iter_comments(cell_source, pure_comments_only=True, line_limit=None):\n",
    "                success, cmd, result, is_set = parse_comment(all_commands, comment)\n",
    "                if not success: continue\n",
    "                print(f'Found: {cmd} @ ({i}, {lineno}, {charno}) with args: {result}')\n",
    "                if cmd in cmd2func: cmd2func[cmd](file_info, cell_info, result, is_set)\n",
    "                else: raise Exception(f\"The command '{cmd}' in cell number {i} is recognized, \"\\\n",
    "                                       \"but is missing a corresponding action.\")\n",
    "                 # cell.remove_comment(loc_line=line_nr, loc_char=None) # this removed the comment from the source.\n",
    "        elif cell_type == 'markdown':\n",
    "            res = re_match_heading.search(cell_source)\n",
    "            if not (res is None): # this cell contains a heading\n",
    "                heading_level, heading_name = res.groups()\n",
    "                new_scope_level = len(heading_level) # number of '#' in the heading\n",
    "                if new_scope_level > scope_level:\n",
    "                    scope_count += ([0] * (new_scope_level - (len(scope_count)))) # extend list if necessary\n",
    "                elif new_scope_level < scope_level:\n",
    "                    scope_count = scope_count[:new_scope_level] # reset lower values\n",
    "                scope_count[new_scope_level - 1] += 1\n",
    "                scope_level = new_scope_level\n",
    "            else: pass # this cell is regular markdown\n",
    "        elif cell_type == 'raw': pass\n",
    "        else: raise Exception(f'Unknown cell_type \"{cell_type}\" in cell number {i}.'\\\n",
    "                               'Should be \"code\", \"markdown\", or \"raw\".')\n",
    "        cells.append(cell_info)\n",
    "    file_info['cells'] = cells\n",
    "    return success, file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse_all(origin_path:Path, output_path:Path, recurse:bool, st:StackTrace) -> (bool, dict):\n",
    "    \"Loads all .ipynb files in the origin_path directory, and passes them one at a time to parse_file.\"\n",
    "    # TODO: replace these two lines with a call to file_generator() defined above.\n",
    "    file_paths:list = crawl_directory(Config().nbs_path)\n",
    "    \n",
    "    # TODO: fine tune, or even pass an argument from the user on how many thread to use for prefetching files.\n",
    "    #       num_cpus() from nbdev.imports can be used here\n",
    "    file_generator = BackgroundGenerator(((file_path, read_nb(file_path)) for file_path in file_paths), max_prefetch=4)\n",
    "    \n",
    "    parsed_files = {\n",
    "        # Add flags and settings variables above this line\n",
    "        'files': list()        \n",
    "    }\n",
    "    \n",
    "    # TODO: use multithreading / multiprocessing per file / per bunch of cells\n",
    "    for file_path, file in file_generator:\n",
    "        if file_path.name != '03_export_v3.ipynb': continue # For Debugging\n",
    "        success, file = parse_file(file_path, file, st=StackTrace('parse_file', st))\n",
    "        # TODO: try parsing all the files, even if one fails?\n",
    "        if not success:\n",
    "            st.report_error(Exception(f'Error while parsing {file_path}'))\n",
    "            return 0, None\n",
    "        # TODO: before returning, give any meta programm a chance to run.\n",
    "        # maybe have parse_file return some additional information about any meta programm\n",
    "        parsed_files['files'].append(file)\n",
    "        \n",
    "    return True, parsed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_py(code:[str], names:{str}, py_fname:str, nb_fname:str, sep:str='\\n\\n'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_info, st:StackTrace) -> bool:\n",
    "    print('-'*70)\n",
    "#     py_path     = lib_path/f'{py_fname}.py'\n",
    "#     nb_path     = file_info['origin_file']\n",
    "#     rel_nb_path = os.path.relpath(nb_path, proj_path).replace('\\\\', '/')\n",
    "#     warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {rel_nb_path} (unless otherwise specified).'\n",
    "#     # names = sep + \"__all__ = ['\" + \"', '\".join(sorted(s.names)) + \"']\" # TODO: add line breaks at regular intervals\n",
    "#     # code  = ''.join(s.code)\n",
    "#     # file_content = warning + names + code\n",
    "#     py_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     with open(py_path, 'w', encoding='utf8') as f: f.write(file_content)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_all(parsed_files, st:StackTrace) -> bool:\n",
    "    # TODO: write one file at a time to disk, to the correct directory,\n",
    "    # initialize a python module, if it doesn't already exists,\n",
    "    # Handle mergers between multiple parsed_files. <-----------------\n",
    "    # Translate export targets that are written in the same way as imports\n",
    "    # e.g. a target of abc.xyz should export into the Config's library directory\n",
    "    # in a way that import lib.abc.xyz imports that specific piece of code. (Same as import xyz from lib.abc)\n",
    "    config    = Config()\n",
    "    lib_path  = config.lib_path\n",
    "    nbs_path  = config.nbs_path\n",
    "    proj_path = config.config_file.parent\n",
    "    \n",
    "    export_files = {}\n",
    "    \n",
    "    for file_info in parsed_files['files']:\n",
    "        scopes:dict = file_info['export_scopes']\n",
    "        assert len(scopes) >= 1, 'No export Scopes Defined.'\n",
    "        use_scopes:bool = len(scopes) > 1\n",
    "        # NOTE: Having no default is ok, as long as all cells still have a valid export target\n",
    "        default_export = scopes[tuple([0])]\n",
    "        if default_export is None:\n",
    "            # TODO: raise Exception here if use_scopes is False?\n",
    "            check_default = True\n",
    "        \n",
    "        scope_paths = {}\n",
    "        for k, v in scopes.items():\n",
    "            # if v is None: continue # skipping None's can lead to unwanted behaviour. Better to raise an Exception.\n",
    "            # TODO: Do the translation to actual file paths.\n",
    "            if v is None: scope_paths[k] = v\n",
    "            else        : scope_paths[k] = Path(v)\n",
    "        \n",
    "        for cell in file_info['cells']:\n",
    "            if not cell['export_to_py']: continue\n",
    "            export_target = None\n",
    "            if cell['export_to'] is None:\n",
    "                best_fit = tuple([0])\n",
    "                if use_scopes: # fast path to skip scope matching if there are no scopes defined.\n",
    "                    # Do scope matching\n",
    "                    cell_scope = cell['scope']\n",
    "                    best_fit_len = 0\n",
    "                    for k in scope_paths.keys():\n",
    "                        if ((len(k) > best_fit_len) # Trying to find the tightest fit\n",
    "                            and (k == cell_scope[:len(k)])): # iff part of this scope check\n",
    "                            best_fit, best_fit_len = k, len(k)\n",
    "                else: pass # use the default\n",
    "                export_target = scope_paths[best_fit]\n",
    "                # NOTE: The export_target can only really be None in the case of the default.\n",
    "                # TODO: This check can maybe be optimised so it doesn't have to happen every time.\n",
    "                if export_target is None: raise Exception(f'Export Target of cell {cell[\"cell_nr\"]} is None. '\\\n",
    "                                                         'Did you forget to add a default target using `default_exp`?')\n",
    "            else:\n",
    "                # TODO: Translate this into a proper Path as well\n",
    "                export_target = Path(cell['export_to'])\n",
    "                \n",
    "            if not (export_target in export_files): export_files[export_target] = {'names': set(), 'code': []}\n",
    "            if not cell['is_internal']: export_files[export_target]['names'].update(cell['names'])\n",
    "            # TODO: use the \"original\", or will there be another one?\n",
    "            export_files[export_target]['code'].append(cell['original_source_code'])\n",
    "        # NOTE: Files can't be written at this point, since there might be other notebooks exporting to the same file.\n",
    "    \n",
    "    print(export_files)\n",
    "    for file_info in export_files: write_file(file_info, st=StackTrace('write_file', st))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(origin_path:str=None, output_path:str=None, recurse:bool=True) -> bool:\n",
    "    st = StackTrace('main')\n",
    "    origin_path:Path = Config().nbs_path if origin_path is None else Path(origin_path).resolve()\n",
    "    output_path:Path = Config().lib_path if output_path is None else Path(output_path).resolve()\n",
    "    \n",
    "    success, parsed_files = load_and_parse_all(origin_path, output_path, recurse,\n",
    "                                               st=StackTrace('load_and_parse_all', st))\n",
    "    if not success:\n",
    "        return 0\n",
    "    # NOTE: At this point all files are completely parsed, and any meta programm has run.\n",
    "    \n",
    "    success = write_out_all(parsed_files, st=StackTrace('write_out_all', st))\n",
    "    return success, parsed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_ERROR  :bool = False\n",
    "REPORT_WARNING:bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: export @ (169, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: default_exp @ (170, 0, 0) with args: {'to': 'et_is_real', 'to_path': '', 'use_scope': False}\n",
      "Found: export @ (170, 1, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (171, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (172, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (173, 0, 0) with args: {'internal': False, 'to': 'abc_test', 'to_path': '', 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "{WindowsPath('D:/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/et_is_real.py'): {'names': {'x'}, 'code': [\"# +export\\nx = 'hi'\", '# +default_exp -to et_is_real\\n# +export\\n\"This is a tricky case\";', '# +export -internal\\n2+2;', '# +export\\n1+1;']}, WindowsPath('D:/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/abc_test.py'): {'names': set(), 'code': ['# +export -to abc_test\\n3+3;']}}\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "success, parsed_files = main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cell_nr': 169,\n",
       "  'cell_type': 'code',\n",
       "  'original_source_code': \"# +export\\nx = 'hi'\",\n",
       "  'scope': (2, 10),\n",
       "  'export_to_py': True,\n",
       "  'is_internal': False,\n",
       "  'export_to': None,\n",
       "  'names': {'x'},\n",
       "  'comments': [],\n",
       "  'info_string': 'Cell nr. 169'},\n",
       " {'cell_nr': 170,\n",
       "  'cell_type': 'code',\n",
       "  'original_source_code': '# +default_exp -to et_is_real\\n# +export\\n\"This is a tricky case\";',\n",
       "  'scope': (2, 10),\n",
       "  'export_to_py': True,\n",
       "  'is_internal': False,\n",
       "  'export_to': None,\n",
       "  'names': set(),\n",
       "  'comments': [],\n",
       "  'info_string': 'Cell nr. 170'},\n",
       " {'cell_nr': 171,\n",
       "  'cell_type': 'code',\n",
       "  'original_source_code': '# +export -internal\\n2+2;',\n",
       "  'scope': (2, 10),\n",
       "  'export_to_py': True,\n",
       "  'is_internal': True,\n",
       "  'export_to': None,\n",
       "  'names': None,\n",
       "  'comments': [],\n",
       "  'info_string': 'Internal Cell nr. 171'},\n",
       " {'cell_nr': 172,\n",
       "  'cell_type': 'code',\n",
       "  'original_source_code': '# +export\\n1+1;',\n",
       "  'scope': (2, 10),\n",
       "  'export_to_py': True,\n",
       "  'is_internal': False,\n",
       "  'export_to': None,\n",
       "  'names': set(),\n",
       "  'comments': [],\n",
       "  'info_string': 'Cell nr. 172'},\n",
       " {'cell_nr': 173,\n",
       "  'cell_type': 'code',\n",
       "  'original_source_code': '# +export -to abc_test\\n3+3;',\n",
       "  'scope': (2, 10),\n",
       "  'export_to_py': True,\n",
       "  'is_internal': False,\n",
       "  'export_to': WindowsPath('D:/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/abc_test.py'),\n",
       "  'names': set(),\n",
       "  'comments': [],\n",
       "  'info_string': 'Cell nr. 173; Comes from 03_export_v3.ipynb'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in parsed_files['files'][0]['cells'] if c['export_to_py']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop new Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config().lib_path == Config().path_to('lib_path') == Config().path_to('lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Projects/GitHub/nbdev_rewrite/nbdev_rewrite')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib = Config().path_to('lib'); lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path parsing copied from nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_import(name, fname):\n",
    "    \"Convert a module `name` to a name relative to `fname`\"\n",
    "    mods = name.split('.')\n",
    "    splits = str(fname).split(os.path.sep)\n",
    "    if mods[0] not in splits: return name\n",
    "    i=len(splits)-1\n",
    "    while i>0 and splits[i] != mods[0]: i-=1\n",
    "    splits = splits[i:]\n",
    "    while len(mods)>0 and splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]\n",
    "    return '.' * (len(splits)) + '.'.join(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(relative_import('nbdev.core', Path.cwd()/'nbdev'/'data.py'), '.core')\n",
    "test_eq(relative_import('nbdev.core', Path('nbdev')/'vision'/'data.py'), '..core')\n",
    "test_eq(relative_import('nbdev.vision.transform', Path('nbdev')/'vision'/'data.py'), '.transform')\n",
    "test_eq(relative_import('nbdev.notebook.core', Path('nbdev')/'data'/'external.py'), '..notebook.core')\n",
    "test_eq(relative_import('nbdev.vision', Path('nbdev')/'vision'/'learner.py'), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_re_import = ReLibName(r'^(\\s*)from (LIB_NAME\\.\\S*) import (.*)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deal_import(code_lines, fname):\n",
    "    def _replace(m):\n",
    "        sp,mod,obj = m.groups()\n",
    "        return f'{sp}from {relative_import(mod, fname)} import {obj}'\n",
    "    return [_re_import.re.sub(_replace,line) for line in code_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = [\"from nbdev.core import *\", \n",
    "#          \"nothing to see\", \n",
    "#          \"  from nbdev.vision import bla1, bla2\", \n",
    "#          \"from nbdev.vision import models\",\n",
    "#          \"import nbdev.vision\"]\n",
    "# test_eq(_deal_import(lines, Path.cwd()/'nbdev'/'data.py'), [\n",
    "#     \"from .core import *\", \n",
    "#     \"nothing to see\", \n",
    "#     \"  from .vision import bla1, bla2\", \n",
    "#     \"from .vision import models\",\n",
    "#     \"import nbdev.vision\"\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "x = 'hi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +default_exp -to et_is_real\n",
    "# +export\n",
    "\"This is a tricky case\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "2+2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "1+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -to abc_test\n",
    "# +export\n",
    "3+3;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
