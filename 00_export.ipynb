{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from collections import namedtuple, defaultdict\n",
    "import os\n",
    "import re\n",
    "from nbdev_rewrite.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "def run_tests(cases, func, verbose=False):\n",
    "    \"\"\"Run test cases by passing a list of tuples (test name, input to func, expected result)\"\"\"\n",
    "    nr_correct = 0\n",
    "    for i, (n, c, r) in enumerate(cases):\n",
    "        if verbose: print(f'({i + 1} / {len(cases)}) TEST {n}:')\n",
    "        try:\n",
    "            res = func(c)\n",
    "            assert res == r, f'TEST FAILED WITH RESULT: {res}\\nEXPECTED: {r}'\n",
    "            nr_correct += (res == r)\n",
    "            if verbose: print(f'TEST RESULT: SUCCESS\\n')\n",
    "        except Exception as e:\n",
    "            if verbose: print(f'TEST FAILED WITH EXCEPTION:\\n{e}\\n')\n",
    "            # raise e\n",
    "    print('--------------- ALL TESTS COMPLETED ---------------')\n",
    "    print(f'{nr_correct} / {len(cases)} Correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_config('nbdev_rewrite', 'flpeters', nbs_path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_nb(fname):\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return nbformat.reads(f.read(), as_version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = read_nb('00_export.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cells', 'metadata', 'nbformat', 'nbformat_minor'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernelspec': {'display_name': 'Python 3',\n",
       "  'language': 'python',\n",
       "  'name': 'python3'},\n",
       " 'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "  'file_extension': '.py',\n",
       "  'mimetype': 'text/x-python',\n",
       "  'name': 'python',\n",
       "  'nbconvert_exporter': 'python',\n",
       "  'pygments_lexer': 'ipython3',\n",
       "  'version': '3.7.6'},\n",
       " 'toc': {'base_numbering': 1,\n",
       "  'nav_menu': {},\n",
       "  'number_sections': True,\n",
       "  'sideBar': True,\n",
       "  'skip_h1_title': False,\n",
       "  'title_cell': 'Table of Contents',\n",
       "  'title_sidebar': 'Contents',\n",
       "  'toc_cell': False,\n",
       "  'toc_position': {},\n",
       "  'toc_section_display': True,\n",
       "  'toc_window_display': False}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{test_nb['nbformat']}.{test_nb['nbformat_minor']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'markdown', 'metadata': {}, 'source': '# Imports'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['cells'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_nb['cells'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iter_comments()` is used to find and extract all comments from a code block.  \n",
    "It's main purpose is to avoid matching on \"comments\" that are actually just part of a string, and not real python comments. One example would be: \n",
    "\n",
    "    \"\"\"\n",
    "    # export\n",
    "    \"\"\"\n",
    "A naive parser would see the literal \"#\" and match that line. In reality however, this code snippet is a string, and might be e.g. part of a test suit (which is how this bug was found in the first place), and not really meant to be exported.  \n",
    "View https://docs.python.org/3/reference/lexical_analysis.html#strings for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# TODO(florian): Only look for 0 indent comments?\n",
    "def iter_comments(src:str, pure_comments_only:bool=True, line_limit=None):\n",
    "    \"\"\"Detect all comments in a piece of code, excluding those that are a part of a string.\"\"\"\n",
    "    in_lstr = in_sstr = False\n",
    "    count, quote = 1, ''\n",
    "    for i, line in enumerate(src.splitlines()[:line_limit]):\n",
    "        is_pure, escape, prev_c = True, False, '\\n'\n",
    "        for j, c in enumerate(line):\n",
    "            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns\n",
    "            if is_pure and (not (c.isspace() or c == '#')): is_pure = False\n",
    "            if (in_sstr or in_lstr):\n",
    "                # assert (in_sstr and not in_lstr) or (in_lstr and not in_sstr)\n",
    "                if escape: count = 0\n",
    "                else:\n",
    "                    if (c == quote):\n",
    "                        count = ((count + 1) if (c == prev_c) else 1)\n",
    "                        if in_sstr: in_sstr = False\n",
    "                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False\n",
    "                escape = False if escape else (c == '\\\\')\n",
    "            else:                    \n",
    "                if (c == '#'):\n",
    "                    if (pure_comments_only and is_pure): yield (line, (i, j))\n",
    "                    elif (not pure_comments_only):       yield (line[j:], (i, j))\n",
    "                    break\n",
    "                elif c == \"'\" or c == '\"':\n",
    "                    count = ((count + 1) if (c == prev_c) else 1)\n",
    "                    if count == 1: in_sstr = True\n",
    "                    elif count == 3: count, in_lstr = 0, True\n",
    "                    else: raise SyntaxError(f'Unexpected quote repetition count: {count} Should be either 1 or 3')\n",
    "                    quote = c\n",
    "            prev_c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "13 / 13 Correct\n"
     ]
    }
   ],
   "source": [
    "def test_iter_comments(src): return list(iter_comments(src, True))\n",
    "test_strings = [\n",
    "(\"trippe quote(''')\", \"\"\"'''\n",
    "# string\n",
    "'''\"\"\", []),\n",
    "('tripple quote(\"\"\")', '''\"\"\"\n",
    "#string\n",
    "\"\"\"''', []),\n",
    "('single quote(\")', '\"\\\n",
    "\\n#string\\n\\\n",
    "\"', []),\n",
    "(\"single quote(')\", \"'\\\n",
    "\\n#string\\n\\\n",
    "'\", []),\n",
    "(\"simple comment\", \"\"\"\n",
    "#comment\n",
    "\"\"\", [('#comment', (1, 0))]),\n",
    "(\"comment sandwich\", \"\"\"\n",
    "'this is a string'\n",
    "# this is a comment\n",
    "'another string , but between is an actual comment'\n",
    "\"\"\", [('# this is a comment', (2, 0))]),\n",
    "(\"tricky case 2\", \"\"\"\n",
    "  a #non-pure comment\n",
    "'''\n",
    "#string\n",
    "'''\n",
    "####comment\"\"\", [('####comment', (5, 0))]),\n",
    "(\"end of string quote\", \"\"\"\n",
    "'''\n",
    "'\n",
    "# still part of the string\n",
    "'\n",
    "'''\n",
    "\"\"\", []),\n",
    "(\"single end of string escape\", \"\"\"\n",
    "'\\\\'\\\\\\n#str\\\\\\n\\\\''\n",
    "\"\"\", []),\n",
    "(\"weird escape sequence\", \"\"\"\n",
    "'\\\\\\n\\\\''\n",
    "\"\"\", []),\n",
    "(\"long end of string escape\", \"\"\"\n",
    "'''\n",
    "# string\n",
    "\\\\'''\n",
    "# string\n",
    "'''\n",
    "\"\"\", []),\n",
    "(\"raw string escape\", \"\"\"\n",
    "r'''\n",
    "# string\n",
    "\\\\'''\n",
    "# string\n",
    "'''\n",
    "\"\"\", []),\n",
    "(\"multiple strings\", \"\"\"\n",
    "'''a''''''b'''\n",
    "\"\"\", []),\n",
    "]\n",
    "run_tests(test_strings, test_iter_comments, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class KeywordParser:\n",
    "    def __init__(self, *init_keywords):\n",
    "        self.parsers = {}\n",
    "        for kw in init_keywords: self.parsers[kw] = self._create_parser(kw)\n",
    "\n",
    "    def _create_parser(self, keyword):\n",
    "        # TODO: decide on the syntax\n",
    "        # TODO: Should there be any whitespace allowed before special comments?\n",
    "        # TODO: Should more than one \"#\" be allowed for special comments?\n",
    "        pattern = fr\"\"\"\n",
    "        ^              # start of line, since MULTILINE is passed\n",
    "        \\s*            # any amount of whitespace\n",
    "        \\#+\\s*          # literal \"#\", then any amount of whitespace\n",
    "        {keyword}(.*)  # keyword followed by arbitrary symbols (except new line)\n",
    "        $              # end of line, since MULTILINE is passed\n",
    "        \"\"\"\n",
    "        return re.compile(pattern, re.IGNORECASE | re.MULTILINE | re.VERBOSE)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.parsers: return self.parsers[key]\n",
    "        else:\n",
    "            parser = self._create_parser(key)\n",
    "            self.parsers[key] = parser\n",
    "            return parser\n",
    "        \n",
    "#     def _search_remove(self, key, text):\n",
    "#         print('WARNING: _search_remove() DOESN\\'T WORK YET')\n",
    "#         # TODO: This function is supposed to remove the keyword comment from the input\n",
    "#         # TODO: detect_comments() has to be modified to allow for the positions to be returned\n",
    "#         parser = self[key]\n",
    "#         text, locations = detect_comments(text)\n",
    "#         for comment, l in zip(text, locations):\n",
    "#             res = parser.search(comment)\n",
    "#             if res: return res, l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse keyword options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "OptionsTuple = namedtuple(typename='Options',\n",
    "                          field_names=['internal', 'export_target'],\n",
    "                          defaults=[False, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_re_legacy_options = re.compile(r'^(i)?\\s*([a-zA-Z0-9]+\\S*|)\\s*$')\n",
    "def legacy_parse_options(options:str) -> OptionsTuple:\n",
    "    res = _re_legacy_options.search(options)\n",
    "    if res:\n",
    "        internal, export_target = res.groups()\n",
    "        return OptionsTuple(internal=(internal == 'i'),\n",
    "                            export_target=(os.path.sep.join(export_target.split('.')) if export_target else None))\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_options(options:str, legacy:bool=True) -> OptionsTuple:\n",
    "    if (options is None) or (options == '') or (options.isspace()): return OptionsTuple()\n",
    "    else:\n",
    "        if legacy:\n",
    "            res = legacy_parse_options(options)\n",
    "            if res: return res\n",
    "            else: pass # Fall through to different parsing scheme\n",
    "        # TODO: New Syntax for specifying keyword options\n",
    "        raise NotImplementedError('this branch of parse_options() is not implemented yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## determine exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comment(source:str, loc_line:int, loc_char:int=None) -> str:\n",
    "    lines = source.splitlines()\n",
    "    if loc_char is None: lines.pop(loc_line)\n",
    "    else: lines[loc_line] = lines[loc_line][:loc_char] # pass loc_char to only remove part of the line and keep the rest\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line\n",
      "third line\n",
      "\n",
      "first line\n",
      "second\n",
      "third line\n"
     ]
    }
   ],
   "source": [
    "t = \"\"\"first line\n",
    "second line\n",
    "third line\"\"\"\n",
    "\n",
    "print(remove_comment(t, 1))\n",
    "print('')\n",
    "print(remove_comment(t, 1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "keyword_parser = KeywordParser()\n",
    "kw_export, kw_hide = keyword_parser['export'], keyword_parser['hide']\n",
    "def find_exports(cells:list, default:str, code_only:bool=True) -> list:\n",
    "    \"\"\"check for each cell if it's supposed to be exported and aggregate cell content together with export options\"\"\"\n",
    "    exports = []\n",
    "    for i, cell in enumerate(cells):\n",
    "        if code_only and (cell.cell_type != 'code'): continue\n",
    "        else:\n",
    "            source = cell.source\n",
    "            for comment, (loc_line, loc_char) in iter_comments(source):\n",
    "                res = kw_export.search(comment)\n",
    "                if res:\n",
    "                    options = parse_options(res.groups()[0])\n",
    "                    assert options.export_target or default, f'Cell nr.{i} doesn\\'t have an export target, \\\n",
    "                                                                and no default is specified:\\n{source}'\n",
    "                    if not options.export_target: options = options._replace(export_target=default)\n",
    "                    source = remove_comment(source, loc_line, None)\n",
    "                    source = re.sub(r'\\s+$', '', source, flags=re.MULTILINE)\n",
    "                    exports.append((source, options))\n",
    "                    continue\n",
    "                if kw_hide.search(comment): break\n",
    "    return exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cell_type', 'metadata', 'source'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['cells'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'markdown', 'metadata': {}, 'source': '# Imports'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['cells'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(find_exports(test_nb['cells'], 'export', code_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "9 / 9 Correct\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\n",
    "(\"trippe quote(''')\", \"\"\"'''\n",
    "#export\n",
    "'''\"\"\", []),\n",
    "('tripple quote(\"\"\")', '''\"\"\"\n",
    "#export\n",
    "\"\"\"''', []),\n",
    "('single quote(\")', '\"\\\n",
    "\\n#export\\n\\\n",
    "\"', []),\n",
    "(\"single quote(')\", \"'\\\n",
    "\\n#export\\n\\\n",
    "'\", []),\n",
    "(\"correct\", \"\"\"\n",
    "#export\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='default'))]),\n",
    "(\"tricky case 1\", \"\"\"\n",
    "'this is a string'\n",
    "#export\n",
    "'this also, but between is an actual comment'\n",
    "\"\"\", [(\"\"\"\n",
    "'this is a string'\n",
    "'this also, but between is an actual comment'\"\"\",\n",
    "OptionsTuple(internal=False, export_target='default'))]),\n",
    "(\"tricky case 2\", \"\"\"\n",
    "  a #export\n",
    "'''\n",
    "#export\n",
    "'''\n",
    "####export\"\"\", [(\"\"\"\n",
    "  a #export\n",
    "'''\n",
    "#export\n",
    "'''\"\"\", OptionsTuple(internal=False, export_target='default'))]),\n",
    "(\"tricky case 3\", \"\"\"\n",
    "'''\n",
    "'\n",
    "# export\n",
    "'\n",
    "'''\n",
    "\"\"\", []),\n",
    "(\"tricky case 4\", \"\"\"\n",
    "'''\n",
    "\\'\n",
    "# export\n",
    "\\'\n",
    "'''\n",
    "\"\"\", []),\n",
    "]\n",
    "def test_find_exports(x):\n",
    "    class y: pass\n",
    "    y.cell_type, y.source = 'code', x\n",
    "    return find_exports([y], default='default')\n",
    "run_tests(test_strings, test_find_exports, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 / 13) TEST export:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(2 / 13) TEST comment layout:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(3 / 13) TEST export internal legacy:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(4 / 13) TEST export internal legacy with target:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(5 / 13) TEST export internal:\n",
      "TEST FAILED WITH EXCEPTION:\n",
      "this branch of parse_options() is not implemented yet.\n",
      "\n",
      "(6 / 13) TEST export show source:\n",
      "TEST FAILED WITH EXCEPTION:\n",
      "this branch of parse_options() is not implemented yet.\n",
      "\n",
      "(7 / 13) TEST export internal show:\n",
      "TEST FAILED WITH EXCEPTION:\n",
      "this branch of parse_options() is not implemented yet.\n",
      "\n",
      "(8 / 13) TEST default empty:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(9 / 13) TEST hide:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(10 / 13) TEST multiple comments:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(11 / 13) TEST multiple comments other way:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(12 / 13) TEST multi comment same line:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(13 / 13) TEST multiple comments default_exp:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "10 / 13 Correct\n"
     ]
    }
   ],
   "source": [
    "test_markup = [\n",
    "('export', \"\"\"\n",
    "# export\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='default'))]),\n",
    "('comment layout', \"\"\"\n",
    "#export\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='default'))]),\n",
    "('export internal legacy', \"\"\"\n",
    "# exporti\n",
    "\"\"\", [('', OptionsTuple(internal=True, export_target='default'))]),\n",
    "('export internal legacy with target', \"\"\"\n",
    "# exporti some.module\n",
    "\"\"\", [('', OptionsTuple(internal=True, export_target='some\\\\module'))]),\n",
    "('export internal', \"\"\"\n",
    "# export -i\n",
    "\"\"\", [('', OptionsTuple(internal=True, export_target='default'))]),\n",
    "('export show source', \"\"\"\n",
    "# export -s\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='default'))]),\n",
    "('export internal show', \"\"\"\n",
    "# export -i -s\n",
    "\"\"\", [('', OptionsTuple(internal=True, export_target='default'))]),\n",
    "('default empty', \"\"\"\n",
    "\n",
    "\"\"\", []),\n",
    "('hide', \"\"\"\n",
    "# hide\n",
    "\"\"\", []),\n",
    "('multiple comments', \"\"\"\n",
    "# export\n",
    "# hide\n",
    "\"\"\", [('\\n# hide', OptionsTuple(internal=False, export_target='default'))]),\n",
    "('multiple comments other way', \"\"\"\n",
    "# hide\n",
    "# export\n",
    "\"\"\", []),\n",
    "('multi comment same line', \"\"\"\n",
    "# export hide\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='hide'))]),\n",
    "('multiple comments default_exp', \"\"\"\n",
    "# export\n",
    "# default_exp\n",
    "\"\"\", [('\\n# default_exp', OptionsTuple(internal=False, export_target='default'))]),\n",
    "]\n",
    "run_tests(test_markup, test_find_exports, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import ast\n",
    "from ast import iter_fields, AST\n",
    "import _ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is using pythons builtin ast module to parse code to be exported into an abstract syntax tree, from which the set of variable-, function-, and classnames is extracted.  \n",
    "All names found, that are not private (prefixed with a single underscore), are later added to the `__all__` in the exported file.  \n",
    "It also parses the special keyword variable `_all_` and adds all the names assigned to it in a list, tuple, set, or directly to `__all__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def unwrap_attr(node:_ast.Attribute) -> str:\n",
    "    if isinstance(node.value, _ast.Attribute): return '.'.join((unwrap_attr(node.value), node.attr))\n",
    "    else: return '.'.join((node.value.id, node.attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def update_recursive(node, names):\n",
    "    \"\"\"inplace, recursive update of names\"\"\"\n",
    "    if   isinstance(node, _ast.Name)      : names.append(node.id)\n",
    "    elif isinstance(node, _ast.Starred)   : names.append(node.value.id)\n",
    "    elif isinstance(node, _ast.Attribute) : names.append(unwrap_attr(node))\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple)):\n",
    "        for x in node.elts: update_recursive(x, names)\n",
    "    elif isinstance(node, list):\n",
    "        for x in node: update_recursive(x, names)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def update_from_all_(node, names): # TODO(florian): should all of these cases be handled?\n",
    "    \"\"\"inplace, recursive update of names, by parsing the right side of a _all_ variable\"\"\"\n",
    "    if isinstance(node, _ast.Str): names.add(node.s)\n",
    "    elif isinstance(node, _ast.Name): names.add(node.id)\n",
    "    elif isinstance(node, _ast.Attribute): names.add(unwrap_attr(node))\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "        for x in node.elts: update_from_all_(x, names)\n",
    "    elif isinstance(node, _ast.Starred): raise SyntaxError(f'Starred expression *{node.value.id} not allowed in _all_')\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def not_private(name): return not (name.startswith('_') and (not name.startswith('__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def add_names(node, names):\n",
    "    tmp_names = list()\n",
    "    update_recursive(node.targets, tmp_names)\n",
    "    for name in tmp_names:\n",
    "        if not_private(name): names.add(name)\n",
    "        # NOTE: cases below can only use private variable names\n",
    "        elif name == '_all_':\n",
    "            assert len(tmp_names) == 1, 'reserved keyword _all_ can only be used in simple assignments'\n",
    "            update_from_all_(node.value, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_names(code:str) -> list:\n",
    "    try: tree = ast.parse(code) # expensive # TODO: make this use the python version specified in config\n",
    "    except Exception as e: raise e # TODO: Logging\n",
    "    else:\n",
    "        names = set()\n",
    "        for node in tree.body:\n",
    "            if   isinstance(node, _ast.Assign): add_names(node, names)\n",
    "            elif isinstance(node, (_ast.FunctionDef, _ast.ClassDef)) and not_private(node.name): names.add(node.name)\n",
    "            else: pass\n",
    "        return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "10 / 10 Correct\n"
     ]
    }
   ],
   "source": [
    "test_assignment = [\n",
    "('Default Assignment', \"\"\"\n",
    "a = 1\n",
    "b = a\n",
    "a = 2\n",
    "\"\"\", {'a', 'b'}),\n",
    "('Tuple unpacking', \"\"\"\n",
    "a, b = (1, 2)\n",
    "\"\"\", {'a', 'b'}),\n",
    "('unpacking to tuples and lists', \"\"\"\n",
    "(a, b) = (1, 2)\n",
    "[a, b] = (1, 2)\n",
    "\"\"\", {'a', 'b'}),\n",
    "('unpacking to tuples and lists x2', \"\"\"\n",
    "([a], (b)) = (1, 2)\n",
    "[[a, ((b))]] = (1, 2)\n",
    "\"\"\", {'a', 'b'}),\n",
    "('Multiple assignments', \"\"\"\n",
    "a = b = 2\n",
    "\"\"\", {'a', 'b'}),\n",
    "('List Deconstruction', \"\"\"\n",
    "head, *tail = [1,2,3,4,5]\n",
    "\"\"\", {'head', 'tail'}),\n",
    "('Private Variables', \"\"\"\n",
    "_a = 1\n",
    "\"\"\", set()),\n",
    "('Dunder Variables', \"\"\"\n",
    "__a = 1\n",
    "\"\"\", {'__a'}),\n",
    "('Attribues', \"\"\"\n",
    "a.b = 1\n",
    "\"\"\", {'a.b'}),\n",
    "('_all_ special keyword', \"\"\"\n",
    "_all_ = {'set', '__d'}\n",
    "_all_ = ['var_a', var_b, a.b, 'c.d', _abc, '''x''']\n",
    "\"\"\", {'set', '__d', 'var_a', 'var_b', 'a.b', 'c.d', '_abc', 'x'}),\n",
    "]\n",
    "run_tests(test_assignment, find_names, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "4 / 4 Correct\n"
     ]
    }
   ],
   "source": [
    "test_funcdef = [\n",
    "('Default function definition', \"\"\"\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\"\"\", {'add'}),\n",
    "('Type Annotated function def', \"\"\"\n",
    "def calc(a:int, b:int) -> int:\n",
    "    c:float = 2.0\n",
    "    return (a + b) * c\n",
    "\"\"\", {'calc'}),\n",
    "('function decorators', \"\"\"\n",
    "@test1\n",
    "@test2\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\"\"\", {'add'}),\n",
    "('@patch and more complex type annotations', \"\"\"\n",
    "@patch\n",
    "def func (obj:(Class1, Class2), a:int)->int:\n",
    "    pass\n",
    "\"\"\", {'func'})\n",
    "]\n",
    "run_tests(test_funcdef, find_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "2 / 2 Correct\n"
     ]
    }
   ],
   "source": [
    "test_classdef = [\n",
    "('Default class definition', \"\"\"\n",
    "class Abc:\n",
    "    pass\n",
    "\"\"\", {'Abc'}),\n",
    "('Default class def 2', \"\"\"\n",
    "class Abc():\n",
    "    pass\n",
    "\"\"\", {'Abc'}),\n",
    "]\n",
    "run_tests(test_classdef, find_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used for keeping track of where each of the code cells are supposed to be exported to.  \n",
    "The `key` is the filename, `code` is a list of strings (converted code cells) that will be added to the file, and `names` is the set of names of objects that are added to `__all__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExportCache(defaultdict):\n",
    "    def __init__(self, default_export:str=None):\n",
    "        super(ExportCache, self).__init__(self._create_exp)\n",
    "        self.tupletype = namedtuple(typename='export', field_names=['code', 'names'])\n",
    "        if default_export is not None: self[default_export]\n",
    "    \n",
    "    def _create_exp(self): return self.tupletype(code=list(), names=set())\n",
    "    \n",
    "    def add_names(self, key:str, names:list): self[key].names.update(names)\n",
    "            \n",
    "    def add_code(self , key:str, code:str)  : self[key].code.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ec = ExportCache('default')\n",
    "test_ec['test']\n",
    "test_ec['abc']\n",
    "assert 'default' in test_ec\n",
    "assert 'test' in test_ec\n",
    "assert 'abc' in test_ec\n",
    "test_ec['test'].code.append('hi')\n",
    "test_ec['test'].code.append('ho')\n",
    "test_ec['test'].names.update({'nanana'})\n",
    "assert test_ec['test'].code == ['hi', 'ho']\n",
    "assert test_ec['test'].names == {'nanana'}\n",
    "assert test_ec['abc'].code == []\n",
    "assert test_ec['default'].names == set()\n",
    "test_ec.add_names('default', ['xyz', 'jkl'])\n",
    "test_ec.add_code('default', \"print('Hello World!')\")\n",
    "test_ec.add_code('default', \"print('Hello World!')\")\n",
    "assert test_ec['default'].names == {'xyz', 'jkl'}\n",
    "assert test_ec['default'].code == [\"print('Hello World!')\", \"print('Hello World!')\"]\n",
    "assert test_ec['abc'].names == set()\n",
    "test_ec.pop('default')\n",
    "assert not ('default' in test_ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_default_export(cells:list) -> str:\n",
    "    # search through all cells to find the default_exp keyword and return it's value.\n",
    "    # syntax checking\n",
    "    # maybe do some sanity checking\n",
    "    default = 'export'\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_mod_file(orig_nbfname, targ_pyfname):\n",
    "    # create the .py file in the correct folder, with a header saying where it was originally from\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _notebook2script(fname=None, cells=None, silent=False, to_dict=False):\n",
    "    \"\"\"Convert a single notebook\"\"\"\n",
    "    fname = Path(fname)\n",
    "    assert (fname and not cells) or (not fname and cells)\n",
    "    if not cells: # TODO(florian): this is temporarily used for testing, remove this\n",
    "        nb = read_nb(fname)\n",
    "        cells = nb['cells']\n",
    "        \n",
    "    sep = '\\n' * (max(int(Config().get('cell_spacing', 1)), 0) + 1)\n",
    "    \n",
    "    default = find_default_export(cells)\n",
    "    if default is None:\n",
    "        print('WARNING: No default export target found! (should this crash, or see if each export has its own target?)')\n",
    "        raise NotImplementedError('Not specifying a default export is not supported yet.')\n",
    "    else:\n",
    "        default = os.path.sep.join(default.split('.'))\n",
    "        ec = ExportCache(default)\n",
    "        # TODO(florian): create_mod_file(original_nbfile_path, target_pyfile_path) # args flipped in original code\n",
    "        pass\n",
    "    # TODO(florian): load _nbdev file and create a spec from it (no idea why this is needed)\n",
    "    \n",
    "    exports = find_exports(cells, default)\n",
    "    for j, (code, options)  in enumerate(exports):\n",
    "        # code = clean_code(code)\n",
    "        # TODO: make imports of the current project relative in the output code\n",
    "        i, e = options.internal, options.export_target\n",
    "        if not i: ec.add_names(e, find_names(code))\n",
    "        orig = (('Internal C' if i else '# C') if e==default else f'# Comes from {fname.name}, c') + 'ell\\n'\n",
    "        ec.add_code(e, (sep + orig + code))\n",
    "        \n",
    "    for e, s in ec.items():\n",
    "        fname_out = Config().lib_path/f'{e}.py'\n",
    "        nb_path = Config().nbs_path/f'{fname}'\n",
    "        config_path = Config().config_file.parent\n",
    "        rel_nb_path = os.path.relpath(nb_path, config_path).replace('\\\\', '/')\n",
    "        fname_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {rel_nb_path} (unless otherwise specified).'\n",
    "        names = sep + \"__all__ = ['\" + \"', '\".join(s.names) + \"']\" # TODO(florian): add line breaks at regular intervals\n",
    "        code  = ''.join(s.code)\n",
    "        file_content = warning + names + code\n",
    "        if e == default:\n",
    "            with open(fname_out, 'w', encoding='utf8') as f: f.write(file_content)\n",
    "        else: raise NotImplementedError('Exporting to a module other than the default is not supported yet.')\n",
    "    # TODO(florian): add names to _nbdev index\n",
    "    # TODO(florian): write code cell to file\n",
    "    # TODO(florian): save _nbdev file\n",
    "    return ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if default in exports:\n",
    "#     write_file(exports.pop(default))\n",
    "# return exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(florian): initialize the library with __init__.py (and other stuff it needs?) if it doesn't already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = _notebook2script(\n",
    "    fname='00_export.ipynb',\n",
    "    # cells=test_nb['cells']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev_rewrite.export import _notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = _notebook2script(\n",
    "    fname='00_export.ipynb',\n",
    "    # cells=test_nb['cells']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(florian): do a copy-rename swap, to prevent corruption of files in case of failure\n",
    "# with safe_replace('export.py') as f:\n",
    "#     f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def notebook2script(fname=None, silent=False, to_dict=False):\n",
    "    \"Convert notebooks matching `fname` to modules\"\n",
    "    # initial checks\n",
    "    if os.environ.get('IN_TEST',0): return  # don't export if running tests\n",
    "    if fname is None:\n",
    "        reset_nbdev_module()\n",
    "        update_version()\n",
    "        update_baseurl()\n",
    "        files = [f for f in Config().nbs_path.glob('*.ipynb') if not f.name.startswith('_')]\n",
    "    else: files = glob.glob(fname)\n",
    "    d = collections.defaultdict(list) if to_dict else None\n",
    "    for f in sorted(files): d = _notebook2script(f, silent=silent, to_dict=d)\n",
    "    if to_dict: return d\n",
    "    else: add_init(Config().lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
