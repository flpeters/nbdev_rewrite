{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from collections import namedtuple, defaultdict\n",
    "import os\n",
    "import re\n",
    "from nbdev_rewrite.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "def run_tests(cases, func, verbose=False):\n",
    "    \"\"\"Run test cases by passing a list of tuples (test name, input to func, expected result)\"\"\"\n",
    "    nr_correct = 0\n",
    "    for i, (n, c, r) in enumerate(cases):\n",
    "        if verbose: print(f'({i + 1} / {len(cases)}) TEST {n}:')\n",
    "        try:\n",
    "            res = func(c)\n",
    "            assert res == r, f'TEST FAILED WITH RESULT: {res}\\nEXPECTED: {r}'\n",
    "            nr_correct += (res == r)\n",
    "            if verbose: print(f'TEST RESULT: SUCCESS\\n')\n",
    "        except Exception as e:\n",
    "            if verbose: print(f'TEST FAILED WITH EXCEPTION:\\n{e}\\n')\n",
    "            # raise e\n",
    "    print('--------------- ALL TESTS COMPLETED ---------------')\n",
    "    print(f'{nr_correct} / {len(cases)} Correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Context:\n",
    "    def __init__(self, cell_nr=None, export_nr=None):\n",
    "        self.cell_nr = cell_nr\n",
    "        self.export_nr = export_nr\n",
    "    def __repr__(self):\n",
    "        return f'cell_nr: {self.cell_nr}, export_nr: {self.export_nr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_config('nbdev_rewrite', 'flpeters', nbs_path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_nb(fname):\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return nbformat.reads(f.read(), as_version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = read_nb('00_export.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cells', 'metadata', 'nbformat', 'nbformat_minor'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernelspec': {'display_name': 'Python 3',\n",
       "  'language': 'python',\n",
       "  'name': 'python3'},\n",
       " 'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "  'file_extension': '.py',\n",
       "  'mimetype': 'text/x-python',\n",
       "  'name': 'python',\n",
       "  'nbconvert_exporter': 'python',\n",
       "  'pygments_lexer': 'ipython3',\n",
       "  'version': '3.7.6'},\n",
       " 'toc': {'base_numbering': 1,\n",
       "  'nav_menu': {},\n",
       "  'number_sections': True,\n",
       "  'sideBar': True,\n",
       "  'skip_h1_title': False,\n",
       "  'title_cell': 'Table of Contents',\n",
       "  'title_sidebar': 'Contents',\n",
       "  'toc_cell': False,\n",
       "  'toc_position': {},\n",
       "  'toc_section_display': True,\n",
       "  'toc_window_display': False}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{test_nb['nbformat']}.{test_nb['nbformat_minor']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'markdown', 'metadata': {}, 'source': '# Imports'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['cells'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_nb['cells'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iter_comments()` is used to find and extract all comments from a code block.  \n",
    "It's main purpose is to avoid matching on \"comments\" that are actually just part of a string, and not real python comments. One example would be: \n",
    "\n",
    "    \"\"\"\n",
    "    # export\n",
    "    \"\"\"\n",
    "A naive parser would see the literal \"#\" and match that line. In reality however, this code snippet is a string, and might be e.g. part of a test suit (which is how this bug was found in the first place), and not really meant to be exported.  \n",
    "View https://docs.python.org/3/reference/lexical_analysis.html#strings for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# TODO(florian): Only look for 0 indent comments?\n",
    "def iter_comments(src:str, cell_nr:int, pure_comments_only:bool=True, line_limit=None):\n",
    "    \"\"\"Detect all comments in a piece of code, excluding those that are a part of a string.\"\"\"\n",
    "    in_lstr = in_sstr = False\n",
    "    count, quote = 1, ''\n",
    "    for i, line in enumerate(src.splitlines()[:line_limit]):\n",
    "        is_pure, escape, prev_c = True, False, '\\n'\n",
    "        for j, c in enumerate(line):\n",
    "            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns\n",
    "            if is_pure and (not (c.isspace() or c == '#')): is_pure = False\n",
    "            if (in_sstr or in_lstr):\n",
    "                # assert (in_sstr and not in_lstr) or (in_lstr and not in_sstr)\n",
    "                if escape: count = 0\n",
    "                else:\n",
    "                    if (c == quote):\n",
    "                        count = ((count + 1) if (c == prev_c) else 1)\n",
    "                        if in_sstr: in_sstr = False\n",
    "                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False\n",
    "                escape = False if escape else (c == '\\\\')\n",
    "            else:                    \n",
    "                if (c == '#'):\n",
    "                    if (pure_comments_only and is_pure): yield (line, (i, j))\n",
    "                    elif (not pure_comments_only):       yield (line[j:], (i, j))\n",
    "                    break\n",
    "                elif c == \"'\" or c == '\"':\n",
    "                    count = ((count + 1) if (c == prev_c) else 1)\n",
    "                    if count == 1: in_sstr = True\n",
    "                    elif count == 3: count, in_lstr = 0, True\n",
    "                    else: raise SyntaxError(f'Unexpected quote repetition count: {count} Should be either 1 or 3. Cell_nr: {cell_nr} Line:{i}/{j}')\n",
    "                    quote = c\n",
    "            prev_c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "13 / 13 Correct\n"
     ]
    }
   ],
   "source": [
    "def test_iter_comments(src): return list(iter_comments(src, 1, True))\n",
    "test_strings = [\n",
    "(\"trippe quote(''')\", \"\"\"'''\n",
    "# string\n",
    "'''\"\"\", []),\n",
    "('tripple quote(\"\"\")', '''\"\"\"\n",
    "#string\n",
    "\"\"\"''', []),\n",
    "('single quote(\")', '\"\\\n",
    "\\n#string\\n\\\n",
    "\"', []),\n",
    "(\"single quote(')\", \"'\\\n",
    "\\n#string\\n\\\n",
    "'\", []),\n",
    "(\"simple comment\", \"\"\"\n",
    "#comment\n",
    "\"\"\", [('#comment', (1, 0))]),\n",
    "(\"comment sandwich\", \"\"\"\n",
    "'this is a string'\n",
    "# this is a comment\n",
    "'another string , but between is an actual comment'\n",
    "\"\"\", [('# this is a comment', (2, 0))]),\n",
    "(\"tricky case 2\", \"\"\"\n",
    "  a #non-pure comment\n",
    "'''\n",
    "#string\n",
    "'''\n",
    "####comment\"\"\", [('####comment', (5, 0))]),\n",
    "(\"end of string quote\", \"\"\"\n",
    "'''\n",
    "'\n",
    "# still part of the string\n",
    "'\n",
    "'''\n",
    "\"\"\", []),\n",
    "(\"single end of string escape\", \"\"\"\n",
    "'\\\\'\\\\\\n#str\\\\\\n\\\\''\n",
    "\"\"\", []),\n",
    "(\"weird escape sequence\", \"\"\"\n",
    "'\\\\\\n\\\\''\n",
    "\"\"\", []),\n",
    "(\"long end of string escape\", \"\"\"\n",
    "'''\n",
    "# string\n",
    "\\\\'''\n",
    "# string\n",
    "'''\n",
    "\"\"\", []),\n",
    "(\"raw string escape\", \"\"\"\n",
    "r'''\n",
    "# string\n",
    "\\\\'''\n",
    "# string\n",
    "'''\n",
    "\"\"\", []),\n",
    "(\"multiple strings\", \"\"\"\n",
    "'''a''''''b'''\n",
    "\"\"\", []),\n",
    "]\n",
    "run_tests(test_strings, test_iter_comments, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class KeywordParser:\n",
    "    def __init__(self, *init_keywords):\n",
    "        self.parsers = {}\n",
    "        for kw in init_keywords: self.parsers[kw] = self._create_parser(kw)\n",
    "\n",
    "    def _create_parser(self, keyword):\n",
    "        # TODO: decide on the syntax\n",
    "        # TODO: Should there be any whitespace allowed before special comments?\n",
    "        # TODO: Should more than one \"#\" be allowed for special comments?\n",
    "        pattern = fr\"\"\"\n",
    "        ^              # start of line, since MULTILINE is passed\n",
    "        \\s*            # any amount of whitespace\n",
    "        \\#+\\s*          # literal \"#\", then any amount of whitespace\n",
    "        {keyword}(.*)  # keyword followed by arbitrary symbols (except new line)\n",
    "        $              # end of line, since MULTILINE is passed\n",
    "        \"\"\"\n",
    "        return re.compile(pattern, re.IGNORECASE | re.MULTILINE | re.VERBOSE)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.parsers: return self.parsers[key]\n",
    "        else:\n",
    "            parser = self._create_parser(key)\n",
    "            self.parsers[key] = parser\n",
    "            return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse keyword options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "OptionsTuple = namedtuple(typename='Options',\n",
    "                          field_names=['internal', 'export_target'],\n",
    "                          defaults=[False, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_re_legacy_options = re.compile(r'^(i)?\\s*([a-zA-Z0-9]+\\S*|)\\s*$')\n",
    "def legacy_parse_options(options:str) -> OptionsTuple:\n",
    "    res = _re_legacy_options.search(options)\n",
    "    if res:\n",
    "        internal, export_target = res.groups()\n",
    "        return OptionsTuple(internal=(internal == 'i'),\n",
    "                            export_target=(os.path.sep.join(export_target.split('.')) if export_target else None))\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_options(options:str, legacy:bool=True) -> OptionsTuple:\n",
    "    if (options is None) or (options == '') or (options.isspace()): return OptionsTuple()\n",
    "    else:\n",
    "        if legacy:\n",
    "            res = legacy_parse_options(options)\n",
    "            if res: return res\n",
    "            else: pass # Fall through to different parsing scheme\n",
    "        # TODO: New Syntax for specifying keyword options\n",
    "        raise NotImplementedError(f'this branch of parse_options() is not implemented yet. you typed: {options}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the line that contains the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def remove_comment(source:str, loc_line:int, loc_char:int=None) -> str:\n",
    "    lines = source.splitlines()\n",
    "    if loc_char is None: lines.pop(loc_line)\n",
    "    else: lines[loc_line] = lines[loc_line][:loc_char] # pass loc_char to only remove part of the line and keep the rest\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line\n",
      "third line\n",
      "\n",
      "first line\n",
      "second\n",
      "third line\n"
     ]
    }
   ],
   "source": [
    "t = \"\"\"first line\n",
    "second line\n",
    "third line\"\"\"\n",
    "\n",
    "print(remove_comment(t, 1))\n",
    "print('')\n",
    "print(remove_comment(t, 1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting absolute imports to relative imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "def relative_import(name, fname):\n",
    "    \"Convert a module `name` to a name relative to `fname`\"\n",
    "    mods = name.split('.')\n",
    "    splits = str(fname).split(os.path.sep)\n",
    "    if mods[0] not in splits: return name\n",
    "    i=len(splits)-1\n",
    "    while i>0 and splits[i] != mods[0]: i-=1\n",
    "    splits = splits[i:]\n",
    "    while len(mods)>0 and splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]\n",
    "    return '.' * (len(splits)) + '.'.join(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "_re_import = ReLibName(r'^(\\s*)from (LIB_NAME\\.\\S*) import (.*)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _deal_import(code_lines, fname):\n",
    "    def _replace(m):\n",
    "        sp,mod,obj = m.groups()\n",
    "        return f'{sp}from {relative_import(mod, fname)} import {obj}'\n",
    "    return [_re_import.re.sub(_replace,line) for line in code_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import numpy\n",
      "import nbdev_rewrite\n",
      "from nbdev_rewrite import *\n",
      "from .core import *\n",
      "from .export import *\n",
      "from .export import test\n",
      "from .core.export import *\n",
      "from .export.core import *\n",
      "a = 1\n",
      "def add(x, y):\n",
      "    return x + y\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "import numpy\n",
    "import nbdev_rewrite\n",
    "from nbdev_rewrite import *\n",
    "from nbdev_rewrite.core import *\n",
    "from nbdev_rewrite.export import *\n",
    "from nbdev_rewrite.export import test\n",
    "from nbdev_rewrite.core.export import *\n",
    "from nbdev_rewrite.export.core import *\n",
    "a = 1\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\"\"\"\n",
    "fname = Config().lib_path/f'export.py'\n",
    "print('\\n'.join(_deal_import(s.splitlines(), fname=fname)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## determine exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "keyword_parser = KeywordParser()\n",
    "kw_export, kw_hide = keyword_parser['export'], keyword_parser['hide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_exports(cells:list, default:str, code_only:bool=True) -> list:\n",
    "    \"\"\"check for each cell if it's supposed to be exported and aggregate cell content together with export options\"\"\"\n",
    "    exports = []\n",
    "    for i, cell in enumerate(cells):\n",
    "        if code_only and (cell.cell_type != 'code'): continue\n",
    "        else:\n",
    "            source = cell.source\n",
    "            for comment, (loc_line, loc_char) in iter_comments(source, cell_nr=i):\n",
    "                res = kw_export.search(comment)\n",
    "                if res:\n",
    "                    options = parse_options(res.groups()[0])\n",
    "                    if not (options.export_target or default): raise SyntaxError(f'Cell nr.{i} doesn\\'t have an export target, \\\n",
    "                                                                                    and no default is specified.')\n",
    "                    if not options.export_target: options = options._replace(export_target=default)\n",
    "                    source = remove_comment(source, loc_line, None)\n",
    "                    # source = re.sub(r'\\s+$', '', source, flags=re.MULTILINE) # remove whitespace at the end of each line\n",
    "                    exports.append((source, options, Context(cell_nr=i)))\n",
    "                    continue\n",
    "                if kw_hide.search(comment): break\n",
    "    return exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cell_type', 'metadata', 'source'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['cells'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'markdown', 'metadata': {}, 'source': '# Imports'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['cells'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(find_exports(test_nb['cells'], 'export', code_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "9 / 9 Correct\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\n",
    "(\"trippe quote(''')\", \"\"\"'''\n",
    "#export\n",
    "'''\"\"\", []),\n",
    "('tripple quote(\"\"\")', '''\"\"\"\n",
    "#export\n",
    "\"\"\"''', []),\n",
    "('single quote(\")', '\"\\\n",
    "\\n#export\\n\\\n",
    "\"', []),\n",
    "(\"single quote(')\", \"'\\\n",
    "\\n#export\\n\\\n",
    "'\", []),\n",
    "(\"correct\", \"\"\"\n",
    "#export\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='default'))]),\n",
    "(\"tricky case 1\", \"\"\"\n",
    "'this is a string'\n",
    "#export\n",
    "'this also, but between is an actual comment'\n",
    "\"\"\", [(\"\"\"\n",
    "'this is a string'\n",
    "'this also, but between is an actual comment'\"\"\",\n",
    "OptionsTuple(internal=False, export_target='default'))]),\n",
    "(\"tricky case 2\", \"\"\"\n",
    "  a #export\n",
    "'''\n",
    "#export\n",
    "'''\n",
    "####export\"\"\", [(\"\"\"\n",
    "  a #export\n",
    "'''\n",
    "#export\n",
    "'''\"\"\", OptionsTuple(internal=False, export_target='default'))]),\n",
    "(\"tricky case 3\", \"\"\"\n",
    "'''\n",
    "'\n",
    "# export\n",
    "'\n",
    "'''\n",
    "\"\"\", []),\n",
    "(\"tricky case 4\", \"\"\"\n",
    "'''\n",
    "\\'\n",
    "# export\n",
    "\\'\n",
    "'''\n",
    "\"\"\", []),\n",
    "]\n",
    "def test_find_exports(x):\n",
    "    class y: pass\n",
    "    y.cell_type, y.source = 'code', x\n",
    "    return [(z[0], z[1]) for z in find_exports([y], default='default')]\n",
    "run_tests(test_strings, test_find_exports, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "10 / 13 Correct\n"
     ]
    }
   ],
   "source": [
    "test_markup = [\n",
    "('export', \"\"\"\n",
    "# export\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='default'))]),\n",
    "('comment layout', \"\"\"\n",
    "#export\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='default'))]),\n",
    "('export internal legacy', \"\"\"\n",
    "# exporti\n",
    "\"\"\", [('', OptionsTuple(internal=True, export_target='default'))]),\n",
    "('export internal legacy with target', \"\"\"\n",
    "# exporti some.module\n",
    "\"\"\", [('', OptionsTuple(internal=True, export_target='some\\\\module'))]),\n",
    "('export internal', \"\"\"\n",
    "# export -i\n",
    "\"\"\", [('', OptionsTuple(internal=True, export_target='default'))]),\n",
    "('export show source', \"\"\"\n",
    "# export -s\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='default'))]),\n",
    "('export internal show', \"\"\"\n",
    "# export -i -s\n",
    "\"\"\", [('', OptionsTuple(internal=True, export_target='default'))]),\n",
    "('default empty', \"\"\"\n",
    "\n",
    "\"\"\", []),\n",
    "('hide', \"\"\"\n",
    "# hide\n",
    "\"\"\", []),\n",
    "('multiple comments', \"\"\"\n",
    "# export\n",
    "# hide\n",
    "\"\"\", [('\\n# hide', OptionsTuple(internal=False, export_target='default'))]),\n",
    "('multiple comments other way', \"\"\"\n",
    "# hide\n",
    "# export\n",
    "\"\"\", []),\n",
    "('multi comment same line', \"\"\"\n",
    "# export hide\n",
    "\"\"\", [('', OptionsTuple(internal=False, export_target='hide'))]),\n",
    "('multiple comments default_exp', \"\"\"\n",
    "# export\n",
    "# default_exp\n",
    "\"\"\", [('\\n# default_exp', OptionsTuple(internal=False, export_target='default'))]),\n",
    "]\n",
    "run_tests(test_markup, test_find_exports, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import ast\n",
    "from ast import iter_fields, AST\n",
    "import _ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is using pythons builtin ast module to parse code to be exported into an abstract syntax tree, from which the set of variable-, function-, and classnames is extracted.  \n",
    "All names found, that are not private (prefixed with a single underscore), are later added to the `__all__` in the exported file.  \n",
    "It also parses the special keyword variable `_all_` and adds all the names assigned to it in a list, tuple, set, or directly to `__all__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def lineno(node):\n",
    "    if hasattr(node, 'lineno') and hasattr(node, 'col_offset'):\n",
    "        return f'line_nr: {node.lineno} col_offset: {node.col_offset}'\n",
    "    else: return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def info(context, node):\n",
    "    return f'\\nLocation: {context} | {lineno(node)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def unwrap_attr(node:_ast.Attribute) -> str:\n",
    "    if isinstance(node.value, _ast.Attribute): return '.'.join((unwrap_attr(node.value), node.attr))\n",
    "    else: return '.'.join((node.value.id, node.attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def unwrap_assign(node, names, c):\n",
    "    \"\"\"inplace, recursive update of list of names\"\"\"\n",
    "    if   isinstance(node, _ast.Name)      : names.append(node.id)\n",
    "    elif isinstance(node, _ast.Starred)   : names.append(node.value.id)\n",
    "    elif isinstance(node, _ast.Attribute) : names.append(unwrap_attr(node))\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple)):\n",
    "        for x in node.elts: unwrap_assign(x, names, c)\n",
    "    elif isinstance(node, list):\n",
    "        for x in node: unwrap_assign(x, names, c)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type. {info(c, node)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def update_from_all_(node, names, c): # TODO: should all of these cases be handled, or just always expect a string?\n",
    "    \"\"\"inplace, recursive update of set of names, by parsing the right side of a _all_ variable\"\"\"\n",
    "    if   isinstance(node, _ast.Str): names.add(node.s)\n",
    "    elif isinstance(node, _ast.Name): names.add(node.id)\n",
    "    elif isinstance(node, _ast.Attribute): names.add(unwrap_attr(node))\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "        for x in node.elts: update_from_all_(x, names, c)\n",
    "    elif isinstance(node, _ast.Starred):\n",
    "        raise SyntaxError(f'Starred expression *{node.value.id} not allowed in _all_. {info(c, node)}')\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type. {info(c, node)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def not_private(name): return not (name.startswith('_') and (not name.startswith('__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def add_names_A(node, names, c):\n",
    "    tmp_names = list()\n",
    "    unwrap_assign(node.targets, tmp_names, c)\n",
    "    for name in tmp_names:\n",
    "        if not_private(name): names.add(name)\n",
    "        # NOTE: cases below can only use private variable names\n",
    "        elif name == '_all_':\n",
    "            if len(tmp_names) != 1:\n",
    "                raise SyntaxError(f'Reserved keyword \"_all_\" can only be used in simple assignments. {info(c, node)}')\n",
    "            update_from_all_(node.value, names, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fastai_patch(cls, node, names, c):\n",
    "    if   isinstance(cls, _ast.Name):\n",
    "        if not_private(cls.id): names.add(f'{cls.id}.{node.name}')\n",
    "    elif isinstance(cls, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "            for x in cls.elts: fastai_patch(x, node, names, c)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {cls} to @patch annotation, unknown type. {info(c, node)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def add_names_FC(node, names, c, fastai_decorators=True):\n",
    "    if fastai_decorators and ('patch' in [d.id for d in node.decorator_list]):\n",
    "        if not (len(node.args.args) >= 1): raise SyntaxError(f'fastai\\'s @patch decorator requires at least one parameter. {info(c, node)}')\n",
    "        cls = node.args.args[0].annotation\n",
    "        if cls is None: raise SyntaxError(f'fastai\\'s @patch decorator requires a type annotation on the first parameter. {info(c, node)}')\n",
    "        fastai_patch(cls, node, names, c)\n",
    "    elif fastai_decorators and ('typedispatch' in [d.id for d in node.decorator_list]): return # ignore @typedispatch\n",
    "    elif not_private(node.name): names.add(node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_names(code:str, context:Context=None) -> list:\n",
    "    tree = ast.parse(code)\n",
    "    names = set()\n",
    "    for node in tree.body:\n",
    "        if   isinstance(node, _ast.Assign): add_names_A(node, names, context)\n",
    "        elif isinstance(node, (_ast.FunctionDef, _ast.ClassDef)): add_names_FC(node, names, context)\n",
    "        else: pass\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 / 10) TEST Default Assignment:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(2 / 10) TEST Tuple unpacking:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(3 / 10) TEST unpacking to tuples and lists:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(4 / 10) TEST unpacking to tuples and lists x2:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(5 / 10) TEST Multiple assignments:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(6 / 10) TEST List Deconstruction:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(7 / 10) TEST Private Variables:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(8 / 10) TEST Dunder Variables:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(9 / 10) TEST Attribues:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "(10 / 10) TEST _all_ special keyword:\n",
      "TEST RESULT: SUCCESS\n",
      "\n",
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "10 / 10 Correct\n"
     ]
    }
   ],
   "source": [
    "test_assignment = [\n",
    "('Default Assignment', \"\"\"\n",
    "a = 1\n",
    "b = a\n",
    "a = 2\n",
    "\"\"\", {'a', 'b'}),\n",
    "('Tuple unpacking', \"\"\"\n",
    "a, b = (1, 2)\n",
    "\"\"\", {'a', 'b'}),\n",
    "('unpacking to tuples and lists', \"\"\"\n",
    "(a, b) = (1, 2)\n",
    "[a, b] = (1, 2)\n",
    "\"\"\", {'a', 'b'}),\n",
    "('unpacking to tuples and lists x2', \"\"\"\n",
    "([a], (b)) = (1, 2)\n",
    "[[a, ((b))]] = (1, 2)\n",
    "\"\"\", {'a', 'b'}),\n",
    "('Multiple assignments', \"\"\"\n",
    "a = b = 2\n",
    "\"\"\", {'a', 'b'}),\n",
    "('List Deconstruction', \"\"\"\n",
    "head, *tail = [1,2,3,4,5]\n",
    "\"\"\", {'head', 'tail'}),\n",
    "('Private Variables', \"\"\"\n",
    "_a = 1\n",
    "\"\"\", set()),\n",
    "('Dunder Variables', \"\"\"\n",
    "__a = 1\n",
    "\"\"\", {'__a'}),\n",
    "('Attribues', \"\"\"\n",
    "a.b = 1\n",
    "\"\"\", {'a.b'}),\n",
    "('_all_ special keyword', \"\"\"\n",
    "_all_ = {'set', '__d'}\n",
    "_all_ = ['var_a', var_b, a.b, 'c.d', _abc, '''x''']\n",
    "\"\"\", {'set', '__d', 'var_a', 'var_b', 'a.b', 'c.d', '_abc', 'x'}),\n",
    "]\n",
    "run_tests(test_assignment, find_names, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "7 / 7 Correct\n"
     ]
    }
   ],
   "source": [
    "test_funcdef = [\n",
    "('Default function definition', \"\"\"\n",
    "def say_hello():\n",
    "    print('hi')\n",
    "\"\"\", {'say_hello'}),\n",
    "('Default function definition', \"\"\"\n",
    "def no_op(a):\n",
    "    return a\n",
    "\"\"\", {'no_op'}),\n",
    "('Two args function definition', \"\"\"\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\"\"\", {'add'}),\n",
    "('Type Annotated function def', \"\"\"\n",
    "def calc(a:int, b:int) -> int:\n",
    "    c:float = 2.0\n",
    "    return (a + b) * c\n",
    "\"\"\", {'calc'}),\n",
    "('function decorators', \"\"\"\n",
    "@test1\n",
    "@test2\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\"\"\", {'add'}),\n",
    "('@patch handling', \"\"\"\n",
    "@patch\n",
    "def func (a:Class1, b:Class2)->int:\n",
    "    pass\n",
    "\"\"\", {'Class1.func'}),\n",
    "('@patch and more complex type annotations', \"\"\"\n",
    "@patch\n",
    "def func (a:(Class1, Class2, _Class3), b:int)->int:\n",
    "    pass\n",
    "\"\"\", {'Class1.func', 'Class2.func'})\n",
    "]\n",
    "run_tests(test_funcdef, find_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ALL TESTS COMPLETED ---------------\n",
      "2 / 2 Correct\n"
     ]
    }
   ],
   "source": [
    "test_classdef = [\n",
    "('Default class definition', \"\"\"\n",
    "class Abc:\n",
    "    pass\n",
    "\"\"\", {'Abc'}),\n",
    "('Default class def 2', \"\"\"\n",
    "class Abc():\n",
    "    pass\n",
    "\"\"\", {'Abc'}),\n",
    "]\n",
    "run_tests(test_classdef, find_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used for keeping track of where each of the code cells are supposed to be exported to.  \n",
    "The `key` is the filename, `code` is a list of strings (converted code cells) that will be added to the file, and `names` is the set of names of objects that are added to `__all__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExportCache(defaultdict):\n",
    "    def __init__(self, default_export:str=None):\n",
    "        super(ExportCache, self).__init__(self._create_exp)\n",
    "        self.tupletype = namedtuple(typename='export', field_names=['code', 'names'])\n",
    "        if default_export is not None: self[default_export]\n",
    "    \n",
    "    def _create_exp(self): return self.tupletype(code=list(), names=set())\n",
    "    \n",
    "    def add_names(self, key:str, names:list): self[key].names.update(names)\n",
    "            \n",
    "    def add_code(self , key:str, code:str)  : self[key].code.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ec = ExportCache('default')\n",
    "test_ec['test']\n",
    "test_ec['abc']\n",
    "assert 'default' in test_ec\n",
    "assert 'test' in test_ec\n",
    "assert 'abc' in test_ec\n",
    "test_ec['test'].code.append('hi')\n",
    "test_ec['test'].code.append('ho')\n",
    "test_ec['test'].names.update({'nanana'})\n",
    "assert test_ec['test'].code == ['hi', 'ho']\n",
    "assert test_ec['test'].names == {'nanana'}\n",
    "assert test_ec['abc'].code == []\n",
    "assert test_ec['default'].names == set()\n",
    "test_ec.add_names('default', ['xyz', 'jkl'])\n",
    "test_ec.add_code('default', \"print('Hello World!')\")\n",
    "test_ec.add_code('default', \"print('Hello World!')\")\n",
    "assert test_ec['default'].names == {'xyz', 'jkl'}\n",
    "assert test_ec['default'].code == [\"print('Hello World!')\", \"print('Hello World!')\"]\n",
    "assert test_ec['abc'].names == set()\n",
    "test_ec.pop('default')\n",
    "assert not ('default' in test_ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_default_export(cells:list) -> str:\n",
    "    # search through all cells to find the default_exp keyword and return it's value.\n",
    "    # syntax checking\n",
    "    # maybe do some sanity checking\n",
    "    default = 'export'\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_mod_file(orig_nbfname, targ_pyfname):\n",
    "    # create the .py file in the correct folder, with a header saying where it was originally from\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _notebook2script(fname=None, cells=None, silent=False, to_dict=False):\n",
    "    \"\"\"Convert a single notebook\"\"\"\n",
    "    fname = Path(fname)\n",
    "    assert (fname and not cells) or (not fname and cells)\n",
    "    if not cells: # TODO(florian): this is temporarily used for testing, remove this\n",
    "        nb = read_nb(fname)\n",
    "        cells = nb['cells']\n",
    "        \n",
    "    sep = '\\n' * (max(int(Config().get('cell_spacing', 1)), 0) + 1)\n",
    "    \n",
    "    default = find_default_export(cells)\n",
    "    if default is None:\n",
    "        print('WARNING: No default export target found! (should this crash, or see if each export has its own target?)')\n",
    "        raise NotImplementedError('Not specifying a default export is not supported yet.')\n",
    "    else:\n",
    "        default = os.path.sep.join(default.split('.'))\n",
    "        ec = ExportCache(default)\n",
    "        # TODO(florian): create_mod_file(original_nbfile_path, target_pyfile_path) # args flipped in original code\n",
    "        pass\n",
    "    # TODO(florian): load _nbdev file and create a spec from it (no idea why this is needed)\n",
    "    \n",
    "    exports = find_exports(cells, default)\n",
    "    for export_nr, (code, options, context)  in enumerate(exports):\n",
    "        context.export_nr = export_nr\n",
    "        # code = clean_code(code)\n",
    "        # TODO: make imports of the current project relative in the output code\n",
    "        i, e = options.internal, options.export_target\n",
    "        if not i: ec.add_names(e, find_names(code, context))\n",
    "        orig = (('Internal C' if i else '# C') if e==default else f'# Comes from {fname.name}, c') + 'ell\\n'\n",
    "        ec.add_code(e, (sep + orig + code))\n",
    "        \n",
    "    for e, s in ec.items():\n",
    "        fname_out   = Config().lib_path/f'{e}.py'\n",
    "        nb_path     = Config().nbs_path/f'{fname}'\n",
    "        config_path = Config().config_file.parent\n",
    "        rel_nb_path = os.path.relpath(nb_path, config_path).replace('\\\\', '/')\n",
    "        warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {rel_nb_path} (unless otherwise specified).'\n",
    "        names = sep + \"__all__ = ['\" + \"', '\".join(s.names) + \"']\" # TODO(florian): add line breaks at regular intervals\n",
    "        code  = ''.join(s.code)\n",
    "        file_content = warning + names + code\n",
    "        if e == default:\n",
    "            fname_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with open(fname_out, 'w', encoding='utf8') as f: f.write(file_content)\n",
    "        else: raise NotImplementedError('Exporting to a module other than the default is not supported yet.')\n",
    "    # TODO(florian): add names to _nbdev index\n",
    "    # TODO(florian): write code cell to file\n",
    "    # TODO(florian): save _nbdev file\n",
    "    return ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if default in exports:\n",
    "#     write_file(exports.pop(default))\n",
    "# return exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(florian): initialize the library with __init__.py (and other stuff it needs?) if it doesn't already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = _notebook2script(\n",
    "    fname='00_export.ipynb',\n",
    "    # cells=test_nb['cells']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev_rewrite.export import _notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = _notebook2script(\n",
    "    fname='00_export.ipynb',\n",
    "    # cells=test_nb['cells']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(florian): do a copy-rename swap, to prevent corruption of files in case of failure\n",
    "# with safe_replace('export.py') as f:\n",
    "#     f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def notebook2script(fname=None, silent=False, to_dict=False):\n",
    "    \"Convert notebooks matching `fname` to modules\"\n",
    "    # initial checks\n",
    "    if os.environ.get('IN_TEST',0): return  # don't export if running tests\n",
    "    if fname is None:\n",
    "        reset_nbdev_module()\n",
    "        update_version()\n",
    "        update_baseurl()\n",
    "        files = [f for f in Config().nbs_path.glob('*.ipynb') if not f.name.startswith('_')]\n",
    "    else: files = glob.glob(fname)\n",
    "    d = collections.defaultdict(list) if to_dict else None\n",
    "    for f in sorted(files): d = _notebook2script(f, silent=silent, to_dict=d)\n",
    "    if to_dict: return d\n",
    "    else: add_init(Config().lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
