{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup [setup.py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +default_exp -to_path ../setup.py -scoped -no_dunder_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "import sys\n",
    "from pkg_resources import parse_version\n",
    "from configparser import ConfigParser\n",
    "from setuptools import setup, find_packages, __version__ as setuptools_version\n",
    "assert parse_version(setuptools_version)>=parse_version('36.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "CFG_NAMES = ['settings.ini'] # NOTE: Add alternative names/paths here\n",
    "DEFAULT_SECTION = 'DEFAULT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_NAMES.append('../settings.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: Load Config\n",
    "config = ConfigParser(default_section=DEFAULT_SECTION)\n",
    "files_found = config.read(CFG_NAMES)\n",
    "if   len(files_found) <= 0:\n",
    "    raise FileNotFoundError(f'No Config file could not be found.\\n\\t\\tExpected one of: {CFG_NAMES}')\n",
    "elif len(files_found) >  1:\n",
    "    raise ValueError(f'More than one Config file found: {files_found}')\n",
    "file_found = files_found[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "key_err = KeyError(f'{file_found} does not have a section titled {DEFAULT_SECTION}')\n",
    "try: cfg = dict(config[DEFAULT_SECTION])\n",
    "except KeyError: raise key_err from None\n",
    "if len(cfg) == 0: raise key_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: Handle cmd line arguments\n",
    "if len(sys.argv)>1 and sys.argv[1]=='version':\n",
    "    if 'version' in cfg:\n",
    "        print(cfg['version'])\n",
    "        exit()\n",
    "    else: raise KeyError(f\"No 'version' is present in {file_found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: Parse Config Metadata\n",
    "# https://docs.python.org/3/distutils/setupscript.html\n",
    "# https://packaging.python.org/specifications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "if not ('lib_name' in cfg): raise KeyError(f\"Missing 'lib_name' in {file_found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "metadata = dict(name = cfg.pop('lib_name'), # POP\n",
    "                entry_points = dict(console_scripts = list()),\n",
    "                install_requires = list(), # ['pip', 'packaging']\n",
    "                extras_require = dict(),\n",
    "                classifiers = list(),\n",
    "                project_urls = dict(),\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'nbdev_rewrite',\n",
       " 'entry_points': {'console_scripts': []},\n",
       " 'install_requires': [],\n",
       " 'extras_require': {},\n",
       " 'classifiers': [],\n",
       " 'project_urls': {}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: license\n",
    "# NOTE: classifiers, license\n",
    "if 'license' in cfg:\n",
    "    # https://spdx.org/licenses/\n",
    "    # https://pypi.org/classifiers/\n",
    "    # https://choosealicense.com/licenses/\n",
    "    L = {'Apache-2.0' : ('Apache License 2.0',\n",
    "                         'OSI Approved :: Apache Software License'),\n",
    "         'MIT'        : ('MIT License',\n",
    "                         'OSI Approved :: MIT License'),\n",
    "         'GPL-3.0'    : ('GNU General Public License v3.0 only',\n",
    "                         'OSI Approved :: GNU General Public License v3 (GPLv3)'),\n",
    "         'Unlicense'  : ('The Unlicense',\n",
    "                         'OSI Approved :: The Unlicense (Unlicense)'),\n",
    "        }\n",
    "    aliases = {'apache2'   : 'Apache-2.0',\n",
    "               'mit'       : 'MIT',\n",
    "               'gpl3'      : 'GPL-3.0',\n",
    "               'unlicense' : 'Unlicense',\n",
    "              }\n",
    "    license = cfg['license'] # POP\n",
    "    if license in L:\n",
    "        L0, L1 = L[license]\n",
    "    elif license in aliases:\n",
    "        L0, L1 = L[aliases[license]]\n",
    "    else:\n",
    "        raise ValueError(f\"License identifier '{license}' in '{file_found}' is not recognized.\\n\"\\\n",
    "                         f\"\\tAvailable identifiers are: {list(L.keys())}\\n\\tAliases: {aliases}.\") from None\n",
    "    metadata['license'] = L0\n",
    "    metadata['classifiers'].append(f'License :: {L1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: python_requires\n",
    "# NOTE: classifiers: Programming Language\n",
    "if 'min_python' in cfg:\n",
    "    py_v = '2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 3.0 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9'.split()\n",
    "    min_python = cfg['min_python'] # POP\n",
    "    assert '2.0' <= min_python, \"A python version below '2.0' is not possible.\"\n",
    "    if min_python not in py_v:\n",
    "        print(f\"[WARNING]: Minimum Python version '{min_python}' in '{file_found}' is not recognized.\\n\"\\\n",
    "              f\"           Recognized versions are: {py_v}\")\n",
    "    metadata['python_requires'] = f'>={min_python}'\n",
    "    \n",
    "    metadata['classifiers'].append('Programming Language :: Python')\n",
    "    if   '2.0' <= min_python < '3.0':\n",
    "        metadata['classifiers'].append('Programming Language :: Python :: 2')\n",
    "    elif '3.0' <= min_python < '4.0':\n",
    "        metadata['classifiers'].append('Programming Language :: Python :: 3')\n",
    "        metadata['classifiers'].append('Programming Language :: Python :: 3 :: Only')\n",
    "    if min_python in py_v:\n",
    "        metadata['classifiers'].extend([f'Programming Language :: Python :: {v}' for v in\n",
    "                                        py_v[py_v.index(min_python):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: classifiers: Development Status\n",
    "if 'status' in cfg:\n",
    "    statuses = ['1 - Planning', '2 - Pre-Alpha', '3 - Alpha', '4 - Beta',\n",
    "                '5 - Production/Stable', '6 - Mature', '7 - Inactive' ]\n",
    "    status = cfg['status'] # POP\n",
    "    try:\n",
    "        metadata['classifiers'].append(f'Development Status :: {statuses[int(status)]}')\n",
    "    except (ValueError, IndexError):\n",
    "        raise ValueError(f\"Status '{status}' is an invalid value in '{file_found}'. \\n\"\\\n",
    "                         \"It can only take on one of the following: {'1', '2', '3', '4', '5', '6', '7'}\") from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: classifiers: Natural Language\n",
    "if 'language' in cfg:\n",
    "    metadata['classifiers'].append(f\"Natural Language :: {cfg['language'].title()}\") # POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: classifiers: Intended Audience\n",
    "if 'audience' in cfg:\n",
    "    # TODO: Support lists as well?\n",
    "    #       There can be multiple indended audiences e.g. 'Developers' + 'Science/Research'\n",
    "    metadata['classifiers'].append(f\"Intended Audience :: {cfg['audience'].title()}\") # POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# TODO: Add 'Operating System' identifier as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: install_requires\n",
    "if 'requirements' in cfg:\n",
    "    metadata['install_requires'].extend(cfg['requirements'].split()) # POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: extras_require\n",
    "if 'dev_requirements' in cfg:\n",
    "    metadata['extras_require']['dev'] = cfg['dev_requirements'].split() # POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: entry_points: console_scripts\n",
    "if 'console_scripts' in cfg:\n",
    "    metadata['entry_points']['console_scripts'].extend(cfg['console_scripts'].split()) # POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: long_description\n",
    "if not 'long_description' in cfg: # NOTE: Allow for long_description to be overwritten in settings.ini\n",
    "    try: metadata['long_description'] = open('README.md').read()\n",
    "    except FileNotFoundError:\n",
    "        if 'description' in cfg:\n",
    "            metadata['long_description'] = cfg['description'] # NOT POP\n",
    "        else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: url\n",
    "# NOTE: download_url\n",
    "# NOTE: project_urls: Source Code\n",
    "if 'git_url' in cfg:\n",
    "    git_url = cfg['git_url'] # POP\n",
    "    if (not 'url' in cfg):\n",
    "        metadata['url'] = git_url # homepage\n",
    "    if (not 'download_url' in cfg):\n",
    "        metadata['download_url'] = git_url # TODO: use pipy url\n",
    "    if (not 'source_url' in cfg):\n",
    "        metadata['project_urls']['Source Code'] = git_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: project_urls: Documentation\n",
    "if 'doc_host' in cfg:\n",
    "    doc_url = cfg['doc_host'] # POP\n",
    "    if 'doc_baseurl' in cfg: doc_url += cfg['doc_baseurl'] # POP\n",
    "    metadata['project_urls']['Documentation'] = doc_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# NOTE: project_urls: Bug Tracker\n",
    "if 'bug_tracker_url' in cfg: # issues\n",
    "    metadata['project_urls']['Bug Tracker'] = cfg['bug_tracker_url'] # POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "setup_kwargs = {k: cfg[k] for k in ['lib_name', 'author', 'author_email', 'maintainer',\n",
    "                                 'maintainer_email', 'version', 'description', 'keywords',]\n",
    "                if k in cfg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "setup_kwargs.update(packages                      = find_packages(where='.'),\n",
    "                    include_package_data          = True,\n",
    "                    long_description_content_type = 'text/markdown',\n",
    "                    zip_safe                      = False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Florian Peters',\n",
       " 'version': '0.0.1',\n",
       " 'packages': [],\n",
       " 'include_package_data': True,\n",
       " 'long_description_content_type': 'text/markdown',\n",
       " 'zip_safe': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "setup_call = {**metadata, **setup_kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -from_string\n",
    "r\"\"\"\n",
    "setup(**setup_call)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'nbdev_rewrite',\n",
       " 'entry_points': {'console_scripts': []},\n",
       " 'install_requires': [],\n",
       " 'extras_require': {},\n",
       " 'classifiers': ['License :: OSI Approved :: Apache Software License',\n",
       "  'Programming Language :: Python',\n",
       "  'Programming Language :: Python :: 3',\n",
       "  'Programming Language :: Python :: 3 :: Only',\n",
       "  'Programming Language :: Python :: 3.7',\n",
       "  'Programming Language :: Python :: 3.8',\n",
       "  'Programming Language :: Python :: 3.9',\n",
       "  'Development Status :: 3 - Alpha',\n",
       "  'Natural Language :: English',\n",
       "  'Intended Audience :: Developers'],\n",
       " 'project_urls': {'Source Code': 'https://github.com/flpeters/nbdev_rewrite/tree/master/',\n",
       "  'Documentation': 'https://flpeters.github.io/nbdev_rewrite/',\n",
       "  'Bug Tracker': 'https://github.com/flpeters/nbdev_rewrite/issues'},\n",
       " 'license': 'Apache License 2.0',\n",
       " 'python_requires': '>=3.7',\n",
       " 'url': 'https://github.com/flpeters/nbdev_rewrite/tree/master/',\n",
       " 'download_url': 'https://github.com/flpeters/nbdev_rewrite/tree/master/',\n",
       " 'author': 'Florian Peters',\n",
       " 'version': '0.0.1',\n",
       " 'packages': [],\n",
       " 'include_package_data': True,\n",
       " 'long_description_content_type': 'text/markdown',\n",
       " 'zip_safe': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unused args:\n",
    "```python\n",
    "nbs_path\n",
    "lib_path\n",
    "doc_path\n",
    "title\n",
    "dep_links # dependency_links\n",
    "git_user\n",
    "host\n",
    "branch\n",
    "repo_name\n",
    "company_name\n",
    "```\n",
    "modified args:\n",
    "```python\n",
    "license\n",
    "min_python\n",
    "status\n",
    "language\n",
    "audience\n",
    "requirements\n",
    "dev_requirements\n",
    "console_scripts\n",
    "git_url\n",
    "doc_host\n",
    "doc_baseurl\n",
    "bug_tracker_url\n",
    "```\n",
    "modified unlisted kwargs:\n",
    "```python\n",
    "long_description\n",
    "url, download_url, source_url\n",
    "dev_requirements\n",
    "```\n",
    "unmodified args:\n",
    "```python\n",
    "lib_name\n",
    "author, author_email\n",
    "maintainer, maintainer_email\n",
    "version\n",
    "description\n",
    "keywords\n",
    "```\n",
    "\n",
    "other args:\n",
    "```python\n",
    "copyright\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import distutils\n",
    "distutils.core.setup_keywords\n",
    "'distclass',\n",
    "'script_name',\n",
    "'script_args',\n",
    "'options',\n",
    "    'name',\n",
    "    'version',\n",
    "    'author',\n",
    "    'author_email',\n",
    "    'maintainer',\n",
    "    'maintainer_email',\n",
    "    'url',\n",
    "    'license',\n",
    "    'description',\n",
    "    'long_description',\n",
    "    'keywords',\n",
    "'platforms',\n",
    "    'classifiers',\n",
    "    'download_url',\n",
    "'requires',\n",
    "'provides',\n",
    "'obsoletes'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "metadata = dict(\n",
    "    # name='numpy',\n",
    "    # maintainer=\"NumPy Developers\",\n",
    "    # maintainer_email=\"numpy-discussion@python.org\",\n",
    "    # description=DOCLINES[0],\n",
    "    # long_description=\"\\n\".join(DOCLINES[2:]),\n",
    "    # url=\"https://www.numpy.org\",\n",
    "    # author=\"Travis E. Oliphant et al.\",\n",
    "    # download_url=\"https://pypi.python.org/pypi/numpy\",\n",
    "    # project_urls={\n",
    "    #     \"Bug Tracker\": \"https://github.com/numpy/numpy/issues\",\n",
    "    #     \"Documentation\": get_docs_url(),\n",
    "    #     \"Source Code\": \"https://github.com/numpy/numpy\",\n",
    "    # },\n",
    "    # license='BSD',\n",
    "    # classifiers=[_f for _f in CLASSIFIERS.split('\\n') if _f],\n",
    "    platforms=[\"Windows\", \"Linux\", \"Solaris\", \"Mac OS-X\", \"Unix\"],\n",
    "    test_suite='pytest',\n",
    "    version=versioneer.get_version(),\n",
    "    cmdclass=cmdclass,\n",
    "    # python_requires='>=3.7',\n",
    "    zip_safe=False,\n",
    "    # entry_points={\n",
    "    #     'console_scripts': f2py_cmds\n",
    "    # }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "setup(\n",
    "    # name = cfg['lib_name'], # lib_name\n",
    "    # license = lic[0], # license\n",
    "    # classifiers = [\n",
    "    #     'Development Status :: ' + statuses[int(cfg['status'])], # status\n",
    "    #     'Intended Audience :: ' + cfg['audience'].title(), # audience\n",
    "    #     'License :: ' + lic[1], # license\n",
    "    #     'Natural Language :: ' + cfg['language'].title(), # language\n",
    "    # ] + ['Programming Language :: Python :: '+o for o in py_versions[py_versions.index(min_python):]], # min_python\n",
    "    # url = cfg['git_url'], # git_url\n",
    "    packages = find_packages(),\n",
    "    include_package_data = True,\n",
    "    # install_requires = requirements, # requirements\n",
    "    # extras_require={ 'dev': dev_requirements }, # dev_requirements\n",
    "    # python_requires  = '>=' + cfg['min_python'], # min_python\n",
    "    # long_description = long_description, # README.md\n",
    "    long_description_content_type = 'text/markdown',\n",
    "    zip_safe = False,\n",
    "    # entry_points = { 'console_scripts': cfg.get('console_scripts','').split() }, # console_scripts\n",
    "    **setup_cfg)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parsing [Module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +default_exp -to argument_parsing -scoped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# This Flag allows anyone to know if this Module exists in their namespace\n",
    "MODULE__ARGUMENT_PARSING__FLAG = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "arg_parse_REPORT_ERROR  :bool = True\n",
    "arg_parse_REPORT_WARNING:bool = True\n",
    "arg_parse_RAISE_ERROR  :bool  = False\n",
    "arg_parse_RAISE_WARNING:bool  = False\n",
    "arg_parse_SILENT:bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def set_arg_parse_report_options(report_error:bool=True, report_warning:bool=True,\n",
    "                                 raise_error:bool=False, raise_warning:bool=False,\n",
    "                                 silent=False):\n",
    "    \"Set options for how the Argument Parsing Module will behave on encountering errors or warnings.\\n\"\\\n",
    "    \"Raise causes an exception to be raised, and it supersedes report.\\n\"\\\n",
    "    \"Report prints the information and then continues. If raise is set, then this setting is ignored.\"\\\n",
    "    \"Silent overwrites all other settings and causes all errors and warnings to be ignored.\"\\\n",
    "    \"The priority is thus: silent > raise > report\"\n",
    "    global arg_parse_REPORT_ERROR, arg_parse_REPORT_WARNING\n",
    "    global arg_parse_RAISE_ERROR, arg_parse_RAISE_WARNING\n",
    "    global arg_parse_SILENT\n",
    "    arg_parse_REPORT_ERROR, arg_parse_REPORT_WARNING = report_error, report_warning\n",
    "    arg_parse_RAISE_ERROR , arg_parse_RAISE_WARNING  = raise_error , raise_warning\n",
    "    arg_parse_SILENT = (silent or not (report_error and report_warning and raise_error and raise_warning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def report_error(err:Exception):\n",
    "    if   arg_parse_SILENT: pass\n",
    "    elif arg_parse_RAISE_ERROR : raise err\n",
    "    elif arg_parse_REPORT_ERROR: print(f'[{err.__class__.__name__}]: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def report_warning(warn:str):\n",
    "    if   arg_parse_SILENT: pass\n",
    "    elif arg_parse_RAISE_WARNING : raise Warning(warn)\n",
    "    elif arg_parse_REPORT_WARNING: print(f'[Warning]: {warn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a fancy way of advancing the cursor and checking for out of bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def get_next_argument(args:list, name:str, cursor:int, suppress_error:bool=False) -> (bool, int, str):\n",
    "    \"Gets the next argument from the list.\\nReturns success, the cursor, and the next argument\"\n",
    "    cursor_1 = cursor + 1\n",
    "    try: return True, cursor_1, args[cursor_1]\n",
    "    except IndexError:\n",
    "        if not suppress_error:\n",
    "            report_error(SyntaxError(f\"End of arguments reached. Missing a value for argument '{name}' at position {cursor_1}\"))\n",
    "        return False, cursor, ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, 'c')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'b', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SyntaxError]: End of arguments reached. Missing a value for argument 'c' at position 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, 2, '')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'c', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 2, '')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'c', 2, suppress_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to Argument Parsing is just a string, so values have to be converted based on the information provided by the caller.  These function help to do that in a safe way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def to_integer(value:str) -> (bool, int, float):\n",
    "    \"Try converting a str to int.\\nReturn success, the value, and possibly a float remainder.\"\n",
    "    try:\n",
    "        f_value = float(value)\n",
    "        int_value = int(f_value)\n",
    "        remainder = f_value - int_value\n",
    "    except: return False, value, None\n",
    "    return True, int_value, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, -2, -0.10000000000000009), (False, 'nice', None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_integer('-2.1'), to_integer('nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def to_float(value:str) -> (bool, float):\n",
    "    \"Try converting a str to float.\\nReturn success, and the value.\"\n",
    "    # TODO: check if 'inf', 'nan', ...?\n",
    "    try   : return True , float(value)\n",
    "    except: return False, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, -0.001), (True, nan), (False, 'nice'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_float('-1e-3'), to_float('nan'), to_float('nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def to_bool(value:str) -> (bool, bool):\n",
    "    \"\"\"Try converting a str to bool.\n",
    "    'True' and 'False' are recognized, otherwise the value is cast to float, and then to bool.\n",
    "    Return success, and the value.\"\"\"\n",
    "    if value == 'True' : return True, True\n",
    "    if value == 'False': return True, False\n",
    "    try   : return True , bool(float(value))\n",
    "    except: return False, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, True), (True, False), (True, True), (True, False), (False, 'abc'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_bool('1'), to_bool('0'), to_bool('True'), to_bool('False'), to_bool('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def to_unbounded_array(args:list, cursor:int) -> (bool, int, list):\n",
    "    \"\"\"Consume any number of values until either reaching the end of args,\n",
    "    or until finding a value starting with '-', denoting the beginning of a new argument.\n",
    "    Return success, the cursor, and the list of values.\n",
    "    Currently this can't actually fail... don't use unbounded lists kids.\"\"\"\n",
    "    values = []\n",
    "    while True:\n",
    "        string_success, cursor, value = get_next_argument(args, None, cursor, suppress_error=True)\n",
    "        if string_success:\n",
    "            if value[0] != '-': values.append(value)\n",
    "            else: # value starting with '-' means it's the next command\n",
    "                cursor -= 1\n",
    "                break\n",
    "        else: break\n",
    "    return True, cursor, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, ['1', '2'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_unbounded_array(['-list', '1', '2', '-3'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def typify(type_or_value:object) -> (type, object):\n",
    "    \"\"\"Takes a type or a value.\n",
    "    Returns a tuple of the type (or type of the value) and value (or None)\"\"\"\n",
    "    return (type_or_value, None) if isinstance(type_or_value, type) else (type(type_or_value), type_or_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, (int, int, int, int))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typify((int, int)*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def parse_arguments(command:dict, args:[str]) -> (bool, dict, dict):\n",
    "    \"Finds, casts, and returns values from command, in the given comment.\"    \n",
    "    # TODO: check that the type of all commands is supported ahead of time?\n",
    "    # TODO: handle quoted arguments?\n",
    "    # TODO: support command aliases?\n",
    "    members = command.keys()\n",
    "    result  = command.copy()\n",
    "    is_set  = {member : False for member in members}\n",
    "    state   = {'args': args, 'name': '', 'cursor': 0, 'inside_array': False,}\n",
    "    success = True\n",
    "    while state['cursor'] < len(args): # for arg in args:\n",
    "        arg = args[state['cursor']]\n",
    "        if arg[0] != '-':\n",
    "            report_error(SyntaxError(f\"Argument {state['cursor']} does not start with a '-'.\"))\n",
    "            return False, result, is_set\n",
    "        arg = arg[1:] # remove '-'\n",
    "        state['name'] = arg # TODO: check that len(arg) > 0?\n",
    "        \n",
    "        for key in members: # loop over keys of command (the things we're supposed to find)\n",
    "            if key != arg: continue    \n",
    "            if is_set[key]:\n",
    "                report_error(SyntaxError(f\"Argument {state['cursor']} ('{arg}') was given multiple times.\"))\n",
    "                success = False\n",
    "            else:\n",
    "                arg_type, arg_default = typify(command[key])\n",
    "                member_success = handle_one_argument(result, state, arg_type, arg_default)\n",
    "                if member_success: is_set[key] = True\n",
    "                else: success = False\n",
    "            break # once we have found the correct struct member, stop!\n",
    "        else: # TODO: improve this msg. maybe: \"is not part of the command\"?\n",
    "            report_error(SyntaxError(f\"Argument {state['cursor']} ('{arg}') is not valid.\"))\n",
    "            success = False\n",
    "        if not success: break # stop at first error\n",
    "        state['cursor'] += 1\n",
    "        \n",
    "    if success: success = check_is_set(result, is_set)\n",
    "    return success, result, is_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def handle_one_argument(result:dict, state:dict, arg_type:type, arg_default:object) -> bool:\n",
    "    \"Parse the input args based on arg_type, and set arg_name in result to that value.\"\n",
    "    # NOTE: 'state' and 'result' are references not values, and modified from here.\n",
    "    args     = state['args']\n",
    "    arg_name = state['name']\n",
    "    success  = True\n",
    "    if arg_type == str:\n",
    "        # get the next argument, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        # TODO: how to handle strings that start with a '-'\n",
    "        if string_success: result[arg_name] = value\n",
    "        else: success = False\n",
    "\n",
    "    elif arg_type == bool:\n",
    "        if state['inside_array']:\n",
    "            string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "            if string_success:\n",
    "                bool_success, value = to_bool(value)\n",
    "                if bool_success: result[arg_name] = value\n",
    "                else:\n",
    "                    report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \"\\\n",
    "                    f\"was not convertable to bool. Please use 'True', 'False', '0', or '1'. (It was '{value}')\"))\n",
    "                    success = False\n",
    "            else: success = False\n",
    "        # special case where supplying the argument means True and not supplying it means use the default (False)\n",
    "        else: result[arg_name] = True\n",
    "\n",
    "    elif arg_type == int:\n",
    "        # get the next argument, cast to int, check for remainder, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        if not string_success: return False\n",
    "        int_success, value, remainder = to_integer(value)\n",
    "        if int_success:\n",
    "            result[arg_name] = value\n",
    "            if remainder:\n",
    "                report_warning(\"Junk on the end of the value for int argument \"\\\n",
    "                              f\"{state['cursor']-1} ('{arg_name}'): {remainder}\")\n",
    "        else:\n",
    "            report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \"\\\n",
    "                                    f\"was not an int. (It was '{value}')\"))\n",
    "            success = False\n",
    "\n",
    "    elif arg_type == float:\n",
    "        # get the next argument, cast to float, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        if not string_success: return False\n",
    "        float_success, value = to_float(value)\n",
    "        if float_success: result[arg_name] = value\n",
    "        else:\n",
    "            report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \"\\\n",
    "                                    f\"was not a float. (It was '{value}')\"))\n",
    "            success = False\n",
    "\n",
    "    elif arg_type == list or arg_type == tuple:\n",
    "        if arg_default is None: # unbounded list / tuple\n",
    "            if state['inside_array']:\n",
    "                report_error(SyntaxError(f\"Using an unbounded list or tuple inside an array is not supported.\"))\n",
    "                return False\n",
    "            array_success, state['cursor'], value = to_unbounded_array(args, state['cursor'])\n",
    "            if array_success: # NOTE: currently this can't actually fail... don't use unbounded lists kids.\n",
    "                result[arg_name] = arg_type(value)\n",
    "            else: success = False\n",
    "            \n",
    "        else: # predefined list\n",
    "            s = {'args': args, 'name': 'v', 'cursor': state['cursor'], 'inside_array': True}\n",
    "            value = []\n",
    "            for i, x in enumerate(arg_default):\n",
    "                t, d = typify(x)\n",
    "                n = f'{arg_name}[{i}]'\n",
    "                s['name'] = n\n",
    "                r = {n:d}\n",
    "                member_success = handle_one_argument(r, s, t, d)\n",
    "                if member_success: value.append(r[n])\n",
    "                else: # TODO: Improve error message\n",
    "                    # report_error(SyntaxError(f\"Array argument {state['cursor']} ('{arg_name}') was not passed correctly.\"))\n",
    "                    return False\n",
    "            state['cursor'] = s['cursor']\n",
    "            result[arg_name] = arg_type(value)\n",
    "\n",
    "    else:\n",
    "        report_error(TypeError(f\"Argument {state['cursor']} ('{arg_name}') is of unsupported type {arg_type}.\"))\n",
    "        success = False\n",
    "        \n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def check_is_set(result:dict, is_set:dict) -> bool:\n",
    "    \"Check if any required values (those without defaults), haven't been set yet\"\n",
    "    success = True\n",
    "    for member, v_is_set in is_set.items():\n",
    "        if v_is_set: continue\n",
    "        arg_type, arg_default = typify(result[member])\n",
    "        if arg_default is None: \n",
    "            if arg_type == bool: # NOTE: Special case, not setting a boolean means it's False.\n",
    "                result[member] = False\n",
    "                continue\n",
    "            report_error(ValueError(f\"Argument '{member}' has not been set, and no default value was given.\"))\n",
    "            success = False\n",
    "        elif (arg_type == list) or (arg_type == tuple): # this is a bounded list\n",
    "            # generate list of names with python indexing syntax for better error reporting.\n",
    "            name = [f'{member}[{i}]' for i in range(len(arg_default))]\n",
    "            # create a new 'result' dict, mapping the 'idx names' to each of the values of the list.\n",
    "            r = {n:x for n, x in zip(name, arg_default)}\n",
    "            # since the entire list hasn't been set, each part of the list has also not been set.\n",
    "            s = {n:False for n in r}\n",
    "            # recurse, treating the members of the list as if they comprised a separate command.\n",
    "            is_set_success = check_is_set(r, s)\n",
    "            if is_set_success: # re-set result if all members of the list have a default value.\n",
    "                result[member] = arg_type([r[n] for n in name])\n",
    "                continue\n",
    "            else: success = False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This argument parser is largely inspired by these two videos by Jonathan Blow.\n",
    ">[Part 1](https://youtu.be/TwqXTf7VfZk)  \n",
    ">[Part 2](https://youtu.be/pgiVrhsGkKY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module besically provides only one function:  \n",
    "```python\n",
    "def parse_arguments(command:dict, comment:str) -> (bool, dict, dict)\n",
    "```  \n",
    "\n",
    "It takes one __\"command\" dictionary__, and a __\"comment\" string__.  \n",
    "\n",
    "#### __The command__\n",
    "\n",
    "is a simple key-value collection of expected flags, where a attribute name maps to either a type, or a default value, from which the type is infered.  \n",
    "```python\n",
    "command = {\n",
    "    'arg1':bool,\n",
    "    'arg2':str,\n",
    "    'arg3':32,\n",
    "    'arg4':3.14,\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The comment__\n",
    "is just a list of space-separated arguments, with words starting with a minus (`'-'`) denoting a keyword, and anything without a minus as the first character being a value to the previous keyword.  \n",
    "```python\n",
    "'-name bob -age 99 -celsius 30.5 -thirsty'\n",
    "```  \n",
    "is a valid string for the command  \n",
    "```python\n",
    "{\n",
    "    'name'   : str,\n",
    "    'weather': 'sunny',\n",
    "    'celsius': float,\n",
    "    'age'    : int,\n",
    "    'thirsty': bool,\n",
    "    'tired'  : bool\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The primitive types:__\n",
    "Currently the following primitive types are supported:  \n",
    "- `str`\n",
    "    - a `str` argument requires one value.\n",
    "    - e.g.: `-weather sunny`\n",
    "- `bool`\n",
    "    - a `bool` argument requires no values. setting the flag automatically sets the value to `True`.\n",
    "    - writing `bool` is the same as using the default value `False`.\n",
    "    - e.g.: `-is_wet`\n",
    "- `int`\n",
    "    - a `int` argument requires one value.\n",
    "    - the value will first be cast to `float`, and then to `int`, partly due to how python works, and also to check for a remainder in case the provided value was actually in a float format.\n",
    "    - e.g.: `-age 99`, `-negative -1`\n",
    "- `float`\n",
    "    - a `float` argument requires one value.\n",
    "    - the value has to be castable to `float`. what is and what isn't a float can be suprising, so you should check the [casting rules](https://stackoverflow.com/a/20929983/) beforehand.\n",
    "    - e.g.: `-pi 3.14`, `-negative -1.0`, `-weird nan`, `-large inf`, `-small -inf`\n",
    "  \n",
    "Any of these types can be declared either by just using the `type` directly, or by giving a default value of the specific `type`. All arguments that use the `type` directly have to be passed in the comment. If a default value is specified, or if the `type` is `bool`, the argument does not have to be passed in the comment, and instead the `result` will simply contain the default value. This changes with composite types (see below). If an argument was passed in the comment or not, can be seen by looking at the `is_set` return value (see below).\n",
    "\n",
    "  \n",
    "##### __The composite types__\n",
    "`list` and `tuple` (referred to as 'array' when it can be either one of them) are also supported, however due to pythons lack of strong typing, they have slightly different semantics.  \n",
    "\n",
    "Specifying only the type `list` or `tuple`, will result in an 'unbounded array' of that type, meaning that all values following the keyword will be added to the array, until either the end of arguments is reached, or a value starts with a minus (`'-'`), which denotes the start of the next argument. All values or the array will be of type `str`. This kind of argument should be used with caution, because, for instance, negative values will be treated as the start of a new argument.  \n",
    "```python\n",
    "{\n",
    "    'unbounded_list' : list,\n",
    "    'unbounded_tuple': tuple,\n",
    "}\n",
    "```  \n",
    "\n",
    "The other, better way to use arrays is to actually create an array containing the types, default values, and ordering you want the values to have. This can get arbitrarily complex, mixing and matching any supported primitive type you want. The only thing not allowed, is using an unbounded array (see above).  \n",
    "All values will be cast to the corresponding type using all the same semantics as of they were single values (see above). The only exception to that is the `bool` type, where the value has to be either `'True'`, `'False'`, or interpretable as a `float`, which will then be cast to a `bool`. This means that e.g. `'0.0'` will result in `False`, and `'123'` will result in `'True'` (careful, check the [casting rules](https://docs.python.org/3.3/library/stdtypes.html?highlight=frozenset#truth-value-testing) first).\n",
    "```python\n",
    "{\n",
    "    'arg1': [int]*5,\n",
    "    'arg2': (3.14, 'pi', bool),\n",
    "    'arg3': (bool, str, 123)*2,\n",
    "    'arg4': [[0]*3, [1]*3, [str]*3],\n",
    "    'arg5': [str, int, bool, True, [1, '2', 3, bool], (2.1, float)]\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The return value__\n",
    "is a three-tuple of `(success, result, is_set)`.  \n",
    "- `success` is a `bool`, saying whether or not parsing was successful. If it is `False`, the other two arguments are not guaranteed to be valid. There will be an error message with details on what happened to help debugging.  \n",
    "- `result` is a `dict` with exactly the same keys as the input `command`, with the corresponding values set to whatever was extracted from the comment. In cases where `success` if `False`, this might only be partially filled out, so `success` should always be checked.\n",
    "- `is_set` is a `dict`, which also contains exactly the same keys as the input `command`, this time mapping to a `bool`. It is `True` if `comment` contains a value for the particular argument, and `False` otherwise. In cases where a default value is given in `command`, the same rule applies. Meaning that only if the default was overwritten by an argument in `comment` will the `is_set` value be `True`. This holds even for `bool`s, which default to `False` even if no explicit default was given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SyntaxError]: Argument 0 ('') is not valid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " {'test': bool,\n",
       "  'sunny': False,\n",
       "  'toast': str,\n",
       "  'shots': int,\n",
       "  'scale': float,\n",
       "  'scoops': [str, int, bool, [1, 2, 3, bool], (float, float)],\n",
       "  'valid': (1, 1.23, bool, 'hi', [1, 2, bool]),\n",
       "  'nah': 'boi',\n",
       "  'sweet': bool,\n",
       "  'nr': int,\n",
       "  'list': list},\n",
       " {'test': False,\n",
       "  'sunny': False,\n",
       "  'toast': False,\n",
       "  'shots': False,\n",
       "  'scale': False,\n",
       "  'scoops': False,\n",
       "  'valid': False,\n",
       "  'nah': False,\n",
       "  'sweet': False,\n",
       "  'nr': False,\n",
       "  'list': False})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = {\n",
    "    'test'  : bool,\n",
    "    'sunny' : False,\n",
    "    'toast' : str,\n",
    "    'shots' : int,\n",
    "    'scale' : float,\n",
    "    'scoops': [str, int, bool, [1, 2, 3, bool], (float, float)],\n",
    "    # 'valid' : (bool, bool),\n",
    "    'valid' : (1, 1.23, bool, 'hi', [1, 2, bool]),\n",
    "    'nah'   : 'boi',\n",
    "    'sweet' : bool,\n",
    "    'nr'    : int,\n",
    "    'list'  : list\n",
    "}\n",
    "\n",
    "comment = '-sunny -toast jelly -shots 25 -scale 69105.1234 -test -list 2 -scoops a 1 0 5 6 7 False 3.0 2.1 -nr 21'\n",
    "# comment = '-sunny -toast jelly -shots 25 -scale 69105.1234 -test -nr 1'\n",
    "parse_arguments(command, comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%timeit parse_arguments(command, comment)\n",
    ">>> 44 µs ± 98.9 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports [Module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +default_exp -to imports -scoped -no_dunder_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# This Flag allows anyone to know if this Module exists in their namespace\n",
    "MODULE__IMPORTS__FLAG = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "import os,re,functools\n",
    "import concurrent.futures\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from configparser import ConfigParser\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "# from nbformat.sign import NotebookNotary\n",
    "# from base64 import b64decode,b64encode\n",
    "# from types import MethodType,FunctionType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def test_eq(a,b): assert a==b, f'{a}, {b}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def save_config_file(file, d, **kwargs):\n",
    "    \"Write settings dict to a new config file, or overwrite the existing one.\"\n",
    "    config = ConfigParser(**kwargs)\n",
    "    config['DEFAULT'] = d\n",
    "    config.write(open(file, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def read_config_file(file, **kwargs):\n",
    "    config = ConfigParser(**kwargs)\n",
    "    config.read(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "_defaults = {\"host\": \"github\", \"doc_host\": \"https://%(user)s.github.io\", \"doc_baseurl\": \"/%(lib_name)s/\"}\n",
    "\n",
    "def _add_new_defaults(cfg, file):\n",
    "    \"If an existing Config does not contain these values, add them, and save the config file.\\n\"\\\n",
    "    \"This is meant to be used in case new default values are added in later versions.\"\n",
    "    for k,v in _defaults.items():\n",
    "        if cfg.get(k, None) is None:\n",
    "            cfg[k] = v\n",
    "            save_config_file(file, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@functools.lru_cache(maxsize=None)\n",
    "class Config:\n",
    "    \"Store the basic information for nbdev to work\"\n",
    "    def __init__(self, cfg_name='settings.ini'):\n",
    "        cfg_path = Path.cwd().absolute().resolve()\n",
    "        while cfg_path != cfg_path.parent and not (cfg_path/cfg_name).exists(): cfg_path = cfg_path.parent\n",
    "        self.config_path,self.config_file = cfg_path,cfg_path/cfg_name\n",
    "        assert self.config_file.exists(), f\"Could not find {cfg_name}\"\n",
    "        self.d = read_config_file(self.config_file)['DEFAULT']\n",
    "\n",
    "    def __getattr__(self,k):\n",
    "        if k.endswith('_path'): return self._path_to(k)\n",
    "        try: return self.d[k]\n",
    "        except KeyError: raise AttributeError(f\"Config ({self.config_file.name}) has no attribute '{k}'\") from None\n",
    "    \n",
    "    def _path_to(self,k,default=None):\n",
    "        v = self.d.get(k, default)\n",
    "        if v is None: raise AttributeError(f\"Config ({self.config_file.name}) has no attribute '{k}'\")\n",
    "        return self.config_path/v\n",
    "    \n",
    "    def path_to(self,k,default=None):\n",
    "        \"Retrieve a path saved in Config relative to the folder the Config file is in.\"\n",
    "        return self._path_to((k if k.endswith('_path') else k+'_path'), default)\n",
    "\n",
    "    def get(self,k,default=None): return self.d.get(k, default)\n",
    "    def __setitem__(self,k,v): self.d[k] = str(v)\n",
    "    def __contains__(self,k):  return k in self.d\n",
    "    def save(self): save_config_file(self.config_file,self.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def create_config(lib_name,\n",
    "                  cfg_path='.', cfg_name='settings.ini',\n",
    "                  license=None,\n",
    "                  author=None, author_email=None, copyright=None,\n",
    "                  maintainer=None, maintainer_email=None,\n",
    "                  nbs_path='nbs',\n",
    "                  lib_path='%(lib_name)s', doc_path='docs',\n",
    "                  version='0.0.1', min_python='3.7',\n",
    "                  language='English', status=None,\n",
    "                  audience=None, title='%(lib_name)s',\n",
    "                  description=None, keywords=None,\n",
    "                  requirements=None, console_scripts=None, dep_links=None,\n",
    "                  git_user=None, host='github', branch='master',\n",
    "                  git_url='https://github.com/%(git_user)s/%(lib_name)s/tree/%(branch)s/',\n",
    "                  doc_host='https://%(git_user)s.github.io',\n",
    "                  doc_baseurl='/%(lib_name)s/',\n",
    "                  bug_tracker_url='https://github.com/%(git_user)s/%(lib_name)s/issues',\n",
    "                  repo_name=None, company_name=None,\n",
    "                  **kwargs):\n",
    "    if git_user is None: host = branch = git_url = doc_host = doc_baseurl = bug_tracker_url= None\n",
    "    else: user = git_user # NOTE: backwards compatibility\n",
    "    args = locals()\n",
    "    path = args.pop('cfg_path')\n",
    "    name = args.pop('cfg_name')\n",
    "    kwargs = args.pop('kwargs') # NOTE: locals() also contains `kwargs` as a key, so remove it\n",
    "    config = OrderedDict(filter(lambda x: x[1] is not None, # NOTE: Filter out None values\n",
    "                                sorted({**args, **kwargs}.items(),\n",
    "                                       key=lambda x:x[0]))) # NOTE: Sort by key\n",
    "    save_config_file(Path(path)/name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "create_config.__doc__ = \"\"\"\n",
    "Create a new config file and save it.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "`lib_name` : str\n",
    "    The name of the package that will be created\n",
    "\n",
    "`cfg_path` : str, optional\n",
    "    The path where to create the config file.\n",
    "`cfg_name` : str, optional\n",
    "    The name of the config file to be created.\n",
    "    \n",
    "`license` : {'apache2', }, optional\n",
    "    The license under which this project is published.\n",
    "`author` : str, optional\n",
    "    The name of the author of this project (probably you).\n",
    "`author_email` : str, optional\n",
    "    The authors email address.\n",
    "`copyright` : str, optional\n",
    "    The authors name, or a company name.\n",
    "`maintainer` : str, optional\n",
    "    The person or group which maintains the project.\n",
    "`maintainer_email` : str, optional\n",
    "    The maintainers email address.\n",
    "\n",
    "`nbs_path` : str, optional\n",
    "    A path to a subdirectory relative to where the 'settings.ini' file is located.\n",
    "    All of the notebooks that you want to have processed need to be in this folder,\n",
    "    or in a subfolder.\n",
    "`lib_path` : str, optional\n",
    "    A path to a subdirectory relative to where the 'settings.ini' file is located.\n",
    "    This is the folder where all generated .py files will be stored,\n",
    "    and the name you use when importing the package.\n",
    "`doc_path` : str, optional\n",
    "    A path to a subdirectory relative to where the 'settings.ini' file is located.\n",
    "    Present for compatibility with the original 'nbdev' project. This folder is\n",
    "    where documentation generated from your notebooks in `nbs_path` is stored.\n",
    "\n",
    "`version` : str, optional\n",
    "    A version number in the '{major}.{minor}.{patch}' semantic versioning format.\n",
    "`min_python` : {..., '3.6', 3.7', '3.8', '3.9', ...}, optional\n",
    "    The minimum python version necessary to run your code [1].\n",
    "`language` : {'English', ...}, optional\n",
    "    The natural language used in your program [1].\n",
    "`status` : {'1', '2', '3', '4', '5', '6', '7'}, optional\n",
    "    The development status of your project [1].\n",
    "    The numbers 1-7 correspond to the following status respectively:\n",
    "    Planning, Pre-Alpha, Alpha, Beta, Production, Mature, Inactive\n",
    "`audience` : {'Developers', 'End Users/Desktop', 'Other Audience', ...}, optional\n",
    "    The intended audience of your project [1].\n",
    "`title` : str, optional\n",
    "    By default the same as your library name.\n",
    "    Currently only used by the original nbdev project.\n",
    "`description` : str, optional\n",
    "    A short, one sentence, description of your project.\n",
    "`keywords` : str, optional\n",
    "    Space separated keywords / tags that describe your project.\n",
    "    e.g. 'python jupyter notebook nbdev'.\n",
    "\n",
    "`requirements` : str, optional\n",
    "    Packages that are minimally required for your project to run.\n",
    "    Written in the same format as setuptools requirements [2].\n",
    "`console_scripts` : str, optional\n",
    "    Space separated list of key=value pairs.\n",
    "    The key is the name of the command,\n",
    "    and value is the python module and function that is supposed to be called.\n",
    "    Written in the same format as setuptools console-scripts [3].\n",
    "`dep_links` : str, optional\n",
    "    Currently not in use.\n",
    "    Written in the same format as setuptools dependency links.\n",
    "\n",
    "`git_user` : str, optional\n",
    "    Your git username.\n",
    "`host` : str, optional\n",
    "    The name of your git repo host.\n",
    "`branch` : str, optional\n",
    "    The name of the main git branch.\n",
    "`git_url` : str, optional\n",
    "    The git URL where your project lives.\n",
    "\n",
    "`doc_host` : str, optional\n",
    "    The URL where you have documentation hosted.\n",
    "`doc_baseurl` : str, optional\n",
    "    The URL path relative to the `doc_host`,\n",
    "    which points to where the docs for this project are stored.\n",
    "\n",
    "`bug_tracker_url` : str, optional\n",
    "    The URL where bugs and issues are tracked and discussed.\n",
    "\n",
    "`repo_name` : str, optional\n",
    "    For enterprise git users.\n",
    "`company_name` : str, optional\n",
    "    For enterprise git users.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "None\n",
    "\n",
    "See Also\n",
    "--------\n",
    "[1] https://pypi.org/classifiers/\n",
    "[2] https://packaging.python.org/discussions/install-requires-vs-requirements/\n",
    "[3] https://python-packaging.readthedocs.io/en/latest/command-line-scripts.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "create_config('nbdev_rewrite', cfg_path='..',\n",
    "              license='apache2',\n",
    "              author='Florian Peters', copyright='Florian Peters',\n",
    "              nbs_path='notebooks',\n",
    "              status='2', audience='Developers',\n",
    "              git_user='flpeters')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def in_ipython():\n",
    "    \"Check if the code is running in the ipython environment (jupyter including)\"\n",
    "    program_name = os.path.basename(os.getenv('_', ''))\n",
    "    if ('jupyter-notebook' in program_name or # jupyter-notebook\n",
    "        'ipython'          in program_name or # ipython\n",
    "        'JPY_PARENT_PID'   in os.environ):    # ipython-notebook\n",
    "        return True\n",
    "    else: return False\n",
    "IN_IPYTHON = in_ipython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def in_colab():\n",
    "    \"Check if the code is running in Google Colaboratory\"\n",
    "    try:\n",
    "        from google import colab\n",
    "        return True\n",
    "    except: return False\n",
    "IN_COLAB = in_colab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def in_notebook():\n",
    "    \"Check if the code is running in a jupyter notebook\"\n",
    "    if in_colab(): return True\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell': return True   # Jupyter notebook, Spyder or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell': return False  # Terminal running IPython\n",
    "        else: return False  # Other type (?)\n",
    "    except NameError: return False      # Probably standard Python interpreter\n",
    "IN_NOTEBOOK = in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def num_cpus():\n",
    "    \"Get number of cpus\"\n",
    "    try:                   return len(os.sched_getaffinity(0)) # NOTE: not available on all platforms\n",
    "    except AttributeError: return os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "class ProcessPoolExecutor(concurrent.futures.ProcessPoolExecutor):\n",
    "    \"Like `concurrent.futures.ProcessPoolExecutor` but handles 0 `max_workers`.\"\n",
    "    def __init__(self, max_workers=None, on_exc=print, **kwargs):\n",
    "        self.not_parallel = max_workers==0\n",
    "        self.on_exc = on_exc\n",
    "        if self.not_parallel: max_workers=1\n",
    "        super().__init__(max_workers, **kwargs)\n",
    "\n",
    "    def map(self, f, items, *args, **kwargs):\n",
    "        g = functools.partial(f, *args, **kwargs)\n",
    "        if self.not_parallel: return map(g, items)\n",
    "        try: return super().map(g, items)\n",
    "        except Exception as e: self.on_exc(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def parallel(f, items, *args, n_workers=None, **kwargs):\n",
    "    \"Applies `func` in parallel to `items`, using `n_workers`\"\n",
    "    if n_workers is None: n_workers = min(16, num_cpus())\n",
    "    with ProcessPoolExecutor(n_workers) as ex:\n",
    "        r = ex.map(f,items, *args, **kwargs)\n",
    "        return list(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# https://github.com/justheuristic/prefetch_generator\n",
    "class BackgroundGenerator(Thread):\n",
    "    \"Computes elements of a Generator in a background Thread.\"\n",
    "    def __init__(self, generator, max_prefetch:int=-1):\n",
    "        \"\"\"\n",
    "        `generator`: A Generator to wrap and prefetch from in a separate thread.\n",
    "        `max_prefetch`: How many items to maximally prefetch at any given time.\n",
    "        If `max_prefetch` is <= 0, then the queue size is infinite.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.queue, self.generator, self.daemon = Queue(max_prefetch), generator, True\n",
    "        self.start()\n",
    "    \n",
    "    def run(self):\n",
    "        try:\n",
    "            for item in self.generator: self.queue.put(item)\n",
    "        except Exception as e:\n",
    "            print('WARNING: Failed in BackgroundGenerator Thread!')\n",
    "            raise e\n",
    "        finally: self.queue.put(StopIteration)\n",
    "    \n",
    "    def __iter__(self): return self\n",
    "    def __next__(self):\n",
    "        next_item = self.queue.get()\n",
    "        if next_item is StopIteration: raise StopIteration\n",
    "        return next_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def prefetch(max_prefetch:int=-1):\n",
    "    \"\"\"\n",
    "    Decorator for wrapping a `yield`-ing Function with `BackgroundGenerator`,\n",
    "    which computes elements of the generator in a background Thread.\n",
    "    \n",
    "    A new instance of `BackgroundGenerator` is created every time the decorated function is called.\n",
    "    \n",
    "    `max_prefetch`: How many items to maximally prefetch at any given time.\n",
    "    If `max_prefetch` is <= 0, then the queue size is infinite.\n",
    "    \"\"\"\n",
    "    def decorator(generator):\n",
    "        def wrapper(*args,**kwargs):\n",
    "            return BackgroundGenerator(generator(*args,**kwargs), max_prefetch=max_prefetch)\n",
    "        functools.update_wrapper(wrapper, generator)\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "class ReLibName():\n",
    "    \"Regex expression that's compiled at first use but not before since it needs `Config().lib_name`\"\n",
    "    def __init__(self, pat, flags=0): self._re,self.pat,self.flags = None,pat,flags\n",
    "    @property\n",
    "    def re(self):\n",
    "        if not hasattr(Config(), 'lib_name'): raise Exception(\"Please fill in the library name in settings.ini.\")\n",
    "        self.pat = self.pat.replace('LIB_NAME', Config().lib_name)\n",
    "        if self._re is None: self._re = re.compile(self.pat, self.flags)\n",
    "        return self._re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def compose(*funcs, order=None):\n",
    "    \"Create a function that composes all functions in `funcs`, \"\\\n",
    "    \"passing along remaining `*args` and `**kwargs` to all\"\n",
    "    if len(funcs)==0: return noop\n",
    "    if len(funcs)==1: return funcs[0]\n",
    "    def _inner(x, *args, **kwargs):\n",
    "        for f in funcs: x = f(x, *args, **kwargs)\n",
    "        return x\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def last_index(x, o):\n",
    "    \"Finds the last index of occurence of `x` in `o` (returns -1 if no occurence)\"\n",
    "    try: return next(i for i in reversed(range(len(o))) if o[i] == x)\n",
    "    except StopIteration: return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main [Module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +default_exp -to main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# This Flag allows anyone to know if this Module exists in their namespace\n",
    "MODULE__MAIN__FLAG = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS_FILE = '00_export_v4.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "from collections import defaultdict\n",
    "from inspect import signature, currentframe, getfullargspec\n",
    "import nbformat\n",
    "import ast\n",
    "from ast import iter_fields, AST\n",
    "import _ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only do these imports if executing as a python file.  \n",
    "For bootstrapping purposes these modules are also contained in this notebook file.  \n",
    "They are however exported to their own respective files, so when running as a python file, we need to import them back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "if (__name__ != '__main__') or ('MODULE__ARGUMENT_PARSING__FLAG' not in globals()):\n",
    "    from nbdev_rewrite.argument_parsing import *\n",
    "assert 'MODULE__ARGUMENT_PARSING__FLAG' in globals(), \"Missing the 'argument_parsing' module.\"\n",
    "\n",
    "if (__name__ != '__main__') or ('MODULE__IMPORTS__FLAG' not in globals()):\n",
    "    from nbdev_rewrite.imports import *\n",
    "assert 'MODULE__IMPORTS__FLAG' in globals(), \"Missing the 'imports' module.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Options / Report Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "main_REPORT_OPTIONAL_ERROR:bool = False\n",
    "main_REPORT_COMMAND_FOUND:bool = False\n",
    "main_REPORT_RUN_STATISTICS:bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def set_main_report_options(report_optional_error:bool=False,\n",
    "                            report_command_found:bool=False,\n",
    "                            report_run_statistics:bool=True):\n",
    "    \"Set options for how the Main Module will behave on encountering errors or warnings.\\n\"\\\n",
    "    \"report_optional_error prints the information and then continues.\"\n",
    "    global main_REPORT_OPTIONAL_ERROR, main_REPORT_COMMAND_FOUND, main_REPORT_RUN_STATISTICS\n",
    "    main_REPORT_OPTIONAL_ERROR = report_optional_error\n",
    "    main_REPORT_COMMAND_FOUND  = report_command_found\n",
    "    main_REPORT_RUN_STATISTICS = report_run_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### report_successful_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def relative_path(file_path, relative_directory=Config().config_file.parent):\n",
    "    return os.path.relpath(file_path, relative_directory).replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def report_successful_export(parsed_files, merged_files):\n",
    "    \"Report stats and compressed information about parsed and exported files.\"\n",
    "    n_nbs = nr_of_notebooks_parsed = len(parsed_files['files'])\n",
    "    n_py  = nr_of_output_py_files = len(merged_files)\n",
    "    Title = f'{n_nbs} notebook{\"s\"*int(n_nbs!=1)} {\"have\" if n_nbs!=1 else \"has\"} been parsed, '\\\n",
    "            f'resulting in {n_py} python file{\"s\"*int(n_py!=1)}.\\n\\n'\n",
    "    \n",
    "    # Information about which notebooks export to which python files\n",
    "    nb_info = f'The following {n_nbs} notebook{\"s\"*int(n_nbs!=1)} have been parsed:\\n'\n",
    "    nb_info += '-' * (len(nb_info) - 1)\n",
    "    n_out = nr_of_files_outputting_code = 0\n",
    "    for file in parsed_files['files']:\n",
    "        nb_info += f\"\\n{file['relative_origin']} ({len(file['cells'])} cells total)\\n\"\n",
    "        default = file['export_scopes'][(0,)]\n",
    "        n_exp = len(file['export_scopes']) - int(default is None)\n",
    "        nb_info += f'---> default:\\t{None if (default is None) else relative_path(default[\"target\"])}'\n",
    "        for scope, target in sorted(file['export_scopes'].items(), key=lambda x: x[0]):\n",
    "            if scope == (0,): continue\n",
    "            nb_info += f\"\\n---> {scope}:\\t{relative_path(target['target'])}\"\n",
    "        if n_exp > 0: n_out += 1\n",
    "    \n",
    "    \n",
    "    Middle = f'Of the {n_nbs} notebook{\"s\"*int(n_nbs!=1)} parsed, '\\\n",
    "             f'{n_out} {\"are\" if n_out!=1 else \"is\"} outputting code.'\n",
    "    \n",
    "    # Information about how many Python files have been generated, and the number of cells exported to each\n",
    "    py_info = f'The following {n_py} python file{\"s\"*int(n_py!=1)} {\"have\" if n_py!=1 else \"has\"} been generated:\\n'\n",
    "    py_info += '-' * (len(py_info) - 1) + '\\n'\n",
    "    for to, state in merged_files.items():\n",
    "        n_cells = len(state['code'])\n",
    "        py_info += f'---> {n_cells} cell{\"s\"*int(n_cells!=1)} output to {relative_path(to)}\\n'\n",
    "        \n",
    "    print(f'{Title}{nb_info}\\n\\n{Middle}\\n\\n{py_info}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackTrace with report_error() and report_optional_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a class for passing along contextual information during execution.  \n",
    "The class is a linked list, which can be extended each time a new function is called.  \n",
    "Everytime a function is called, create a new StackTrace instance, and pass the current instance to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "class StackTrace: pass # only for :StackTrace annotations to work\n",
    "class StackTrace:\n",
    "    _up:StackTrace = None\n",
    "    namespace:str = None\n",
    "    lineno   :int = None\n",
    "    _ext_file:dict = None\n",
    "    \n",
    "    def __init__(self, namespace:object=None, up:StackTrace=None):\n",
    "        \"`namespace` can be a function, a class, or None.\\n\"\\\n",
    "        \"`up` is optional and can be another StackTrace instance.\"\n",
    "        self.namespace = f'<{namespace.__qualname__}>()' if namespace else currentframe().f_back.f_code.co_name\n",
    "        self._up, self.lineno, self._ext_file = up, currentframe().f_back.f_lineno, {}\n",
    "    \n",
    "    def ext(self, file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):\n",
    "        \"Set context information for reporting errors in external files e.g. notebooks.\"\n",
    "        e = self._ext_file\n",
    "        if not (file    is None) : e['file'   ] = file\n",
    "        if not (cellno  is None) : e['cellno' ] = cellno\n",
    "        if not (lineno  is None) : e['lineno' ] = lineno\n",
    "        if not (excerpt is None) : e['excerpt'] = excerpt\n",
    "        if not (span    is None) : e['span'   ] = span # TODO: convert a single int to tuple?\n",
    "    \n",
    "    def ext_clear_file   (self): self._ext_file.pop('file'   , None)\n",
    "    def ext_clear_cellno (self): self._ext_file.pop('cellno' , None)\n",
    "    def ext_clear_lineno (self): self._ext_file.pop('lineno' , None)\n",
    "    def ext_clear_excerpt(self): self._ext_file.pop('excerpt', None)\n",
    "    def ext_clear_span   (self): self._ext_file.pop('span'   , None)\n",
    "    \n",
    "    def to_list(self):\n",
    "        \"Creates list of the entire StackTrace (most recent last).\"\n",
    "        if self._up: return [*self._up.to_list(), self]\n",
    "        else: return [self]\n",
    "        \n",
    "    def _reduce_ext(self):\n",
    "        \"Combines all `StackTrace._ext_file` dicts into one, prefering more recest settings over old ones.\"\n",
    "        ext = [s._ext_file for s in self.to_list() if s._ext_file]\n",
    "        e = {}\n",
    "        for d in ext: e.update(d)\n",
    "        return e\n",
    "        \n",
    "    def up(self, up:StackTrace):\n",
    "        \"Set this StackTraces `_up` reference and return `self`. Useful for chaining references.\"\n",
    "        self._up=up\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self): return f\"{__name__}.StackTrace(namespace={self.namespace},line={self.lineno})\"\n",
    "    \n",
    "    def _repr(self):\n",
    "        \"Recursively create a string of all StackTraces for printing error messages.\"\n",
    "        return f\"{'' if self._up is None else self._up._repr()}\"\\\n",
    "               f\"<{__name__}>, line {self.lineno} in {self.namespace}\\n\"\n",
    "    \n",
    "    def _repr_ext(self, file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):\n",
    "        \"Create a string from the `StackTrace._ext_file` dict for printing error messages.\"\n",
    "        s = f\"<{file}>, cell {cellno}, line {lineno}\\n\"\n",
    "        if excerpt:\n",
    "            x = f\"--->{' ' if ((lineno is None) or (0 <= lineno <= 9)) else ''}{lineno} \"\n",
    "            s += f\"{x}{excerpt}\\n\"\\\n",
    "                 f\"{(' ' * (len(x) + span[0]) + '^' * span[1]) if span else ''}\\n\"\n",
    "        return s\n",
    "    \n",
    "    def report_error(self, err:Exception,\n",
    "                     file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None,\n",
    "                     success=False, _ln_of_callsite=True) -> bool:\n",
    "        \"Report the Error `err`.\\nOther args are used for setting `_ext_file` and are optional.\\n\"\\\n",
    "        \"Returns whatever is passes as `success`.\"\n",
    "        if _ln_of_callsite: self.lineno = currentframe().f_back.f_lineno\n",
    "        err_type = err.__class__.__name__\n",
    "        s = f\"{'-'*75}\\n\"\\\n",
    "            f\"{err_type}{' '*(41-len(err_type))}Stacktrace (most recent call last)\\n\"\\\n",
    "            f\"{self._repr()}\\n\"\n",
    "        self.ext(file, cellno, lineno, excerpt, span) # TODO: should this maybe be passed to _reduce_ext?\n",
    "        ext:dict = self._reduce_ext()\n",
    "        if ext: s += f\"{self._repr_ext(**ext)}\\n\" # TODO: check for len(ext) > 0 and values not None?\n",
    "        s += f\"[{err_type}]: {err}\"\n",
    "        print(s) # NOTE: This is what prints the error message.\n",
    "        return success\n",
    "    \n",
    "    def report_caught_syntax_error(self, err:SyntaxError, msg='invalid syntax', success=False):\n",
    "        \"Report an error taking advantage of common formatting when handling a python SyntaxError.\"\n",
    "        self.lineno = currentframe().f_back.f_lineno\n",
    "        return self.report_error(SyntaxError(msg),\n",
    "                                 excerpt=err.text[:-1],\n",
    "                                 lineno=err.lineno,\n",
    "                                 span=(err.offset-1, 1),\n",
    "                                 success=success,\n",
    "                                 _ln_of_callsite=False)\n",
    "    \n",
    "    def report_optional_error(self, err:Exception,\n",
    "                        file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):\n",
    "        \"Report the error if the global variable `main_REPORT_OPTIONAL_ERROR` is set.\"\n",
    "        if main_REPORT_OPTIONAL_ERROR:\n",
    "            self.lineno = currentframe().f_back.f_lineno\n",
    "            self.report_error(err=err, _ln_of_callsite=False,\n",
    "                              file=file,\n",
    "                              cellno=cellno, lineno=lineno,\n",
    "                              excerpt=excerpt, span=span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def Traced(f):\n",
    "    \"The Annotated function will have a StackTrace instance passed to it as the `st` keyword-argument.\\n\"\\\n",
    "    \"That instance represents the annotated function, with a reference to the calling site.\"\n",
    "    spec = getfullargspec(f)\n",
    "    assert ('st' in spec.args) or ('st' in spec.kwonlyargs), \"Traced functions have to take a 'st' argument.\"\n",
    "    if 'st' in spec.annotations:\n",
    "        assert spec.annotations['st'] == StackTrace, \"A traced functions 'st' argument is reserved for \"\\\n",
    "                                                     \"a StackTrace. Other annotations are not allowed.\"\n",
    "    else: f.__annotations__['st'] = StackTrace # This modifies the original function. Is that acceptable?\n",
    "    \n",
    "    _st = StackTrace(f)\n",
    "    def _wrapper(*args, st:StackTrace=None, **kwargs):\n",
    "        if not st:\n",
    "            st = StackTrace(None)\n",
    "            st.namespace = currentframe().f_back.f_code.co_name\n",
    "        elif (st is _st): return f(*args, st=st, **kwargs) # prevent self referencing due to e.g. recursion.\n",
    "        st.lineno = currentframe().f_back.f_lineno\n",
    "        # NOTE: clearing _st._ext_file to an empty dict like this is actually faster than not clearing it...\n",
    "        res = f(*args, st=_st.up(st), **kwargs)\n",
    "        _st._ext_file = {}\n",
    "        return res\n",
    "    \n",
    "    functools.update_wrapper(_wrapper, f)\n",
    "    return _wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Traced\n",
    "def _do_the_thing(st):\n",
    "    success = True\n",
    "    if True:# Error has happened!\n",
    "        return st.report_error(Exception('Failed doing the thing!'))\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Traced\n",
    "def _start(st):\n",
    "    success = True\n",
    "    success = _do_the_thing(st=st)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Exception                                Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 4 in <_start>()\n",
      "<__main__>, line 5 in <_do_the_thing>()\n",
      "\n",
      "[Exception]: Failed doing the thing!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Traced\n",
    "def _recursive_stuff(i, st):\n",
    "    print(i, st, st._up)\n",
    "    if i <= 0: return 1\n",
    "    else: return i + _recursive_stuff(i - 1, st=st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 __main__.StackTrace(namespace=<_recursive_stuff>(),line=12) __main__.StackTrace(namespace=<module>,line=1)\n",
      "2 __main__.StackTrace(namespace=<_recursive_stuff>(),line=12) __main__.StackTrace(namespace=<module>,line=1)\n",
      "1 __main__.StackTrace(namespace=<_recursive_stuff>(),line=12) __main__.StackTrace(namespace=<module>,line=1)\n",
      "0 __main__.StackTrace(namespace=<_recursive_stuff>(),line=12) __main__.StackTrace(namespace=<module>,line=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_recursive_stuff(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SyntaxError                              Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <_start>()\n",
      "<__main__>, line 6 in <_do_the_thing>()\n",
      "\n",
      "<file.py>, cell 18, line 33\n",
      "--->33 # this overwrites the weird comment\n",
      "         ^^^^^^^\n",
      "\n",
      "[SyntaxError]: Failed to parse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_st=StackTrace(namespace=_start)\n",
    "_st.ext(file='file.py', lineno=45, excerpt='# weird comment')\n",
    "_st=StackTrace(_do_the_thing, up=_st)\n",
    "_st.ext(cellno=18, lineno=33)\n",
    "_st.ext(excerpt = '# this overwrites the weird comment')\n",
    "_st.report_error(SyntaxError('Failed to parse'), span=(2, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StackTrace(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'test_file.py'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ext(file='test_file.py'); a._ext_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = StackTrace((lambda:'some function'), up=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lineno': 2}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.ext(lineno=2); b._ext_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Exception                                Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 1 in <<lambda>>()\n",
      "\n",
      "<test_file.py>, cell None, line 2\n",
      "\n",
      "[Exception]: OH NO! Something went wrong!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.report_error(Exception('OH NO! Something went wrong!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'test_file.py'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b._up._ext_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lineno': 2}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b._ext_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.StackTrace(namespace=<module>,line=1),\n",
       " __main__.StackTrace(namespace=<<lambda>>(),line=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Parse Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding comments in source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# TODO: Only look for 0 indent comments?\n",
    "def iter_comments(src:str, pure_comments_only:bool=True, line_limit:int=None) -> (str, (int, int)):\n",
    "    \"Detect all comments in a piece of code, excluding those that are a part of a string.\"\n",
    "    in_lstr = in_sstr = False\n",
    "    count, quote = 1, ''\n",
    "    for i, line in enumerate(src.splitlines()[:line_limit]):\n",
    "        is_pure, escape, prev_c = True, False, '\\n'\n",
    "        for j, c in enumerate(line):\n",
    "            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns\n",
    "            if is_pure and (not (c.isspace() or c == '#')): is_pure = False\n",
    "            if (in_sstr or in_lstr):\n",
    "                # assert in_sstr ^ in_lstr # XOR\n",
    "                if escape: count = 0\n",
    "                else:\n",
    "                    if (c == quote):\n",
    "                        count = ((count + 1) if (c == prev_c) else 1)\n",
    "                        if in_sstr: in_sstr = False\n",
    "                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False\n",
    "                escape = False if escape else (c == '\\\\')\n",
    "            else:                    \n",
    "                if (c == '#'):\n",
    "                    if (pure_comments_only and is_pure): yield (line, (i, j))\n",
    "                    elif (not pure_comments_only):       yield (line[j:], (i, j))\n",
    "                    break\n",
    "                elif c == \"'\" or c == '\"':\n",
    "                    count = ((count + 1) if (c == prev_c) else 1)\n",
    "                    if count == 1: in_sstr = True\n",
    "                    elif count == 3: count, in_lstr = 0, True\n",
    "                    else: assert False, 'If this code path happens, then the code keeping track of quotes is broken.'\n",
    "                    quote = c\n",
    "            prev_c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('# this is a zero indented comment', (0, 0))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iter_comments('# this is a zero indented comment'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This regex is used to remove whitespace and the '#' of python comments.  \n",
    "The content of the comment will be added to a group, which can be extracted afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_comment = re.compile(r\"\"\"\n",
    "        ^              # start of the string\n",
    "        \\s?            # 0 or 1 whitespace\n",
    "        \\#+\\s?         # 1 or more literal \"#\", then 0 or 1 whitespace\n",
    "        (.*)           # group of arbitrary symbols (except new line)\n",
    "        $              # end of the string\n",
    "        \"\"\",re.IGNORECASE | re.VERBOSE) # re.MULTILINE is not passed, since this regex is used on each line separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='# hi'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_comment.search('# hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_match_comment.search('a\\n# hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('# hi',)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_comment.search('# # hi').groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specifies what a valid nbdev comment has to look like, and filters out everything whose syntax does not fit with any of the registered commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def parse_comment(all_commands:dict, comment:str, st:StackTrace) -> (bool, str, dict, dict):\n",
    "    \"Finds command names and arguments in comments and parses them with parse_arguments()\"\n",
    "    res = re_match_comment.search(comment)\n",
    "    if not res:\n",
    "        st.report_optional_error(SyntaxError('Not a valid comment syntax.'))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    all_args = res.groups()[0].split()\n",
    "    if len(all_args) == 0:\n",
    "        st.report_optional_error(SyntaxError(f\"Need at least one argument in comment. Reveived: '{comment}'\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    cmd, *args = all_args\n",
    "    if cmd[0] != '+':\n",
    "        st.report_optional_error(SyntaxError(\"The first argument (the command to execute) does not start with a '+'.\"\\\n",
    "                                            f\"It was: '{cmd}'\"), span=(1, 3))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    cmd = cmd[1:] # remove the '+'\n",
    "    if cmd not in all_commands:\n",
    "        st.report_optional_error(KeyError(f\"'{cmd}' is not a recognized command. See 'all_commands'.\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    success, result, is_set = parse_arguments(all_commands[cmd], args)\n",
    "    if not success: return False, None, None, None\n",
    "    \n",
    "    return True, cmd, result, is_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_default_exp = {'scope': 'file' , 'to': str}\n",
    "kw_export      = {'internal': bool, 'to': ''}\n",
    "\n",
    "all_commands   = {'default_exp': kw_default_exp, 'export': kw_export}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SyntaxError]: Argument 0 ('') is not valid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, {'internal': bool, 'to': ''}, {'internal': False, 'to': False})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_arguments(all_commands['export'], '-internal -to file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 'export',\n",
       " {'internal': True, 'to': 'file.py'},\n",
       " {'internal': True, 'to': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_comment(all_commands, '# +export -internal -to file.py', st=StackTrace(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Cell from String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def from_string_cell(source:str, st:StackTrace) -> (bool, str):\n",
    "    \"Take a cell containing a single string and return the content of that string.\"\n",
    "    try: tree = ast.parse(source).body\n",
    "    except SyntaxError as e: return st.report_caught_syntax_error(e), None\n",
    "    if len(tree) == 1:\n",
    "        node = tree[0]\n",
    "        if isinstance(node, _ast.Expr):\n",
    "            if isinstance(node.value, _ast.Str):\n",
    "                code = node.value.s.strip()\n",
    "                try: ast.parse(code)\n",
    "                except SyntaxError as e:\n",
    "                    return st.report_caught_syntax_error(e, msg=\"The code in the 'from_string' \"\\\n",
    "                                                         \"cell is invalid python syntax.\"), None\n",
    "                return True, code\n",
    "#             elif isinstance(node.value, _ast.JoinedStr):\n",
    "#                 return st.report_error(SyntaxError(\"'f'-strings are not allowed.\")), None\n",
    "            else: return st.report_error(SyntaxError(f\"Expected cell to contain a single '_ast.Str' expression, \"\\\n",
    "                                                     f\"but got {type(node.value)}\")), None\n",
    "        else: return st.report_error(SyntaxError(f\"Expected cell to contain a single expression '_ast.Expr', \"\\\n",
    "                                                 f\"but got {type(node)}\")), None\n",
    "    else: return st.report_error(SyntaxError('Cell contains more than one Expression. '\\\n",
    "                                             'Expected cell to contain exactly one String.')), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['r\"\"\"\\nsetup(**setup_call)\\n\"\"\";',\n",
    "            '\"\"\"\\nsetup(**setup_call)\\n\"\"\";',\n",
    "            '\"\"\"\\nsetup(**setup_call)\\n\"\"\"',\n",
    "            '\"\"\"setup(**setup_call)\"\"\"',\n",
    "            '\"setup(**setup_call)\"',\n",
    "            'r\"setup(**setup_call)\"',\n",
    "            'r\"setup(**setup_call)\";',\n",
    "            '\"print()\"\\\\\\n\"print()\"',\n",
    "            '\"\"\"print(\\'a\\')\"\"\"\\n\"\"\"print(\\'b\\')\"\"\"',\n",
    "            '1+1\\n\"print(2)\"',\n",
    "            '\"print(2)\"\\n1+1',\n",
    "            \"f'print(1)'\",\n",
    "            'test=123',\n",
    "            \"f'''\\nprint{test}\\n''';\",\n",
    "            '1+1',\n",
    "            '!what is this???'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'setup(**setup_call)')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_string_cell(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SyntaxError                              Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 14 in <from_string_cell>()\n",
      "\n",
      "<None>, cell None, line 1\n",
      "---> 1 print()print()\n",
      "                  ^\n",
      "\n",
      "[SyntaxError]: The code in the 'from_string' cell is invalid python syntax.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_string_cell(examples[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SyntaxError                              Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 23 in <from_string_cell>()\n",
      "\n",
      "[SyntaxError]: Cell contains more than one Expression. Expected cell to contain exactly one String.\n",
      "\n",
      "--------------\n",
      "\"\"\"print('a')\"\"\"\n",
      "\"\"\"print('b')\"\"\"\n"
     ]
    }
   ],
   "source": [
    "from_string_cell(examples[8])\n",
    "print('\\n--------------')\n",
    "print(examples[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SyntaxError                              Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 21 in <from_string_cell>()\n",
      "\n",
      "[SyntaxError]: Expected cell to contain a single expression '_ast.Expr', but got <class '_ast.Assign'>\n",
      "\n",
      "--------------\n",
      "test=123\n"
     ]
    }
   ],
   "source": [
    "from_string_cell(examples[12])\n",
    "print('\\n--------------')\n",
    "print(examples[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SyntaxError                              Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 19 in <from_string_cell>()\n",
      "\n",
      "[SyntaxError]: Expected cell to contain a single '_ast.Str' expression, but got <class '_ast.JoinedStr'>\n",
      "\n",
      "--------------\n",
      "f'''\n",
      "print{test}\n",
      "''';\n"
     ]
    }
   ],
   "source": [
    "from_string_cell(examples[13])\n",
    "print('\\n--------------')\n",
    "print(examples[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SyntaxError                              Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 6 in <from_string_cell>()\n",
      "\n",
      "<None>, cell None, line 1\n",
      "---> 1 !what is this???\n",
      "       ^\n",
      "\n",
      "[SyntaxError]: invalid syntax\n",
      "\n",
      "--------------\n",
      "!what is this???\n"
     ]
    }
   ],
   "source": [
    "from_string_cell(examples[15])\n",
    "print('\\n--------------')\n",
    "print(examples[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find function, class and variable Names in Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/3/library/ast.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is using pythons builtin `ast` module to parse source code into an abstract syntax tree, from which the set of all variable-, function-, and classnames is extracted.  \n",
    "All names found, that are not private (prefixed with a single underscore), are added to a set to get rid of duplicate names.  \n",
    "It also seperately parses the nbdev-reserved special variable name `_all_` and adds all assignments to it to the set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some special cases (like fastai specific python extensions) are also handled here, although this will probably change in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debug help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def lineno(node):\n",
    "    \"Format a string containing location information on ast nodes. Used for Debugging only.\"\n",
    "    lineno     = getattr(node, 'lineno', None)\n",
    "    col_offset = getattr(node, 'col_offset', None)\n",
    "    return lineno, col_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def unwrap_attr(node:_ast.Attribute) -> str:\n",
    "    \"Joins a sequance of Attribute accesses together in a single string. e.g. numpy.array\"\n",
    "    if isinstance(node.value, _ast.Attribute): return '.'.join((unwrap_attr(node.value), node.attr))\n",
    "    else: return '.'.join((node.value.id, node.attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def unwrap_assign(node, names):\n",
    "    \"inplace, recursive update of list of names\"\n",
    "    if   isinstance(node, _ast.Name)      : names.append(node.id)\n",
    "    elif isinstance(node, _ast.Starred)   : names.append(node.value.id)\n",
    "    elif isinstance(node, _ast.Attribute) : names.append(unwrap_attr(node))\n",
    "    elif isinstance(node, _ast.Subscript) : pass # e.g. a[0] = 1\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple)):\n",
    "        for x in node.elts: unwrap_assign(x, names)\n",
    "    elif isinstance(node, list):\n",
    "        for x in node: unwrap_assign(x, names)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def not_private(name): return not (name.startswith('_') and (not name.startswith('__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def resolve_decorator_name(node):\n",
    "    if   isinstance(node, _ast.Name): return node.id\n",
    "    elif isinstance(node, _ast.Call):\n",
    "        if   isinstance(node.func, _ast.Name     ): return node.func.id\n",
    "        elif isinstance(node.func, _ast.Attribute): return unwrap_attr(node.func)\n",
    "    elif isinstance(node, _ast.Attribute): return unwrap_attr(node)\n",
    "    raise SyntaxError(f'Can\\'t resolve decorator {node} to name, unknown type.')\n",
    "\n",
    "def decorators(node): yield from (resolve_decorator_name(d) for d in node.decorator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def update_from_all_(node, names):\n",
    "    \"inplace, recursive update of set of names, by parsing the right side of a _all_ variable\"\n",
    "    if   isinstance(node, _ast.Str): names.add(node.s)\n",
    "    elif isinstance(node, _ast.Name): names.add(node.id)\n",
    "    elif isinstance(node, _ast.Attribute): names.add(unwrap_attr(node))\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "        for x in node.elts: update_from_all_(x, names)\n",
    "    elif isinstance(node, _ast.Subscript) :\n",
    "        raise SyntaxError(f'Subscript expression not allowed in _all_.')\n",
    "    elif isinstance(node, _ast.Starred):\n",
    "        raise SyntaxError(f'Starred expression *{node.value.id} not allowed in _all_.')\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +set -to_dunder_all setup MODULE_MAIN_THING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions are a mess, and hacky way to handle the fastai specific `@patch` decorator.\n",
    "```python\n",
    "def fastai_patch(cls, node, names):\n",
    "    if   isinstance(cls, _ast.Name):\n",
    "        if not_private(cls.id): names.add(f'{cls.id}.{node.name}')\n",
    "    elif isinstance(cls, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "            for x in cls.elts: fastai_patch(x, node, names)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {cls} to @patch annotation, unknown type.')\n",
    "\n",
    "def handle_fastai_specific_logic(node, names):\n",
    "    if 'patch' in decorators(node):\n",
    "        if not (len(node.args.args) >= 1):\n",
    "            raise SyntaxError(f'fastai\\'s @patch decorator requires at least one parameter.')\n",
    "        cls = node.args.args[0].annotation\n",
    "        if cls is None:\n",
    "            raise SyntaxError(f'fastai\\'s @patch decorator requires a type annotation on the first parameter.')\n",
    "        fastai_patch(cls, node, names)\n",
    "        return False\n",
    "    return True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def find_names(code:str, st:StackTrace) -> (bool, set):\n",
    "    \"Find all function, class and variable names in the given source code.\"\n",
    "    try: tree = ast.parse(code).body\n",
    "    except SyntaxError as e: return st.report_caught_syntax_error(e), None\n",
    "    names = set()\n",
    "    for node in tree:\n",
    "        if isinstance(node, (_ast.FunctionDef, _ast.ClassDef )):\n",
    "            if not_private(node.name): names.add(node.name)\n",
    "        else:\n",
    "            is_assign, is_ann_assign = isinstance(node, _ast.Assign), isinstance(node, _ast.AnnAssign)\n",
    "            if is_assign or is_ann_assign:\n",
    "                tmp_names = list()\n",
    "                if   is_assign:     unwrap_assign(node.targets, tmp_names)\n",
    "                elif is_ann_assign: unwrap_assign(node.target , tmp_names)\n",
    "                for name in tmp_names:\n",
    "                    if not_private(name): names.add(name)\n",
    "                    # NOTE: special reserved var names can only use private variable names\n",
    "                    elif name == '_all_': # NOTE: _all_ is a keyword reserved by nbdev.\n",
    "                        if len(tmp_names) != 1:\n",
    "                            raise SyntaxError(f'Reserved keyword \"_all_\" can only be used in simple assignments.')\n",
    "                        update_from_all_(node.value, names)\n",
    "    return True, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "def abc():\n",
    "    pass\n",
    "    \n",
    "b = abc()\n",
    "a, *ayy_ = range(100)\n",
    "_all_ = [a, v, 'g', _i]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, {'_i', 'a', 'abc', 'ayy_', 'b', 'g', 'v'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_names(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, {'x'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_names('x = 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relativify import statements in output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is responsible for transforming import statements.  \n",
    "It only affects 'from' imports of the library the project belongs to.  \n",
    "So if the project library is called \"my_library\", then `from my_library import *` might be transformed into `from . import *` in the output file.  \n",
    "The relative path is generated in such a way that it will be a valid import from the file the code is exported to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"normal\" `import module` statement does not allow relative module names, so it can not be translated from an absolute version in the notebook to a relative one in the output file.  \n",
    "Similarly, using a relative module name in the notebook in a `from .module import ...` statement does not work due to the interactive nature of the notebook environment.  \n",
    "Those two cases are not supported for automatic translation since they would require a very hacky solution, which can not be guaranteed to be always correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def make_import_relative(p_from:Path, m_to:str)->str:\n",
    "    \"Convert a module `m_to` to a name relative to `p_from`.\"\n",
    "    mods = m_to.split('.')\n",
    "    splits = str(p_from).split(os.path.sep)\n",
    "    if mods[0] not in splits: return m_to\n",
    "    i=len(splits)-1\n",
    "    while i>0 and splits[i] != mods[0]: i-=1\n",
    "    splits = splits[i:]\n",
    "    while len(mods)>0 and splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]\n",
    "    return '.' * len(splits) + '.'.join(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2, n3, n4, n5 = 'nbdev.core', 'nbdev.core', 'nbdev.vision.transform', 'nbdev.notebook.core', 'nbdev.vision'\n",
    "p1, p2, p3 = Path('./nbdev/data.py').absolute(), Path('./nbdev/vision/data.py'), Path('./nbdev/vision/data.py')\n",
    "p4, p5     = Path('./nbdev/data/external.py'), Path('./nbdev/vision/learner.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(make_import_relative(p1, n1),'.core')\n",
    "test_eq(make_import_relative(p2, n2),'..core')\n",
    "test_eq(make_import_relative(p3, n3),'.transform')\n",
    "test_eq(make_import_relative(p4, n4),'..notebook.core')\n",
    "test_eq(make_import_relative(p5, n5),'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%%timeit\n",
    ">>> 8.49 µs ± 23.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "letter = 'a-zA-Z'\n",
    "identifier = f'[{letter}_][{letter}0-9_]*'\n",
    "re_import = ReLibName(fr\"\"\"\n",
    "    ^                             # start of the string / line\n",
    "    (\\ *)                         # any amount of whitespace (indenting)\n",
    "    from(\\ +)                     # 'from', followed by at least one whitespace\n",
    "    (LIB_NAME(?:\\.{identifier})*) # Name of the library, possibly followed by dot separated submodules\n",
    "    \\ +import(.+)                 # whitespace, then 'import', followed by arbitrary symbols except new line\n",
    "    $                             # end of the string / line\n",
    "    \"\"\", re.VERBOSE | re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def relativify_imports(origin:Path, code:str)->str:\n",
    "    \"Transform an absolute 'from LIB_NAME import module' into a relative import of 'module' wrt the library.\"\n",
    "    def repl(match):\n",
    "        sp1,sp2,module,names = match.groups()\n",
    "        return f'{sp1}from{sp2}{make_import_relative(origin, m_to=module)} import{names}'\n",
    "    return re_import.re.sub(repl,code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod\n",
      "import nbdev_rewrite.vision\n",
      "# Nothing to see here\n",
      "from   ..abc import array as arr, linalg.solve, module as mod\n",
      "def function():\n",
      "    \"from nbdev_rewrite import *\"\n",
      "    pass\n",
      "from     .. import (abs, b as c, h,) # sure\n",
      "from .. import *\n",
      "from ..core import* # ok\n",
      "    from . import *\n",
      "from .. import(\n",
      "    abs\n",
      "                  as a\n",
      "    , # this is weird, but legal\n",
      "                       absolute \n",
      "    as \n",
      "                  f\n",
      "                  )\n"
     ]
    }
   ],
   "source": [
    "print(relativify_imports(Path('./nbdev_rewrite/submodule/data.py'),\"\"\"\n",
    "import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod\n",
    "import nbdev_rewrite.vision\n",
    "# Nothing to see here\n",
    "from   nbdev_rewrite.abc   import array as arr, linalg.solve, module as mod\n",
    "def function():\n",
    "    \"from nbdev_rewrite import *\"\n",
    "    pass\n",
    "from     nbdev_rewrite import (abs, b as c, h,) # sure\n",
    "from nbdev_rewrite import *\n",
    "from nbdev_rewrite.core import* # ok\n",
    "    from . import *\n",
    "from nbdev_rewrite  import(\n",
    "    abs\n",
    "                  as a\n",
    "    , # this is weird, but legal\n",
    "                       absolute \n",
    "    as \n",
    "                  f\n",
    "                  )\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def init_lib():\n",
    "    \"initialize the module folder, if it's not initialized already\"\n",
    "    C = Config()\n",
    "    if (not C.lib_path.exists()) or (not (C.lib_path/'__init__.py').exists()):\n",
    "        C.lib_path.mkdir(parents=True, exist_ok=True)\n",
    "        with (C.lib_path/'__init__.py').open('w') as f:\n",
    "            f.write(f'__version__ = \"{C.version}\"\\n')\n",
    "    else: pass # module *should* already exists\n",
    "init_lib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Path Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identify modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use pattern matching to identify valid module names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/2.0/ref/identifiers.html  \n",
    "```\n",
    "identifier:     (letter|\"_\") (letter|digit|\"_\")*\n",
    "letter:         lowercase | uppercase\n",
    "lowercase:      \"a\"...\"z\"\n",
    "uppercase:      \"A\"...\"Z\"\n",
    "digit:          \"0\"...\"9\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/2.0/ref/import.html  \n",
    "```\n",
    "import_stmt:    \"import\" module [\"as\" name] (\",\" module [\"as\" name] )* \n",
    "              | \"from\" module \"import\" identifier [\"as\" name]\n",
    "                (\",\" identifier [\"as\" name] )*\n",
    "              | \"from\" module \"import\" \"*\" \n",
    "module:         (identifier \".\")* identifier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "letter = 'a-zA-Z'\n",
    "identifier = f'[{letter}_][{letter}0-9_]*'\n",
    "module = fr'(?:{identifier}\\.)*{identifier}'\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_module = re.compile(fr\"\"\"\n",
    "        ^              # start of the string\n",
    "        {module}       # definition for matching a module \n",
    "        $              # end of the string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 16), match='module.main.test'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_module.search('module.main.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def module_to_path(m:str, st:StackTrace)->(bool, Path):\n",
    "    \"Turn a module name into a path such that the exported file can be imported from the library \"\\\n",
    "    \"using the same expression.\"\n",
    "    if re_match_module.search(m) is not None:\n",
    "        if m.endswith('.py'):\n",
    "            return st.report_error(ValueError(f\"The module name '{m}' is not valid, because ending on '.py' \"\\\n",
    "                                f\"would produce a file called 'py.py' in the folder '{m.split('.')[-2]}', \"\\\n",
    "                                 \"which is most likely not what was intended.\\nTo name a file 'py.py', use the \"\\\n",
    "                                 \"'-to_path' argument instead of '-to'.\")), None\n",
    "        return True, Config().path_to('lib')/f\"{os.path.sep.join(m.split('.'))}.py\"\n",
    "    else: return st.report_error(ValueError(f\"'{m}' is not a valid module name.\")), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/module/sub/file.py'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_to_path('module.sub.file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "ValueError                               Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 13 in <module_to_path>()\n",
      "\n",
      "[ValueError]: 'lalala :) lalala' is not a valid module name.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_to_path('lalala :) lalala')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions might come in handy late on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import importlib.util\n",
    "# importlib.util._resolve_name\n",
    "# importlib.util.resolve_name\n",
    "importlib.util.resolve_name('..export', 'module.test')\n",
    ">>> 'module.export'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identify paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the user explicitly passes a path, then this code is tasked with checking it for correctness and converting it to an absolute path from the perspective of the library path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def commonpath(*paths)->Path:\n",
    "    \"Given a sequence of path names, returns the longest common sub-path.\"\n",
    "    return Path(os.path.commonpath(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/abc/fgh')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonpath(Path('c:/abc/fgh/a'), Path('c:/abc/fgh/b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def in_directory(p:Path, d:Path)->bool:\n",
    "    \"Tests if `p` is pointing to something in the directory `d`.\\n\"\\\n",
    "    \"Expects both `p` and `d` to be fully resolved and absolute paths.\"\n",
    "    return p.as_posix().startswith(d.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_directory_slow_1(p, d)->bool:\n",
    "    try: p.relative_to(d)\n",
    "    except: return False\n",
    "    else: return True\n",
    "def in_directory_slow_2(p, d)->bool:\n",
    "    return len(commonpath(p, d).parts) >= len(d.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_directory(p=Path('C:/abc/fgh/abc.txt'), d=Path('C:/abc/fgh/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def make_valid_path(s:str, st:StackTrace)->(bool, Path):\n",
    "    \"Turn a export path argument into a valid path, resolving relative paths and checking for mistakes.\"\n",
    "    config = Config()\n",
    "    p, lib, proj = Path(s), config.path_to('lib'), config.config_file.parent\n",
    "    is_abs = p.is_absolute()\n",
    "    p = (p if is_abs else (lib/p)).absolute().resolve()\n",
    "    if (not is_abs) and (not in_directory(p, proj)):\n",
    "        return st.report_error(ValueError(\"Relative export path beyond top level directory of project \"\\\n",
    "                                          \"is not allowed by default. Use an absolute path, \"\\\n",
    "                                          f\"or set <NOT IMPLEMENTED YET> flag on the command. ('{s}')\")), None\n",
    "    if not p.suffix:\n",
    "        return st.report_error(ValueError(f\"The path '{s}' is missing a file type suffix like '.py'.\")), None\n",
    "    if p.suffix == '.py': return True, p\n",
    "    else: return st.report_error(ValueError(f\"Expected '.py' file ending, but got '{p.suffix}'. ('{s}')\")), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/hi.py'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path(Path('./module/../hi.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/main.py'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path('main.py')\n",
    "make_valid_path('./main.py')\n",
    "make_valid_path('../../nbdev_rewrite/nbdev_rewrite/main.py')\n",
    "make_valid_path('d:/main.py')\n",
    "make_valid_path('main/main.py')\n",
    "make_valid_path('../nbdev_rewrite/main.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "ValueError                               Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 16 in <make_valid_path>()\n",
      "\n",
      "[ValueError]: Expected '.py' file ending, but got '.pyy'. ('test.pyy')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path('test.pyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/test.py'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path('../test.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "ValueError                               Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <module>\n",
      "<__main__>, line 10 in <make_valid_path>()\n",
      "\n",
      "[ValueError]: Relative export path beyond top level directory of project is not allowed by default. Use an absolute path, or set <NOT IMPLEMENTED YET> flag on the command. ('../../test.py')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path('../../test.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@register_command` stores argument information about the registered function in the global variables `all_commands`, and a reference to the function in `cmd2func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def register_command(cmd, args, active=True):\n",
    "    \"Store mapping from command name to args, and command name to reference to the decorated function in globals.\"\n",
    "    if not active: return lambda f: f\n",
    "    all_commands[cmd] = args\n",
    "    def _reg(f):\n",
    "        cmd2func[cmd] = f\n",
    "        return f\n",
    "    return _reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "all_commands = {}\n",
    "cmd2func     = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful with the order of the decorators!!!  \n",
    "Since `@register_command` stores a reference to the function, and `@traced` modifies the function, they are not commutative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@register_command(cmd='default_exp', # allow custom scope name that can be referenced in export?\n",
    "                  args={'to': '', 'to_path': '', 'no_dunder_all': False, 'scoped': False})\n",
    "@Traced\n",
    "def kw_default_exp(file_info, cell_info, result, is_set, st:StackTrace) -> bool:\n",
    "    \"Set the default file that cells of this notebook will be exported to.\"\n",
    "    success:bool = True\n",
    "    if not (is_set['to'] ^ is_set['to_path']): # NOTE: XOR\n",
    "        return st.report_error(ValueError(\"The `default_exp` command expects exactly one of the arguments \"\\\n",
    "                               f\"'-to' or '-to_path' to be set, but recieved was: {result}\"))\n",
    "    # NOTE: use this cells indentation level, or the default tuple([0]) as key to identify scope\n",
    "    scope:tuple     = cell_info['scope'] if result['scoped'] else tuple([0])\n",
    "    old_target:Path = file_info['export_scopes'].get(scope, None)\n",
    "    conv_success, new_target = (module_to_path(result['to'], st=st)\n",
    "                                if is_set['to'] else\n",
    "                                make_valid_path(result['to_path'], st=st))\n",
    "    if not conv_success: return False\n",
    "    if old_target is not None:\n",
    "        if old_target['target'] != new_target:\n",
    "            return st.report_error(ValueError(f\"Overwriting an existing export target is not allowed.\"\\\n",
    "                            f\"\\n\\twas (cell {old_target['cell_info']['cell_nr']}): '{old_target['target']}'\"\\\n",
    "                            f\"\\n\\tnew (cell {cell_info['cell_nr']}): '{new_target}'\"))\n",
    "        else: pass # TODO: issue a warning in this case\n",
    "    file_info['export_scopes'][scope] = {\n",
    "        'target' : new_target,\n",
    "        'add_dunder_all' : (not result['no_dunder_all']),\n",
    "        'cell_info' : cell_info,\n",
    "    }\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert kw_default_exp == cmd2func['default_exp'], 'are the decorators in the right order?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@register_command(cmd='export',\n",
    "                  args={'internal': False, 'to': '', 'to_path':'', 'ignore_scope':False, 'from_string':False})\n",
    "@Traced\n",
    "def kw_export(file_info, cell_info, result, is_set, st:StackTrace) -> bool:\n",
    "    \"This cell will be exported from the notebook to a .py file.\"\n",
    "    success:bool = True\n",
    "    if (is_set['to'] and is_set['to_path']):\n",
    "        return st.report_error(ValueError(\"The `export` command does not accept the '-to' and '-to_path' \"\\\n",
    "                               f\"argument at the same time. They are mutually exclusive. Received: {result}\"))\n",
    "    cell_info['export_to_py'] = True # Using this command implicitly means to export this cell\n",
    "    if result['from_string']:\n",
    "        # TODO: unwrap cell content\n",
    "        # from_string_cell(cell_info['original_source_code'])\n",
    "        pass\n",
    "    is_internal = cell_info['is_internal'] = result['internal']\n",
    "    if is_internal: pass # no contained names will be added to __all__ for importing\n",
    "    else: success, cell_info['names'] = find_names(cell_info['original_source_code'])\n",
    "    conv_success, export_target = True, None\n",
    "    if is_set['to'     ]: conv_success, export_target = module_to_path (result['to'], st=st)\n",
    "    if is_set['to_path']: conv_success, export_target = make_valid_path(result['to_path'], st=st)\n",
    "    if not conv_success: return False\n",
    "    if export_target is not None:\n",
    "        if is_set['ignore_scope']:\n",
    "            return st.report_error(ValueError(\"Setting 'ignore_scope' is not allowed when \"\\\n",
    "                                   f\"exporting to a custom target using 'to' or 'to_path'.\"))\n",
    "        cell_info['export_to'].append(export_target) # Set a new export target just for this cell.\n",
    "    else:\n",
    "        if result['ignore_scope']: cell_info['export_to_default'] += 1\n",
    "        else:                      cell_info['export_to_scope']   += 1\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert kw_export == cmd2func['export'], 'are the decorators in the right order?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_command(cmd='set',\n",
    "                  args={'file': '', 'use_names': True},\n",
    "                  active=False)\n",
    "@Traced\n",
    "def kw_set(file_info, cell_info, result, is_set, st:StackTrace) -> bool:\n",
    "    \"set some predefined variables that control execution behaviour\"\n",
    "    success:bool = True\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `default_exp`  \n",
    "Set the default file that cells of this notebook will be exported to.  \n",
    "Args:\n",
    "- `to`: The target file written in a python module form. \n",
    "- `to_path`: The target file as a relative or absolute path.\n",
    "- `scoped`: Flag for setting the export target only for the scope that the command has been invoked from. Scopes are implicitly set by markdown cells with different levels of headings.\n",
    "- `no_dunder_all` : The target file will not have a `__all__` defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `export`  \n",
    "This cell will be exported from the notebook to a .py file.  \n",
    "Args:  \n",
    "- `internal`: The variable, function and class names of this cell will not be added to `__all__` in the exported file, making them hidden from any `import *`.\n",
    "- `to`: Instead of exporting to the notebook or scope wide default file, this cell is exported to the file specified in this argument. File is written in python module form.\n",
    "- `to_path`: The same as `to`, but this argument is written as a path.\n",
    "- `ignore_scope`: This cell ignores any export targets set for the scope it resides in, and instead always uses the default for the entire notebook. This argument is incompatible with `to` and `to_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `set`  \n",
    "Set some predefined variables that control execution behaviour.  \n",
    "Args:  \n",
    "- `file`: If this is set, the variables will only be set on this specific file.\n",
    "- `use_names`: Control whether or not a `__all__` with all (non internal) variable, function and class names should be inserted at the top of the file. Default is `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Improve `init_lib()`\n",
    "- Generalize the `relative_path()` function currently under error reporting\n",
    "- Maybe add reverse mapping from  commands to cells that use those commands\n",
    "- Add better debugging information.\n",
    "- Think about how a change to a .py file could be re-ported into the notebook.\n",
    "- fix settings propagation to imported modules, e.g. Argument Parsing print options don't work properly when they are a second hand import.\n",
    "- Only keep cells that contain commands / ones that are supposed to be exported and throw away the rest as soon as possible. This could become important if notebooks contain lots of large images or other data.\n",
    "    - Keeping all the cells is done in anticipation of handing over control to a meta program, which might still need those cells we deem unnecessary, and because it is easier to modify the program if the original state of all cells is available at every step, only with additional state being added.\n",
    "- Should `find_names()` be executed at the very end, during exporting, after it has been decided if it is actually necessary? Even if it's not `internal`, its export scope might have `no_dunder_all` set.\n",
    "- in name parsing `find_names()`:\n",
    "    - improve error messages\n",
    "    - replace `SyntaxError` with something like `CompilerError` in `find_names()`, to signal to the user that it's not their fault, but a missing case in this program.\n",
    "    - remove fastai specific code from the `find_names()` code, and instead implement that logic in a meta program\n",
    "- in commands:\n",
    "    - Add aliases to commands / arguments?\n",
    "    - add a `names_only` flag to the `export` command or a command to directly add names to `__all__`, similar to the current `_all_` hack?\n",
    "    - Add `auto` flag to `default_exp` to automatically determine export path and file name from notebook directory and name.\n",
    "    - Add a `file_documentation` command, for writing a doc string for an entire file, or for an entire module?\n",
    "- in file writing:\n",
    "    - Parallelize file writing\n",
    "    - initialize a python package, if it doesn't already exists\n",
    "    - Support Automatic / Explicit Versioning\n",
    "- global settings:\n",
    "    - seperation amount (vertical whitespace) between cells\n",
    "    - adding callbacks?\n",
    "    - overwriting parsing functions?\n",
    "    - recursively search for files?\n",
    "    - overwrite config paths?\n",
    "    - Most of these should probably NOT be allowed, because (a) it would be a nightmare to reason about, (b) if file 1 sets the setting one way and file 2 sets it a different way, how do we deal with that?, (c) there already is a way to do some of these settings, namely in the config. Global settings should be done in the config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "_reserved_dirs = (Config().lib_path, Config().doc_path)\n",
    "def crawl_directory(path:Path, recurse:bool=True) -> list:\n",
    "    \"Crawl the `path` directory for a list of .ipynb files.\"\n",
    "    # TODO: Handle symlinks?\n",
    "    if isinstance(path, (list, tuple, set)):\n",
    "        for p in path: yield from crawl_directory(p, recurse)\n",
    "    else:\n",
    "        if path.is_file(): yield path\n",
    "        else:\n",
    "            for p in path.iterdir():\n",
    "                fn = p.name\n",
    "                if fn.startswith('.') or fn.startswith('_'): continue\n",
    "                if p.is_file():\n",
    "                    if fn.endswith('.ipynb'): yield p\n",
    "                    else: continue\n",
    "                elif p.is_dir() and recurse:\n",
    "                    if p in _reserved_dirs: continue\n",
    "                    else: yield from crawl_directory(p, recurse)\n",
    "                else: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def read_nb(fname:Path) -> dict:\n",
    "    \"Read the `fname` notebook.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return dict(nbformat.reads(f.read(), as_version=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@prefetch(max_prefetch=-1) # NOTE: max_prefetch <= 0 means the queue size is infinite\n",
    "def async_load_notebooks(path:Path=Config().nbs_path, recurse:bool=True) -> (Path, dict):\n",
    "    \"Crawl for notebooks in the `path` directory, and load in a background thread.\"\n",
    "    for file_path in crawl_directory(path, recurse): yield (file_path, read_nb(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/notebooks/00_export_v4.ipynb'),\n",
       " WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/notebooks/99_index.ipynb')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(crawl_directory(Config().nbs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = read_nb(THIS_FILE)\n",
    "len(nb['cells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [len(x[1]['cells']) for x in async_load_notebooks()]\n",
    "#>[90, 2, 100, 174, 31, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_heading = re.compile(r\"\"\"\n",
    "        ^              # start of the string\n",
    "        (\\#+)\\s+       # 1 or more literal \"#\", then 1 or more whitespace\n",
    "        (.*)           # group of arbitrary symbols (including new line)\n",
    "        $              # end of the string\n",
    "        \"\"\",re.IGNORECASE | re.VERBOSE | re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('##', 'test')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = re_match_heading.search('## test')\n",
    "res.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "class DictLikeAccess():\n",
    "    __slots__ = []\n",
    "    def __getitem__(self, key):        return getattr(self, key)\n",
    "    def __setitem__(self, key, value): return setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "class DictLikeRepr():\n",
    "    __slots__ = []\n",
    "    def __repr__(self):\n",
    "        s = self.__class__.__name__ + ' {\\n'\n",
    "        for key in self.__slots__:\n",
    "            s += f'\\t{key} : {getattr(self, key, None).__repr__()},\\n'\n",
    "        return s+'}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportUnit(DictLikeAccess, DictLikeRepr):\n",
    "    __slots__ = ('cell_nr', 'scope', 'is_internal', 'names',\n",
    "                 'source_code', 'export_to',\n",
    "                 'export_to_scope', 'export_to_default')\n",
    "    def __init__(self, cell_nr, scope, source_code):\n",
    "        self.cell_nr           = cell_nr\n",
    "        self.scope             = scope\n",
    "        self.source_code       = source_code\n",
    "        self.is_internal       = None\n",
    "        self.names             = None\n",
    "        self.export_to         = list()\n",
    "        self.export_to_scope   = 0\n",
    "        self.export_to_default = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ExportUnit(0, (0,), 'x=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['cell_nr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExportUnit {\n",
       "\tcell_nr : 0,\n",
       "\tscope : (0,),\n",
       "\tis_internal : None,\n",
       "\tnames : None,\n",
       "\tsource_code : 'x=1',\n",
       "\texport_to : [],\n",
       "\texport_to_scope : 0,\n",
       "\texport_to_default : 0,\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "class FileInfo(DictLikeAccess, DictLikeRepr):\n",
    "    __slots__ = ('origin_file', 'relative_origin', 'nb_version',\n",
    "                 'export_scopes', 'cells', 'export_units')\n",
    "    def __init__(self, origin_file, nb_version,\n",
    "                 export_scopes=None, cells=None, export_units=None):\n",
    "        self.origin_file     = origin_file\n",
    "        self.relative_origin = os.path.relpath(origin_file, Config().config_file.parent).replace('\\\\', '/')\n",
    "        self.nb_version      = nb_version\n",
    "        self.export_scopes   = {(0,): None} if (export_scopes is None) else export_scopes\n",
    "        self.cells           = list()       if (cells         is None) else cells\n",
    "        self.export_units    = list()       if (export_units  is None) else export_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(THIS_FILE).absolute().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = FileInfo(p, (3, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['cells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['origin_file'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['origin_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = FileInfo(p, (3, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cells.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileInfo {\n",
       "\torigin_file : '1',\n",
       "\trelative_origin : 'notebooks/00_export_v4.ipynb',\n",
       "\tnb_version : (3, 7),\n",
       "\texport_scopes : {(0,): None},\n",
       "\tcells : [1],\n",
       "\texport_units : [],\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileInfo {\n",
       "\torigin_file : WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/notebooks/00_export_v4.ipynb'),\n",
       "\trelative_origin : 'notebooks/00_export_v4.ipynb',\n",
       "\tnb_version : (3, 7),\n",
       "\texport_scopes : {(0,): None},\n",
       "\tcells : [],\n",
       "\texport_units : [],\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def parse_file(file_path:Path, file:dict, st:StackTrace) -> (bool, dict):\n",
    "    success = True\n",
    "    pure_comments_only = True\n",
    "    nb_version:(int, int) = (file['nbformat'], file['nbformat_minor'])\n",
    "    metadata  :dict       =  file['metadata']\n",
    "    \n",
    "    file_info = FileInfo(origin_file = file_path,\n",
    "                         nb_version  = nb_version)\n",
    "#     file_info = {\n",
    "#         'origin_file': file_path,\n",
    "#         'relative_origin': os.path.relpath(file_path, Config().config_file.parent).replace('\\\\', '/'),\n",
    "#         'nb_version': nb_version,\n",
    "#         'export_scopes': {\n",
    "#             (0,): None, # NOTE: (0,) maps to the default target for an entire file.\n",
    "#         },\n",
    "#         'cells': list(),\n",
    "#         'export_units' : list(),\n",
    "#     }\n",
    "    scope_count :[int] = [0]\n",
    "    scope_level :int   = 0\n",
    "    \n",
    "    cells:list = file_info['cells']\n",
    "    \n",
    "    st.ext(file=file_info['relative_origin'])\n",
    "    \n",
    "    for i, cell in enumerate(file['cells']):\n",
    "        cell_type   = cell['cell_type']\n",
    "        cell_source = cell['source']\n",
    "        cell_info = {\n",
    "            'cell_nr' : i,\n",
    "            'cell_type' : cell_type,\n",
    "            'original_source_code' : cell_source,\n",
    "            'processed_source_code': cell_source,\n",
    "            'scope' : tuple(scope_count),\n",
    "            'export_to_py' : False,\n",
    "            'export_to_scope' : 0,\n",
    "            'export_to_default' : 0,\n",
    "            'is_internal' : None,\n",
    "            'export_to' : [],\n",
    "            'names' : None,\n",
    "            'comments' : []\n",
    "        }\n",
    "        if cell_type == 'code':\n",
    "            st.ext(cellno = i)\n",
    "            comments_to_remove = []\n",
    "            for comment, (lineno, charno) in iter_comments(cell_source, pure_comments_only, line_limit=None):\n",
    "                st.ext(lineno = lineno + 1) # zero counting offset\n",
    "                st.ext(excerpt = comment)\n",
    "                parsing_success, cmd, result, is_set = parse_comment(all_commands,comment,st=st)\n",
    "                if not parsing_success: continue\n",
    "                # TODO: cound nr of found cells\n",
    "                if main_REPORT_COMMAND_FOUND:\n",
    "                    print(f'Found: {cmd} @ ({i}, {lineno}, {charno}) with args: {result}')\n",
    "                if cmd in cmd2func:\n",
    "                    cmd_success = cmd2func[cmd](file_info, cell_info, result, is_set, st=st)\n",
    "                    if not cmd_success: return False, file_info # TODO: Stop at first error or continue?\n",
    "                else: raise ValueError(f\"The command '{cmd}' in cell number {i} is recognized, \"\\\n",
    "                                        \"but is missing a corresponding action mapping in cmd2func.\")\n",
    "                cell_info['comments'].append(comment)\n",
    "                comments_to_remove.append((lineno, charno))\n",
    "            if len(comments_to_remove) > 0:\n",
    "                lines = cell_source.splitlines()\n",
    "                if pure_comments_only:\n",
    "                    for lineno, charno in comments_to_remove[::-1]: lines.pop(lineno)\n",
    "                else:\n",
    "                    for lineno, charno in comments_to_remove[::-1]: lines[lineno] = lines[lineno][:charno]\n",
    "                cell_info['processed_source_code'] = '\\n'.join(lines)\n",
    "            \n",
    "        elif cell_type == 'markdown':\n",
    "            res = re_match_heading.search(cell_source)\n",
    "            if not (res is None): # this cell contains a heading\n",
    "                heading_level, heading_name = res.groups()\n",
    "                new_scope_level = len(heading_level) # number of '#' in the heading\n",
    "                if new_scope_level > scope_level:\n",
    "                    scope_count += ([0] * (new_scope_level - (len(scope_count)))) # extend list if necessary\n",
    "                elif new_scope_level < scope_level:\n",
    "                    scope_count = scope_count[:new_scope_level] # reset lower values\n",
    "                scope_count[new_scope_level - 1] += 1\n",
    "                scope_level = new_scope_level\n",
    "            else: pass # this cell is regular markdown\n",
    "        elif cell_type == 'raw': pass\n",
    "        else: raise ValueError(f\"Unknown cell_type '{cell_type}' in cell number {i}.\"\\\n",
    "                                \"Should be 'code', 'markdown', or 'raw'.\")\n",
    "        cells.append(cell_info)\n",
    "    return success, file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def parse_all(file_generator, st:StackTrace) -> (bool, dict):\n",
    "    \"Loads all .ipynb files in the origin_path directory, and passes them one at a time to parse_file.\"\n",
    "    success:bool = True\n",
    "    parsed_files = {\n",
    "        # Add flags and settings variables above this line\n",
    "        'files': list()\n",
    "    }\n",
    "    # TODO: use multithreading / multiprocessing per file / per n cells\n",
    "    for file_path, file in file_generator:\n",
    "        # if file_path.name != THIS_FILE: continue # For Debugging\n",
    "        parse_success, file = parse_file(file_path, file, st=st)\n",
    "        if not parse_success:\n",
    "            success = False # TODO: Stop at first error or continue?\n",
    "        # TODO: before returning, give any meta programm a chance to run.\n",
    "        # maybe have parse_file return some additional information about any meta programm\n",
    "        parsed_files['files'].append(file)\n",
    "        \n",
    "    return success, parsed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def merge_all(parsed_files:dict, st:StackTrace) -> (bool, dict):\n",
    "    success:bool = True\n",
    "    config    = Config()\n",
    "    lib_path  = config.lib_path\n",
    "    nbs_path  = config.nbs_path\n",
    "    proj_path = config.config_file.parent\n",
    "    zero_tuple = (0,)\n",
    "    \n",
    "    # NOTE: This will contain all the merges files\n",
    "    export_files = defaultdict(lambda: {'names': set(), 'code': [], 'orig': None, 'add_dunder_all':None})\n",
    "    \n",
    "    for file_info in parsed_files['files']:\n",
    "        rel_orig:str = file_info['relative_origin']\n",
    "        st.ext(file=rel_orig)\n",
    "        st.ext_clear_cellno() # NOTE: Clear cellno, because this is a new file.\n",
    "        scopes:dict  = file_info['export_scopes']\n",
    "        assert zero_tuple in scopes, 'No default in export Scopes.'\n",
    "        scopes_available:bool = (len(scopes) > 1)\n",
    "        default_scope   :dict = scopes[zero_tuple]\n",
    "        # NOTE: Having no default is ok, as long as all cells still have a valid export target\n",
    "        none_default    :bool = (default_scope is None)\n",
    "        default_export  :Path = None if none_default else default_scope['target']\n",
    "            \n",
    "        if not none_default:\n",
    "            # NOTE: Set this notebooks default as the origin of one of the `export_files`.\n",
    "            default_state:dict = export_files[default_export]\n",
    "            if (default_state['orig'] is None): default_state['orig'] = rel_orig\n",
    "            else: return st.report_error(\n",
    "                ValueError(f'Multiple files have {default_export} as the default export target. '\\\n",
    "                           f'(old: {default_state[\"orig\"]} | new: {rel_orig})')), None\n",
    "                \n",
    "        for cell in file_info['cells']:\n",
    "            # NOTE: At this point, the `file_info` still contains all of the original cells of the notebook\n",
    "            if not cell['export_to_py']: continue\n",
    "            st.ext(cellno=cell[\"cell_nr\"])\n",
    "            info_string = f\"# {'Internal ' if cell['is_internal'] else ''}Cell nr. {cell['cell_nr']}\"\n",
    "            info_string_src = (info_string + f\"; Comes from '{rel_orig}'\")\n",
    "            \n",
    "            # NOTE: Handle a cell directly specifying its export target\n",
    "            if len(cell['export_to']) > 0:\n",
    "                for to in cell['export_to']:\n",
    "                    state:dict = export_files[to]\n",
    "                    if not cell['is_internal']: state['names'].update(cell['names'])\n",
    "                    state['code'].append(f\"{info_string_src}\\n{relativify_imports(to, cell['processed_source_code'])}\")\n",
    "            \n",
    "            # NOTE: Handle a cell belonging to a scope and find the best match\n",
    "            if scopes_available:\n",
    "                if cell['export_to_scope'] > 0:\n",
    "                    # Do scope matching\n",
    "                    cell_scope:tuple = cell['scope']\n",
    "                    best_fit = zero_tuple\n",
    "                    best_fit_len = 0\n",
    "                    # NOTE: The number of scopes should usually be relatively small, so this should be fine.\n",
    "                    for k in scopes.keys():\n",
    "                        if ((len(k) > best_fit_len) # Trying to find the tightest fit\n",
    "                            and (k == cell_scope[:len(k)])): # iff cell is part of this scope\n",
    "                            best_fit, best_fit_len = k, len(k)\n",
    "                    to:Path = scopes[best_fit]['target']\n",
    "                    if (best_fit == zero_tuple) or (to == default_export):\n",
    "                        cell['export_to_default'] += cell['export_to_scope']\n",
    "                        cell['export_to_scope'] = 0\n",
    "                        pass\n",
    "                    else:\n",
    "                        state:dict = export_files[to]\n",
    "                        if not cell['is_internal']: state['names'].update(cell['names'])\n",
    "                        for _ in range(cell['export_to_scope']):\n",
    "                            state['code'].append(f\"{info_string_src}\\n{relativify_imports(to, cell['processed_source_code'])}\")\n",
    "            else:\n",
    "                cell['export_to_default'] += cell['export_to_scope']\n",
    "                cell['export_to_scope'] = 0\n",
    "            \n",
    "            # NOTE: Handle a cell ignoring all scopes, or being in the default scope.\n",
    "            if cell['export_to_default'] > 0:\n",
    "                if none_default:\n",
    "                    return st.report_error(ValueError(f'Cell does not have a export target. '\\\n",
    "                                     'Did you forget to add a default target using `default_exp`?')), None\n",
    "                to:Path = default_export\n",
    "                state:dict = export_files[to]\n",
    "                if not cell['is_internal']: state['names'].update(cell['names'])\n",
    "                for _ in range(cell['export_to_default']):\n",
    "                    state['code'].append(f\"{info_string}\\n{relativify_imports(to, cell['processed_source_code'])}\")\n",
    "        # NOTE: Set 'add_dunder_all' and check for mismatches\n",
    "        for k, v in scopes.items(): # for all scopes that this files exports to\n",
    "            if v is None: continue\n",
    "            state = export_files[v['target']]\n",
    "            if   state['add_dunder_all'] is None: # it defaults to None, see top of the function\n",
    "                 state['add_dunder_all'] = v['add_dunder_all']\n",
    "            elif state['add_dunder_all'] == v['add_dunder_all']:\n",
    "                continue\n",
    "            else:\n",
    "                # TODO: To improve this error message further, information about which previous files / cells\n",
    "                # affected the same export state are necessary\n",
    "                return st.report_error(ValueError('Multiple `default_exp` commands which specify the same target '\\\n",
    "                                        'cannot have different values for the `no_dunder_all` argument.\\n'\\\n",
    "                                       f\"The value defined in cell nr {v['cell_info']['cell_nr']} in '{rel_orig}' \"\\\n",
    "                                       f'does not match with a previous definition.')), None\n",
    "        # NOTE: The files can't yet be written, because there might be other notebooks exporting to the same files.\n",
    "        # NOTE: This is the end of the \"for each file\" loop\n",
    "    return success, export_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_names(names:set, sep='\\n\\n\\n')->str:\n",
    "    start, part = \"__all__ = [\", ''\n",
    "    for name in sorted(names):\n",
    "        if len(part) + len(name) < 90:\n",
    "            part = f\"{part}'{name}', \"\n",
    "        else:\n",
    "            start += (part + '\\n')\n",
    "            part = f\"           '{name}', \"\n",
    "    return f'{sep}{start}{part[:-2]}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_names_2(names):\n",
    "    return f\"\\n\\n\\n__all__ = ['{', '.join(sorted(names))}']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "test_data = ['abc'] * 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%timeit stringify_names(test_data)\n",
    ">>> 242 µs ± 489 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%timeit stringify_names_2(test_data)\n",
    ">>> 18 µs ± 146 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def write_file(to:Path, state:dict, st:StackTrace) -> bool:\n",
    "    success:bool = True\n",
    "    orig:str  = state['orig']\n",
    "    names:set = state['names']\n",
    "    code:list = state['code']\n",
    "    add_dunder_all:bool = state['add_dunder_all']\n",
    "    sep:str = '\\n\\n\\n'\n",
    "    if orig is None:\n",
    "        warning = f'# AUTOGENERATED! DO NOT EDIT! View info comment on each cell for file to edit.'\n",
    "    else:\n",
    "        warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {orig} (unless otherwise specified).'\n",
    "    if add_dunder_all:\n",
    "        if len(names) > 0:\n",
    "            # TODO: add line breaks at regular intervals\n",
    "            comma = \"', '\"\n",
    "            dunder_all = f\"{sep}__all__ = ['{comma.join(sorted(names))}']\"\n",
    "        else: dunder_all = f'{sep}__all__ = []'\n",
    "    else: dunder_all = ''\n",
    "    code :str = sep + sep.join(code)\n",
    "    file_content:str = f'{warning}{dunder_all}{code}'\n",
    "    to.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        with open(to, 'w', encoding='utf8') as f: f.write(file_content)\n",
    "    except Exception as e: return st.report_error(e)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def write_all(merged_files:dict, st:StackTrace) -> bool:\n",
    "    # print(dict(export_files))\n",
    "    success:bool = True\n",
    "    for to, state in merged_files.items():\n",
    "        write_success = write_file(to=to, state=state, st=st)\n",
    "        if not write_success: return False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@Traced\n",
    "def main(nbs_path:str=None, lib_path:str=None, recurse:bool=True, st:StackTrace=None) -> (bool, dict, dict):\n",
    "    \"Load, Parse, Merge, and Write .ipynb files to .py files.\"\n",
    "    success:bool = True\n",
    "    config = Config()\n",
    "    proj_path:Path = config.config_file.parent\n",
    "    nbs_path:Path  = config.nbs_path if (nbs_path is None) else Path(nbs_path).absolute().resolve()\n",
    "    lib_path:Path  = config.lib_path if (lib_path is None) else Path(lib_path).absolute().resolve()\n",
    "    \n",
    "    # NOTE: LOAD\n",
    "    notebooks = async_load_notebooks(path=nbs_path, recurse=recurse)\n",
    "    \n",
    "    # NOTE: PARSE\n",
    "    parse_success, parsed_files = parse_all(notebooks, st=st)\n",
    "    if not parse_success:\n",
    "        st.report_error(Exception('At least one Error has occured during parsing. '\\\n",
    "                                  'No files on disk have been modified. Exiting.'))\n",
    "        return False, parsed_files, None\n",
    "    \n",
    "    # NOTE: MERGE\n",
    "    merge_success, merged_files = merge_all(parsed_files, st=st)\n",
    "    if not merge_success:\n",
    "        st.report_error(Exception('At least one Error occured during merging of files to be exported. '\\\n",
    "                                  'No files on disk have been modified. Exiting.'))\n",
    "        return False, parsed_files, merged_files\n",
    "    \n",
    "    # NOTE: WRITE\n",
    "    write_success = write_all(merged_files, st=st)\n",
    "    if not write_success:\n",
    "        st.report_error(Exception('At least one Error occured during writing the parsed and merged files to disk. '\\\n",
    "                                  'Some files might have been written to disk and others might not. Exiting.'))\n",
    "        return False, parsed_files, merged_files\n",
    "    \n",
    "    if main_REPORT_RUN_STATISTICS:\n",
    "        report_successful_export(parsed_files, merged_files)\n",
    "    # NOTE: RETURN\n",
    "    return success, parsed_files, merged_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "set_arg_parse_report_options(report_error=False)\n",
    "set_main_report_options(report_optional_error=False,\n",
    "                        report_command_found=False,\n",
    "                        report_run_statistics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 notebooks have been parsed, resulting in 4 python files.\n",
      "\n",
      "The following 2 notebooks have been parsed:\n",
      "-------------------------------------------\n",
      "notebooks/00_export_v4.ipynb (302 cells total)\n",
      "---> default:\tnbdev_rewrite/main.py\n",
      "---> (1,):\tsetup.py\n",
      "---> (2,):\tnbdev_rewrite/argument_parsing.py\n",
      "---> (3,):\tnbdev_rewrite/imports.py\n",
      "notebooks/99_index.ipynb (23 cells total)\n",
      "---> default:\tNone\n",
      "\n",
      "Of the 2 notebooks parsed, 1 is outputting code.\n",
      "\n",
      "The following 4 python files have been generated:\n",
      "-------------------------------------------------\n",
      "---> 48 cells output to nbdev_rewrite/main.py\n",
      "---> 25 cells output to setup.py\n",
      "---> 14 cells output to nbdev_rewrite/argument_parsing.py\n",
      "---> 20 cells output to nbdev_rewrite/imports.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "success, parsed_files, merged_files = main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev_rewrite.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 notebooks have been parsed, resulting in 4 python files.\n",
      "\n",
      "The following 2 notebooks have been parsed:\n",
      "-------------------------------------------\n",
      "notebooks/00_export_v4.ipynb (302 cells total)\n",
      "---> default:\tnbdev_rewrite/main.py\n",
      "---> (1,):\tsetup.py\n",
      "---> (2,):\tnbdev_rewrite/argument_parsing.py\n",
      "---> (3,):\tnbdev_rewrite/imports.py\n",
      "notebooks/99_index.ipynb (23 cells total)\n",
      "---> default:\tNone\n",
      "\n",
      "Of the 2 notebooks parsed, 1 is outputting code.\n",
      "\n",
      "The following 4 python files have been generated:\n",
      "-------------------------------------------------\n",
      "---> 48 cells output to nbdev_rewrite/main.py\n",
      "---> 25 cells output to setup.py\n",
      "---> 14 cells output to nbdev_rewrite/argument_parsing.py\n",
      "---> 20 cells output to nbdev_rewrite/imports.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "success, parsed_files, merged_files = main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0,): {'target': WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/main.py'),\n",
       "  'add_dunder_all': True,\n",
       "  'cell_info': {'cell_nr': 103,\n",
       "   'cell_type': 'code',\n",
       "   'original_source_code': '# +default_exp -to main',\n",
       "   'processed_source_code': '',\n",
       "   'scope': (4,),\n",
       "   'export_to_py': False,\n",
       "   'export_to_scope': 0,\n",
       "   'export_to_default': 0,\n",
       "   'is_internal': None,\n",
       "   'export_to': [],\n",
       "   'names': None,\n",
       "   'comments': ['# +default_exp -to main']}},\n",
       " (1,): {'target': WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/setup.py'),\n",
       "  'add_dunder_all': False,\n",
       "  'cell_info': {'cell_nr': 1,\n",
       "   'cell_type': 'code',\n",
       "   'original_source_code': '# +default_exp -to_path ../setup.py -scoped -no_dunder_all',\n",
       "   'processed_source_code': '',\n",
       "   'scope': (1,),\n",
       "   'export_to_py': False,\n",
       "   'export_to_scope': 0,\n",
       "   'export_to_default': 0,\n",
       "   'is_internal': None,\n",
       "   'export_to': [],\n",
       "   'names': None,\n",
       "   'comments': ['# +default_exp -to_path ../setup.py -scoped -no_dunder_all']}},\n",
       " (2,): {'target': WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/argument_parsing.py'),\n",
       "  'add_dunder_all': True,\n",
       "  'cell_info': {'cell_nr': 37,\n",
       "   'cell_type': 'code',\n",
       "   'original_source_code': '# +default_exp -to argument_parsing -scoped',\n",
       "   'processed_source_code': '',\n",
       "   'scope': (2,),\n",
       "   'export_to_py': False,\n",
       "   'export_to_scope': 0,\n",
       "   'export_to_default': 0,\n",
       "   'is_internal': None,\n",
       "   'export_to': [],\n",
       "   'names': None,\n",
       "   'comments': ['# +default_exp -to argument_parsing -scoped']}},\n",
       " (3,): {'target': WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/imports.py'),\n",
       "  'add_dunder_all': False,\n",
       "  'cell_info': {'cell_nr': 74,\n",
       "   'cell_type': 'code',\n",
       "   'original_source_code': '# +default_exp -to imports -scoped -no_dunder_all',\n",
       "   'processed_source_code': '',\n",
       "   'scope': (3,),\n",
       "   'export_to_py': False,\n",
       "   'export_to_scope': 0,\n",
       "   'export_to_default': 0,\n",
       "   'is_internal': None,\n",
       "   'export_to': [],\n",
       "   'names': None,\n",
       "   'comments': ['# +default_exp -to imports -scoped -no_dunder_all']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_files['files'][0]['export_scopes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in parsed_files['files'][0]['cells'] if c['export_to_py']];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop new Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config().lib_path == Config().path_to('lib_path') == Config().path_to('lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib = Config().path_to('lib'); lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regex for matching import statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/3.0/reference/simple_stmts.html#the-import-statement  \n",
    "```\n",
    "import_stmt     ::=  \"import\" module [\"as\" name] ( \",\" module [\"as\" name] )*\n",
    "                     \n",
    "                     | \"from\" relative_module \"import\" identifier [\"as\" name]\n",
    "                     ( \",\" identifier [\"as\" name] )*\n",
    "                     \n",
    "                     | \"from\" relative_module \"import\" \"(\" identifier [\"as\" name]\n",
    "                     ( \",\" identifier [\"as\" name] )* [\",\"] \")\"\n",
    "                     \n",
    "                     | \"from\" module \"import\" \"*\"\n",
    "module          ::=  (identifier \".\")* identifier\n",
    "relative_module ::=  \".\"* module | \".\"+\n",
    "name            ::=  identifier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "letter = 'a-zA-Z'\n",
    "identifier = f'[{letter}_][{letter}0-9_]*'\n",
    "module = fr'(?:{identifier}\\.)*{identifier}'\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_module = fr'(?:\\.*{module}|\\.+)'\n",
    "name = identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:from\\\\ +((?:\\\\.*(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*|\\\\.+))\\\\ +import\\\\ +([a-zA-Z_][a-zA-Z0-9_]*(?:\\\\ +as\\\\ +[a-zA-Z_][a-zA-Z0-9_]*)?(?:\\\\ *,\\\\ *(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*(?:\\\\ +as\\\\ +[a-zA-Z_][a-zA-Z0-9_]*)?)*)|from\\\\ +((?:\\\\.*(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*|\\\\.+))\\\\ +import\\\\ *(\\\\(\\\\s*[a-zA-Z_][a-zA-Z0-9_]*(?:\\\\s+as\\\\s+[a-zA-Z_][a-zA-Z0-9_]*)?(?:\\\\s*,\\\\s*(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*(?:\\\\s+as\\\\s+[a-zA-Z_][a-zA-Z0-9_]*)?)*\\\\s*,?\\\\s*\\\\))|from\\\\ +((?:\\\\.*(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*|\\\\.+))\\\\ +import\\\\ *\\\\*)'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_name  = fr'(?:\\ +as\\ +{name})'\n",
    "as_name  = fr'{as_name}?(?:\\ *,\\ *{module}{as_name}?)*'\n",
    "\n",
    "import_1 = fr'import\\ +({module})({as_name})'\n",
    "\n",
    "import_2 = fr'from\\ +({relative_module})\\ +import\\ +({identifier}{as_name})'\n",
    "\n",
    "as_name_s  = fr'(?:\\s+as\\s+{name})'\n",
    "as_name_s  = fr'{as_name_s}?(?:\\s*,\\s*{module}{as_name_s}?)*'\n",
    "import_3   = fr'from\\ +({relative_module})\\ +import\\ *(\\(\\s*{identifier}{as_name_s}\\s*,?\\s*\\))'\n",
    "\n",
    "# NOTE: The docs say 'module', but in reality relative imports work as well.\n",
    "import_4 = fr'from\\ +({relative_module})\\ +import\\ *\\*'\n",
    "\n",
    "# NOTE: import_1 is not included, because it doesn't allow relative imports.\n",
    "import_stmt = fr'(?:{import_2}|{import_3}|{import_4})'\n",
    "import_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "re_test = re.compile(fr\"\"\"\n",
    "        ^              # start of the string\n",
    "        (\\ *)          # capturing group of any amount of whitespace (indenting)\n",
    "        {import_stmt}  # definition for matching a module \n",
    "        \\ *            # non-capturing whitespace\n",
    "                       # TODO: match any remaining character in case of e.g. comments\n",
    "        $              # end of the string\n",
    "        \"\"\", re.VERBOSE | re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_test.search('import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod') # import_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from numpy import array as arr, linalg.solve, module as mod'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_test.search('from numpy import array as arr, linalg.solve, module as mod').group() # import_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from numpy import (abs, b as c, h,)'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_test.search('from numpy import (abs, b as c, h,)').group() # import_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from . import *'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_test.search('from numpy import *').group() # import_4\n",
    "re_test.search('from . import *').group() # import_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'numpy', 'array as arr, linalg.solve, module as mod', None, None, None)\n",
      "('', None, None, 'numpy', '(abs, b as c, h,)', None)\n",
      "('', None, None, None, None, 'numpy')\n",
      "('    ', None, None, None, None, '.')\n",
      "('', None, None, 'numpy', '(\\n    abs\\n                  as a\\n    ,\\n                       absolute \\n    as \\n                  f\\n                  )', None)\n",
      "\n",
      "import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod\n",
      "# Nothing to see here\n",
      "from <REL>numpy import array as arr, linalg.solve, module as mod\n",
      "def function():\n",
      "    pass\n",
      "\n",
      "\n",
      "    from . import *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_The_Name = 'numpy'\n",
    "# import_stmt\n",
    "def repl(match):\n",
    "    print(match.groups())\n",
    "    sp, n2, a2, n3, a3, n4 = match.groups()\n",
    "    if n2:\n",
    "        if n2 == _The_Name: return f'{sp}from <REL>{n2} import {a2}'\n",
    "        else: return f'{sp}from {n2} import {a2}'\n",
    "    elif n3:\n",
    "        if n3 == _The_Name: f'{sp}from <REL>{n3} import {a3}'\n",
    "        else: return f'{sp}from {n3} import {a3}'\n",
    "    elif n4:\n",
    "        if n4 == _The_Name: f'{sp}from <REL>{n4} import *'\n",
    "        else: return f'{sp}from {n4} import *'\n",
    "\n",
    "res = re_test.sub(repl, \"\"\"\n",
    "import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod\n",
    "# Nothing to see here\n",
    "from numpy import array as arr, linalg.solve, module as mod\n",
    "def function():\n",
    "    pass\n",
    "from numpy import (abs, b as c, h,)\n",
    "from numpy import *\n",
    "    from . import *\n",
    "from numpy  import(\n",
    "    abs\n",
    "                  as a\n",
    "    ,\n",
    "                       absolute \n",
    "    as \n",
    "                  f\n",
    "                  )\"\"\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
