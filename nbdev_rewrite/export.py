# AUTOGENERATED! DO NOT EDIT! File to edit: 01_export_v2.ipynb (unless otherwise specified).

__all__ = ['Context', 'ExportCache', 'KeywordParser', 'OptionsTuple', 'add_names_A', 'add_names_FC', 'create_mod_file', 'decorators', 'fastai_patch', 'find_default_export', 'find_exports', 'find_names', 'info', 'iter_comments', 'keyword_parser', 'kw_export', 'kw_hide', 'legacy_parse_options', 'lineno', 'not_private', 'notebook2script', 'parse_options', 'read_nb', 'relative_import', 'remove_comment', 'unwrap_assign', 'unwrap_attr', 'update_from_all_', 'write_out_py']

# Cell
from collections import namedtuple, defaultdict
import os
import re
from .imports import *

from inspect import signature

# Cell
class Context:
    def __init__(self, cell_nr=None, export_nr=None):
        self.cell_nr = cell_nr
        self.export_nr = export_nr
    def __repr__(self):
        return f'cell_nr: {self.cell_nr}, export_nr: {self.export_nr}'

# Cell
def remove_comment(source:str, loc_line:int, loc_char:int=None) -> str:
    lines = source.splitlines()
    if loc_char is None: lines.pop(loc_line)
    else: lines[loc_line] = lines[loc_line][:loc_char] # pass loc_char to only remove part of the line and keep the rest
    return '\n'.join(lines)

# Cell
def relative_import(name, fname):
    "Convert a module `name` to a name relative to `fname`"
    mods = name.split('.')
    splits = str(fname).split(os.path.sep)
    if mods[0] not in splits: return name
    i=len(splits)-1
    while i>0 and splits[i] != mods[0]: i-=1
    splits = splits[i:]
    while len(mods)>0 and splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]
    return '.' * (len(splits)) + '.'.join(mods)

# Cell
_re_import = ReLibName(r'^(\s*)from (LIB_NAME\.\S*) import (.*)$')

# Cell
def _deal_import(code_lines, fname):
    def _replace(m):
        sp,mod,obj = m.groups()
        return f'{sp}from {relative_import(mod, fname)} import {obj}'
    return [_re_import.re.sub(_replace,line) for line in code_lines]

# Cell
def read_nb(fname):
    "Read the notebook in `fname`."
    with open(Path(fname),'r', encoding='utf8') as f: return nbformat.reads(f.read(), as_version=4)

# Cell
# TODO(florian): Only look for 0 indent comments?
def iter_comments(src:str, cell_nr:int, pure_comments_only:bool=True, line_limit=None):
    """Detect all comments in a piece of code, excluding those that are a part of a string."""
    in_lstr = in_sstr = False
    count, quote = 1, ''
    for i, line in enumerate(src.splitlines()[:line_limit]):
        is_pure, escape, prev_c = True, False, '\n'
        for j, c in enumerate(line):
            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns
            if is_pure and (not (c.isspace() or c == '#')): is_pure = False
            if (in_sstr or in_lstr):
                # assert (in_sstr and not in_lstr) or (in_lstr and not in_sstr)
                if escape: count = 0
                else:
                    if (c == quote):
                        count = ((count + 1) if (c == prev_c) else 1)
                        if in_sstr: in_sstr = False
                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False
                escape = False if escape else (c == '\\')
            else:                    
                if (c == '#'):
                    if (pure_comments_only and is_pure): yield (line, (i, j))
                    elif (not pure_comments_only):       yield (line[j:], (i, j))
                    break
                elif c == "'" or c == '"':
                    count = ((count + 1) if (c == prev_c) else 1)
                    if count == 1: in_sstr = True
                    elif count == 3: count, in_lstr = 0, True
                    else: raise SyntaxError(f'Unexpected quote repetition count: {count} Should be either 1 or 3. Cell_nr: {cell_nr} Line:{i}/{j}')
                    quote = c
            prev_c = c

# Cell
class KeywordParser:
    def __init__(self, *init_keywords):
        self.parsers = {}
        for kw in init_keywords: self.parsers[kw] = self._create_parser(kw)

    def _create_parser(self, keyword):
        # TODO: decide on the syntax
        # TODO: Should there be any whitespace allowed before special comments?
        # TODO: Should more than one "#" be allowed for special comments?
        pattern = fr"""
        ^              # start of line, since MULTILINE is passed
        \s*            # any amount of whitespace
        \#+\s*          # literal "#", then any amount of whitespace
        {keyword}(.*)  # keyword followed by arbitrary symbols (except new line)
        $              # end of line, since MULTILINE is passed
        """
        return re.compile(pattern, re.IGNORECASE | re.MULTILINE | re.VERBOSE)

    def __getitem__(self, key):
        if key in self.parsers: return self.parsers[key]
        else:
            parser = self._create_parser(key)
            self.parsers[key] = parser
            return parser

# Cell
OptionsTuple = namedtuple(typename='Options',
                          field_names=['internal', 'export_target'],
                          defaults=[False, None])

# Cell
_re_legacy_options = re.compile(r'^(i)?\s*([a-zA-Z0-9]+\S*|)\s*$')
def legacy_parse_options(options:str) -> OptionsTuple:
    res = _re_legacy_options.search(options)
    if res:
        internal, export_target = res.groups()
        return OptionsTuple(internal=(internal == 'i'),
                            export_target=(os.path.sep.join(export_target.split('.')) if export_target else None))
    else: return None

# Cell
def parse_options(options:str, legacy:bool=True) -> OptionsTuple:
    if (options is None) or (options == '') or (options.isspace()): return OptionsTuple()
    else:
        if legacy:
            res = legacy_parse_options(options)
            if res: return res
            else: pass # Fall through to different parsing scheme
        # TODO: New Syntax for specifying keyword options
        raise NotImplementedError(f'this branch of parse_options() is not implemented yet. you typed: {options}')

# Cell
keyword_parser = KeywordParser()
kw_export, kw_hide = keyword_parser['export'], keyword_parser['hide']

# Cell
def find_exports(cells:list, default:str, code_only:bool=True) -> list:
    """check for each cell if it's supposed to be exported and aggregate cell content together with export options"""
    exports = []
    for i, cell in enumerate(cells):
        if code_only and (cell.cell_type != 'code'): continue
        else:
            source = cell.source
            # TODO: fix imports here or only on export?
            for comment, (loc_line, loc_char) in iter_comments(source, cell_nr=i):
                res = kw_export.search(comment)
                if res:
                    options = parse_options(res.groups()[0])
                    if not (options.export_target or default): raise SyntaxError(f'Cell nr.{i} doesn\'t have an export target, \
                                                                                    and no default is specified.')
                    if not options.export_target: options = options._replace(export_target=default)
                    source = remove_comment(source, loc_line, None)
                    # source = re.sub(r'\s+$', '', source, flags=re.MULTILINE) # remove whitespace at the end of each line
                    fname_out = Config().lib_path/f'{options.export_target}.py'
                    source = '\n'.join(_deal_import(source.splitlines(), fname=fname_out)) # Fix relative imports
                    exports.append((source, options, Context(cell_nr=i)))
                    continue
                if kw_hide.search(comment): break
    return exports

# Cell
import ast
from ast import iter_fields, AST
import _ast

# Cell
def lineno(node):
    "Format a string containing location information on ast nodes. Used for Debugging only."
    if hasattr(node, 'lineno') and hasattr(node, 'col_offset'):
        return f'line_nr: {node.lineno} col_offset: {node.col_offset}'
    else: return ''

# Cell
def info(context, node):
    "Format a string with available information on a ast node. Used for Debugging only."
    return f'\nLocation: {context} | {lineno(node)}'

# Cell
def unwrap_attr(node:_ast.Attribute) -> str:
    "Joins a sequance of Attribute accesses together in a single string. e.g. numpy.array"
    if isinstance(node.value, _ast.Attribute): return '.'.join((unwrap_attr(node.value), node.attr))
    else: return '.'.join((node.value.id, node.attr))

# Cell
def unwrap_assign(node, names, c):
    "inplace, recursive update of list of names"
    if   isinstance(node, _ast.Name)      : names.append(node.id)
    elif isinstance(node, _ast.Starred)   : names.append(node.value.id)
    elif isinstance(node, _ast.Attribute) : names.append(unwrap_attr(node))
    elif isinstance(node, (_ast.List, _ast.Tuple)):
        for x in node.elts: unwrap_assign(x, names, c)
    elif isinstance(node, list):
        for x in node: unwrap_assign(x, names, c)
    else: raise SyntaxError(f'Can\'t resolve {node} to name, unknown type. {info(c, node)}')

# Cell
def update_from_all_(node, names, c): # TODO: should all of these cases be handled, or just always expect a string?
    "inplace, recursive update of set of names, by parsing the right side of a _all_ variable"
    if   isinstance(node, _ast.Str): names.add(node.s)
    elif isinstance(node, _ast.Name): names.add(node.id)
    elif isinstance(node, _ast.Attribute): names.add(unwrap_attr(node))
    elif isinstance(node, (_ast.List, _ast.Tuple, _ast.Set)):
        for x in node.elts: update_from_all_(x, names, c)
    elif isinstance(node, _ast.Starred):
        raise SyntaxError(f'Starred expression *{node.value.id} not allowed in _all_. {info(c, node)}')
    else: raise SyntaxError(f'Can\'t resolve {node} to name, unknown type. {info(c, node)}')

# Cell
def not_private(name): return not (name.startswith('_') and (not name.startswith('__')))

# Cell
def add_names_A(node, names, c):
    "Handle Assignments to variables"
    tmp_names = list()
    unwrap_assign(node.targets, tmp_names, c)
    for name in tmp_names:
        if not_private(name): names.add(name)
        # NOTE: special cases below can only use private variable names
        elif name == '_all_':
            if len(tmp_names) != 1:
                raise SyntaxError(f'Reserved keyword "_all_" can only be used in simple assignments. {info(c, node)}')
            update_from_all_(node.value, names, c)

# Cell
def fastai_patch(cls, node, names, c):
    if   isinstance(cls, _ast.Name):
        if not_private(cls.id): names.add(f'{cls.id}.{node.name}')
    elif isinstance(cls, (_ast.List, _ast.Tuple, _ast.Set)):
            for x in cls.elts: fastai_patch(x, node, names, c)
    else: raise SyntaxError(f'Can\'t resolve {cls} to @patch annotation, unknown type. {info(c, node)}')

# Cell
def decorators(node): yield from [d.id for d in node.decorator_list]

# Cell
def add_names_FC(node, names, c, fastai_decorators=True):
    "Handle Function and Class Definitions"
    if fastai_decorators and ('patch' in decorators(node)):
        if not (len(node.args.args) >= 1): raise SyntaxError(f'fastai\'s @patch decorator requires at least one parameter. {info(c, node)}')
        cls = node.args.args[0].annotation
        if cls is None: raise SyntaxError(f'fastai\'s @patch decorator requires a type annotation on the first parameter. {info(c, node)}')
        fastai_patch(cls, node, names, c)
    elif fastai_decorators and ('typedispatch' in decorators(node)): return # ignore @typedispatch
    elif not_private(node.name): names.add(node.name)

# Cell
def find_names(code:str, context:Context=None) -> list:
    tree = ast.parse(code)
    names = set()
    for node in tree.body:
        if   isinstance(node, _ast.Assign): add_names_A(node, names, context)
        elif isinstance(node, (_ast.FunctionDef, _ast.ClassDef)): add_names_FC(node, names, context)
        else: pass
    return names

# Cell
class ExportCache(defaultdict):
    def __init__(self, default_export:str=None):
        super(ExportCache, self).__init__(self._create_exp)
        self.tupletype = namedtuple(typename='export', field_names=['code', 'names'])
        if default_export is not None: self[default_export]
    
    def _create_exp(self): return self.tupletype(code=list(), names=set())
    
    def add_names(self, key:str, names:list): self[key].names.update(names)
            
    def add_code(self , key:str, code:str)  : self[key].code.append(code)

# Cell
def find_default_export(cells:list) -> str:
    # search through all cells to find the default_exp keyword and return it's value.
    # syntax checking
    # maybe do some sanity checking
    default = 'export'
    return default

# Cell
def create_mod_file(orig_nbfname, targ_pyfname):
    # create the .py file in the correct folder, with a header saying where it was originally from
    pass

# Cell
def write_out_py(e, s, fname, sep):
    config = Config() # TODO: is this faster than making a new one every time?
    fname_out   = config.lib_path/f'{e}.py'
    nb_path     = config.nbs_path/f'{fname}'
    config_path = config.config_file.parent
    rel_nb_path = os.path.relpath(nb_path, config_path).replace('\\', '/')
    warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {rel_nb_path} (unless otherwise specified).'
    names = sep + "__all__ = ['" + "', '".join(sorted(s.names)) + "']" # TODO(florian): add line breaks at regular intervals
    code  = ''.join(s.code)
    file_content = warning + names + code
    fname_out.parent.mkdir(parents=True, exist_ok=True)
    with open(fname_out, 'w', encoding='utf8') as f: f.write(file_content)

# Cell
def _notebook2script(fname=None, silent=False, to_dict=False):
    """Convert a single notebook"""
    fname = Path(fname)
    nb = read_nb(fname)
    cells = nb['cells']
    sep = '\n' * (max(int(Config().get('cell_spacing', 1)), 0) + 1)
    default = find_default_export(cells)
    if default is None:
        print('WARNING: No default export target found! (should this crash, or see if each export has its own target?)')
        raise NotImplementedError('Not specifying a default export is not supported yet.')
    else:
        default = os.path.sep.join(default.split('.'))
        ec = ExportCache(default)
        # TODO(florian): create_mod_file(original_nbfile_path, target_pyfile_path) # args flipped in original code
        pass
    # TODO(florian): load _nbdev file and create a spec from it (no idea why this is needed)
    
    exports = find_exports(cells, default)
    for export_nr, (code, options, context)  in enumerate(exports):
        context.export_nr = export_nr
        # code = clean_code(code)
        # TODO: make imports of the current project relative in the output code
        i, e = options.internal, options.export_target
        if not i: ec.add_names(e, find_names(code, context))
        orig = (('Internal C' if i else '# C') if e==default else f'# Comes from {fname.name}, c') + 'ell\n'
        ec.add_code(e, (sep + orig + code))
    
    if default in ec:
        # write_out_py(default, ec.pop(default), fname, sep) # NOTE remove default from the set
        write_out_py(default, ec[default], fname, sep) # NOTE used for testing
    else: raise NotImplementedError('Exporting to a module other than the default is not supported yet.')
    # TODO(florian): add names to _nbdev index
    # TODO(florian): write code cell to file
    # TODO(florian): save _nbdev file
    return ec

# Cell
def notebook2script(fname=None, silent=False, to_dict=False):
    "Convert notebooks matching `fname` to modules"
    # initial checks
    if os.environ.get('IN_TEST',0): return  # don't export if running tests
    if fname is None:
        reset_nbdev_module()
        update_version()
        update_baseurl()
        files = [f for f in Config().nbs_path.glob('*.ipynb') if not f.name.startswith('_')]
    else: files = glob.glob(fname)
    d = collections.defaultdict(list) if to_dict else None
    for f in sorted(files): d = _notebook2script(f, silent=silent, to_dict=d)
    if to_dict: return d
    else: add_init(Config().lib_path)