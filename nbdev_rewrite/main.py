# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/00_export_v4.ipynb (unless otherwise specified).


__all__ = ['CellInfoStruct', 'CommentStruct', 'Config', 'DictLikeAccess', 'DictLikeRepr', 'ExportUnitStruct', 'MODULE__MAIN__FLAG', 'MergedFileInfoStruct', 'NotebookStruct', 'ScopeUnitStruct', 'StackTrace', 'Traced', 'all_commands', 'async_load_notebooks', 'cmd2func', 'convert2py', 'crawl_directory', 'create_config', 'kw_default_exp', 'kw_export', 'merge_all', 'parse_all', 'parse_file', 'read_notebook', 'register_command', 'set_main_report_options', 'write_all', 'write_file']


# Cell nr. 112
# This Flag allows anyone to know if this Module exists in their namespace
MODULE__MAIN__FLAG = None


# Cell nr. 114
from typing import Union, Tuple, List, Dict, Generator, Iterable, Iterator
from collections import defaultdict
from inspect import signature, currentframe, getfullargspec
import nbformat
import ast
from ast import iter_fields, AST
import _ast


# Cell nr. 116
if (__name__ != '__main__') or ('MODULE__ARGUMENT_PARSING__FLAG' not in globals()):
    from .argument_parsing import *
assert 'MODULE__ARGUMENT_PARSING__FLAG' in globals(), "Missing the 'argument_parsing' module."

if (__name__ != '__main__') or ('MODULE__IMPORTS__FLAG' not in globals()):
    from .imports import *
assert 'MODULE__IMPORTS__FLAG' in globals(), "Missing the 'imports' module."

_all_ = ['Config', 'create_config'] # NOTE: Add these to __all__ in the output file


# Internal Cell nr. 119
main_REPORT_OPTIONAL_ERROR:bool = False
main_REPORT_COMMAND_FOUND:bool = False
main_REPORT_RUN_STATISTICS:bool = True


# Cell nr. 120
def set_main_report_options(report_optional_error:bool=False,
                            report_command_found:bool=False,
                            report_run_statistics:bool=True):
    "Set options for how the Main Module will behave on encountering errors or warnings.\n"\
    "report_optional_error prints the information and then continues."
    global main_REPORT_OPTIONAL_ERROR, main_REPORT_COMMAND_FOUND, main_REPORT_RUN_STATISTICS
    main_REPORT_OPTIONAL_ERROR = report_optional_error
    main_REPORT_COMMAND_FOUND  = report_command_found
    main_REPORT_RUN_STATISTICS = report_run_statistics


# Internal Cell nr. 122
def report_successful_export(ParsedNotebooks:list, merged_files):
    "Report stats and compressed information about parsed and exported files."
    p = Config().proj_path
    n_nbs = nr_of_notebooks_parsed = len(ParsedNotebooks)
    n_py  = nr_of_output_py_files  = len(merged_files)
    Title = f'{n_nbs} notebook{"s"*int(n_nbs!=1)} {"have" if n_nbs!=1 else "has"} been parsed, '\
            f'resulting in {n_py} python file{"s"*int(n_py!=1)}.\n\n'
    
    # Information about which notebooks export to which python files
    nb_info = f'The following {n_nbs} notebook{"s"*int(n_nbs!=1)} have been parsed:\n'
    nb_info += '-' * (len(nb_info) - 1)
    n_out = nr_of_files_outputting_code = 0
    Notebook:NotebookStruct = None # type hint
    for Notebook in ParsedNotebooks:
        nb_info += f"\n{Notebook.RelativeFilePath} ({len(Notebook.ExportCells)} cells total)\n"
        default = Notebook.ExportScopes[(0,)]
        n_exp = len(Notebook.ExportScopes) - int(default is None)
        nb_info += f'---> default:\t{None if (default is None) else relative_path(default["target"], p)}'
        for scope, target in sorted(Notebook.ExportScopes.items(), key=lambda x: x[0]):
            if scope == (0,): continue
            nb_info += f"\n---> {scope}:\t{relative_path(target['target'], p)}"
        if n_exp > 0: n_out += 1
    
    
    Middle = f'Of the {n_nbs} notebook{"s"*int(n_nbs!=1)} parsed, '\
             f'{n_out} {"are" if n_out!=1 else "is"} outputting code.'
    
    # Information about how many Python files have been generated, and the number of cells exported to each
    py_info = f'The following {n_py} python file{"s"*int(n_py!=1)} {"have" if n_py!=1 else "has"} been generated:\n'
    py_info += '-' * (len(py_info) - 1) + '\n'
    for to, state in merged_files.items():
        n_cells = str(len(state['code']))
        n_cells = (max(0, 4-len(n_cells))* ' ') + n_cells
        py_info += f'---> {n_cells} cell{"s"*int(n_cells!=1)} output to {relative_path(to, p)}\n'
        
    print(f'{Title}{nb_info}\n\n{Middle}\n\n{py_info}')


# Cell nr. 125
class StackTrace: pass # only for :StackTrace annotations to work
class StackTrace:
    _up:StackTrace = None
    namespace:str = None
    lineno   :int = None
    _ext_file:dict = None
    
    def __init__(self, namespace:object=None, up:StackTrace=None):
        "`namespace` can be a function, a class, or None.\n"\
        "`up` is optional and can be another StackTrace instance."
        self.namespace = f'<{namespace.__qualname__}>()' if namespace else currentframe().f_back.f_code.co_name
        self._up, self.lineno, self._ext_file = up, currentframe().f_back.f_lineno, {}
    
    def ext(self, file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):
        "Set context information for reporting errors in external files e.g. notebooks."
        e = self._ext_file
        if not (file    is None) : e['file'   ] = file
        if not (cellno  is None) : e['cellno' ] = cellno
        if not (lineno  is None) : e['lineno' ] = lineno
        if not (excerpt is None) : e['excerpt'] = excerpt
        if not (span    is None) : e['span'   ] = span # TODO: convert a single int to tuple?
    
    def ext_clear_file   (self): self._ext_file.pop('file'   , None)
    def ext_clear_cellno (self): self._ext_file.pop('cellno' , None)
    def ext_clear_lineno (self): self._ext_file.pop('lineno' , None)
    def ext_clear_excerpt(self): self._ext_file.pop('excerpt', None)
    def ext_clear_span   (self): self._ext_file.pop('span'   , None)
    
    def to_list(self):
        "Creates list of the entire StackTrace (most recent last)."
        if self._up: return [*self._up.to_list(), self]
        else: return [self]
        
    def _reduce_ext(self):
        "Combines all `StackTrace._ext_file` dicts into one, prefering more recent settings over old ones."
        ext = [s._ext_file for s in self.to_list() if s._ext_file]
        e = {}
        for d in ext: e.update(d)
        return e
        
    def up(self, up:StackTrace):
        "Set this StackTraces `_up` reference and return `self`. Useful for chaining references."
        self._up=up
        return self
    
    def __repr__(self): return f"{__name__}.StackTrace(namespace={self.namespace},line={self.lineno})"
    
    def _repr(self):
        "Recursively create a string of all StackTraces for printing error messages."
        return f"{'' if self._up is None else self._up._repr()}"\
               f"<{__name__}>, line {self.lineno} in {self.namespace}\n"
    
    def _repr_ext(self, file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):
        "Create a string from the `StackTrace._ext_file` dict for printing error messages."
        s = f"<{file}>, cell {cellno}, line {lineno}\n"
        if excerpt:
            x = f"--->{' ' if ((lineno is None) or (0 <= lineno <= 9)) else ''}{lineno} "
            s += f"{x}{excerpt}\n"\
                 f"{(' ' * (len(x) + span[0]) + '^' * span[1]) if span else ''}\n"
        return s
    
    def report_error(self, err:Exception,
                     file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None,
                     success=False, _ln_of_callsite=True) -> bool:
        "Report the Error `err`.\nOther args are used for setting `_ext_file` and are optional.\n"\
        "Returns whatever is passes as `success`."
        if _ln_of_callsite: self.lineno = currentframe().f_back.f_lineno
        err_type = err.__class__.__name__
        s = f"{'-'*75}\n"\
            f"{err_type}{' '*(41-len(err_type))}Stacktrace (most recent call last)\n"\
            f"{self._repr()}\n"
        self.ext(file, cellno, lineno, excerpt, span) # TODO: should this maybe be passed to _reduce_ext?
        ext:dict = self._reduce_ext()
        if ext: s += f"{self._repr_ext(**ext)}\n" # TODO: check for len(ext) > 0 and values not None?
        s += f"[{err_type}]: {err}"
        print(s) # NOTE: This is what prints the error message.
        return success
    
    def report_caught_syntax_error(self, err:SyntaxError, msg='invalid syntax', success=False):
        "Report an error taking advantage of common formatting when handling a python SyntaxError."
        self.lineno = currentframe().f_back.f_lineno
        return self.report_error(SyntaxError(msg),
                                 excerpt=err.text[:-1],
                                 lineno=err.lineno,
                                 span=(err.offset-1, 1),
                                 success=success,
                                 _ln_of_callsite=False)
    
    def report_optional_error(self, err:Exception,
                        file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):
        "Report the error if the global variable `main_REPORT_OPTIONAL_ERROR` is set."
        if main_REPORT_OPTIONAL_ERROR:
            self.lineno = currentframe().f_back.f_lineno
            self.report_error(err=err, _ln_of_callsite=False,
                              file=file,
                              cellno=cellno, lineno=lineno,
                              excerpt=excerpt, span=span)


# Cell nr. 126
def Traced(f):
    "The Annotated function will have a StackTrace instance passed to it as the `st` keyword-argument.\n"\
    "That instance represents the annotated function, with a reference to the calling site."
    spec = getfullargspec(f)
    assert ('st' in spec.args) or ('st' in spec.kwonlyargs), "Traced functions have to take a 'st' argument."
    if 'st' in spec.annotations:
        assert spec.annotations['st'] == StackTrace, "A traced functions 'st' argument is reserved for "\
                                                     "a StackTrace. Other annotations are not allowed."
    else: f.__annotations__['st'] = StackTrace # This modifies the original function. Is that acceptable?
    
    _st = StackTrace(f)
    def _wrapper(*args, st:StackTrace=None, **kwargs):
        if not st:
            st = StackTrace(None)
            st.namespace = currentframe().f_back.f_code.co_name
        elif (st is _st): return f(*args, st=st, **kwargs) # prevent self referencing due to e.g. recursion.
        st.lineno = currentframe().f_back.f_lineno
        # NOTE: clearing _st._ext_file to an empty dict like this is actually faster than not clearing it...
        res = f(*args, st=_st.up(st), **kwargs)
        _st._ext_file = {}
        return res
    
    functools.update_wrapper(_wrapper, f)
    return _wrapper


# Internal Cell nr. 144
# TODO: Only look for 0 indent comments?
def iter_comments(src:str, pure_comments_only:bool=True, line_limit:int=None) -> Tuple[str, Tuple[int, int]]:
    "Detect all comments in a piece of code, excluding those that are a part of a string."
    in_lstr = in_sstr = False
    count, quote = 1, ''
    for i, line in enumerate(src.splitlines()[:line_limit]):
        is_pure, escape, prev_c = True, False, '\n'
        for j, c in enumerate(line):
            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns
            if is_pure and (not (c.isspace() or c == '#')): is_pure = False
            if (in_sstr or in_lstr):
                # assert in_sstr ^ in_lstr # XOR
                if escape: count = 0
                else:
                    if (c == quote):
                        count = ((count + 1) if (c == prev_c) else 1)
                        if in_sstr: in_sstr = False
                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False
                escape = False if escape else (c == '\\')
            else:                    
                if (c == '#'):
                    if (pure_comments_only and is_pure): yield (line, (i, j))
                    elif (not pure_comments_only):       yield (line[j:], (i, j))
                    break
                elif c == "'" or c == '"':
                    count = ((count + 1) if (c == prev_c) else 1)
                    if count == 1: in_sstr = True
                    elif count == 3: count, in_lstr = 0, True
                    else: assert False, 'If this code path happens, then the code keeping track of quotes is broken.'
                    quote = c
            prev_c = c


# Internal Cell nr. 148
# https://docs.python.org/3/library/re.html
re_match_comment = re.compile(r"""
        ^              # start of the string
        \s?            # 0 or 1 whitespace
        \#+\s?         # 1 or more literal "#", then 0 or 1 whitespace
        (.*)           # group of arbitrary symbols (except new line)
        $              # end of the string
        """,re.IGNORECASE | re.VERBOSE) # re.MULTILINE is not passed, since this regex is used on each line separately.


# Internal Cell nr. 153
@Traced
def parse_comment(all_commands:dict, comment:str, st:StackTrace) -> Tuple[bool, str, dict, dict]:
    "Finds command names and arguments in comments and parses them with parse_arguments()"
    res = re_match_comment.search(comment)
    if not res:
        st.report_optional_error(SyntaxError('Not a valid comment syntax.'))
        return False, None, None, None
    
    all_args = res.groups()[0].split()
    if len(all_args) == 0:
        st.report_optional_error(SyntaxError(f"Need at least one argument in comment. Reveived: '{comment}'"))
        return False, None, None, None
    
    cmd, *args = all_args
    if cmd[0] != '+':
        st.report_optional_error(SyntaxError("The first argument (the command to execute) does not start with a '+'."\
                                            f"It was: '{cmd}'"), span=(1, 3))
        return False, None, None, None
    
    cmd = cmd[1:] # remove the '+'
    if cmd not in all_commands:
        st.report_optional_error(KeyError(f"'{cmd}' is not a recognized command. See 'all_commands'."))
        return False, None, None, None
    
    success, result, is_set = parse_arguments(all_commands[cmd], args)
    if not success: return False, None, None, None
    
    return True, cmd, result, is_set


# Internal Cell nr. 159
@Traced
def from_string_cell(source:str, st:StackTrace) -> (bool, str):
    "Take a cells source code containing a single string and return the content of that string."
    try: tree = ast.parse(source).body
    except SyntaxError as e: return st.report_caught_syntax_error(e), None
    if len(tree) == 1:
        node = tree[0]
        if isinstance(node, _ast.Expr):
            if isinstance(node.value, _ast.Str):
                code = node.value.s.strip()
                try: ast.parse(code)
                except SyntaxError as e:
                    return st.report_caught_syntax_error(e, msg="The code in the 'from_string' "\
                                                         "cell is invalid python syntax."), None
                return True, code
#             elif isinstance(node.value, _ast.JoinedStr):
#                 return st.report_error(SyntaxError("'f'-strings are not allowed.")), None
            else: return st.report_error(SyntaxError(f"Expected cell to contain a single '_ast.Str' expression, "\
                                                     f"but got {type(node.value)}")), None
        else: return st.report_error(SyntaxError(f"Expected cell to contain a single expression '_ast.Expr', "\
                                                 f"but got {type(node)}")), None
    else: return st.report_error(SyntaxError('Cell contains more than one Expression. '\
                                             'Expected cell to contain exactly one String.')), None


# Internal Cell nr. 173
def lineno(node):
    "Format a string containing location information on ast nodes. Used for Debugging only."
    lineno     = getattr(node, 'lineno', None)
    col_offset = getattr(node, 'col_offset', None)
    return lineno, col_offset


# Internal Cell nr. 175
def unwrap_attr(node:_ast.Attribute) -> str:
    "Joins a sequance of Attribute accesses together in a single string. e.g. numpy.array"
    if isinstance(node.value, _ast.Attribute): return '.'.join((unwrap_attr(node.value), node.attr))
    else: return '.'.join((node.value.id, node.attr))


# Internal Cell nr. 176
def unwrap_assign(node, names):
    "inplace, recursive update of list of names"
    if   isinstance(node, _ast.Name)      : names.append(node.id)
    elif isinstance(node, _ast.Starred)   : names.append(node.value.id)
    elif isinstance(node, _ast.Attribute) : names.append(unwrap_attr(node))
    elif isinstance(node, _ast.Subscript) : pass # e.g. a[0] = 1
    elif isinstance(node, (_ast.List, _ast.Tuple)):
        for x in node.elts: unwrap_assign(x, names)
    elif isinstance(node, list):
        for x in node: unwrap_assign(x, names)
    else: raise ValueError(f'Can\'t resolve {node} to name, unknown type.')


# Internal Cell nr. 177
def not_private(name): return not (name.startswith('_') and (not name.startswith('__')))


# Internal Cell nr. 178
def resolve_decorator_name(node):
    if   isinstance(node, _ast.Name): return node.id
    elif isinstance(node, _ast.Call):
        if   isinstance(node.func, _ast.Name     ): return node.func.id
        elif isinstance(node.func, _ast.Attribute): return unwrap_attr(node.func)
    elif isinstance(node, _ast.Attribute): return unwrap_attr(node)
    raise ValueError(f'Can\'t resolve decorator {node} to name, unknown type.')

def decorators(node): yield from (resolve_decorator_name(d) for d in node.decorator_list)


# Internal Cell nr. 179
def update_from_all_(node, names):
    "inplace, recursive update of set of names, by parsing the right side of a _all_ variable"
    if   isinstance(node, _ast.Str): names.add(node.s)
    elif isinstance(node, _ast.Name): names.add(node.id)
    elif isinstance(node, _ast.Attribute): names.add(unwrap_attr(node))
    elif isinstance(node, (_ast.List, _ast.Tuple, _ast.Set)):
        for x in node.elts: update_from_all_(x, names)
    elif isinstance(node, _ast.Subscript) :
        raise SyntaxError(f'Subscript expression not allowed in _all_.')
    elif isinstance(node, _ast.Starred):
        raise SyntaxError(f'Starred expression *{node.value.id} not allowed in _all_.')
    else: raise ValueError(f'Can\'t resolve {node} to name, unknown type.')


# Internal Cell nr. 182
@Traced
def find_names(code:str, st:StackTrace) -> (bool, set):
    "Find all function, class and variable names in the given source code."
    try: tree = ast.parse(code).body
    except SyntaxError as e: return st.report_caught_syntax_error(e), None
    names = set()
    for node in tree:
        if isinstance(node, (_ast.FunctionDef, _ast.ClassDef )):
            if not_private(node.name): names.add(node.name)
        else:
            is_assign, is_ann_assign = isinstance(node, _ast.Assign), isinstance(node, _ast.AnnAssign)
            if is_assign or is_ann_assign:
                tmp_names = list()
                if   is_assign:     unwrap_assign(node.targets, tmp_names)
                elif is_ann_assign: unwrap_assign(node.target , tmp_names)
                for name in tmp_names:
                    if not_private(name): names.add(name)
                    # NOTE: special reserved var names can only use private variable names
                    elif name == '_all_': # NOTE: _all_ is a keyword reserved by nbdev.
                        if len(tmp_names) != 1:
                            raise SyntaxError(f'Reserved keyword "_all_" can only be used in simple assignments.')
                        update_from_all_(node.value, names)
    return True, names


# Internal Cell nr. 190
def make_import_relative(p_from:Path, m_to:str)->str:
    "Convert a module `m_to` to a name relative to `p_from`."
    mods = m_to.split('.')
    splits = str(p_from).split(os.path.sep)
    if mods[0] not in splits: return m_to
    i=len(splits)-1
    while i>0 and splits[i] != mods[0]: i-=1
    splits = splits[i:]
    while len(mods)>0 and splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]
    return '.' * len(splits) + '.'.join(mods)


# Internal Cell nr. 194
# https://docs.python.org/3/library/re.html
letter = 'a-zA-Z'
identifier = f'[{letter}_][{letter}0-9_]*'
re_import = ReLibName(fr"""
    ^                             # start of the string / line
    (\ *)                         # any amount of whitespace (indenting)
    from(\ +)                     # 'from', followed by at least one whitespace
    (LIB_NAME(?:\.{identifier})*) # Name of the library, possibly followed by dot separated submodules
    \ +import(.+)                 # whitespace, then 'import', followed by arbitrary symbols except new line
    $                             # end of the string / line
    """, re.VERBOSE | re.MULTILINE)


# Internal Cell nr. 195
def relativify_imports(origin:Path, code:str)->str:
    "Transform an absolute 'from LIB_NAME import module' into a relative import of 'module' wrt the library."
    def repl(match):
        sp1,sp2,module,names = match.groups()
        return f'{sp1}from{sp2}{make_import_relative(origin, m_to=module)} import{names}'
    return re_import.re.sub(repl,code)


# Internal Cell nr. 202
# https://docs.python.org/3/library/re.html
letter = 'a-zA-Z'
identifier = f'[{letter}_][{letter}0-9_]*'
module = fr'(?:{identifier}\.)*{identifier}'
module


# Internal Cell nr. 203
# https://docs.python.org/3/library/re.html
re_match_module = re.compile(fr"""
        ^              # start of the string
        {module}       # definition for matching a module 
        $              # end of the string
        """, re.VERBOSE)


# Internal Cell nr. 205
@Traced
def module_to_path(m:str, st:StackTrace)->(bool, Path):
    "Turn a module name into a path such that the exported file can be imported from the library "\
    "using the same expression."
    if re_match_module.search(m) is not None:
        if m.endswith('.py'):
            return st.report_error(ValueError(f"The module name '{m}' is not valid, because ending on '.py' "\
                                f"would produce a file called 'py.py' in the folder '{m.split('.')[-2]}', "\
                                 "which is most likely not what was intended.\nTo name a file 'py.py', use the "\
                                 "'-to_path' argument instead of '-to'.")), None
        return True, Config().lib_path/f"{os.path.sep.join(m.split('.'))}.py"
    else: return st.report_error(ValueError(f"'{m}' is not a valid module name.")), None


# Internal Cell nr. 213
@Traced
def make_valid_path(s:str, st:StackTrace)->(bool, Path):
    "Turn a export path argument into a valid path, resolving relative paths and checking for mistakes."
    config = Config()
    p, lib, proj = Path(s), config.lib_path, config.proj_path
    is_abs = p.is_absolute()
    p = (p if is_abs else (lib/p)).absolute().resolve()
    if (not is_abs) and (not in_directory(p, proj)):
        return st.report_error(ValueError("Relative export path beyond top level directory of project "\
                                          "is not allowed by default. Use an absolute path, "\
                                          f"or set <NOT IMPLEMENTED YET> flag on the command. ('{s}')")), None
    if not p.suffix:
        return st.report_error(ValueError(f"The path '{s}' is missing a file type suffix like '.py'.")), None
    if p.suffix == '.py': return True, p
    else: return st.report_error(ValueError(f"Expected '.py' file ending, but got '{p.suffix}'. ('{s}')")), None


# Cell nr. 222
class DictLikeAccess():
    __slots__ = []
    def __getitem__(self, key):        return getattr(self, key)
    def __setitem__(self, key, value): return setattr(self, key, value)


# Cell nr. 223
class DictLikeRepr():
    __slots__ = []
    def _pretty_repr(self, refs):
        s = self.__class__.__name__ + ' {\n'
        refs.append(self)
        for key in self.__slots__:
            value = getattr(self, key, None)
            if any((value is ref for ref in refs)) or hasattr(value, '_pretty_repr'):
                s += f'\t{key} : {value.__class__.__name__} '  + '{...},\n'
            else:
                s += f'\t{key} : {value.__repr__()},\n'
        return s + '}'
        
    def __repr__(self):
        s = self.__class__.__name__ + ' {\n'
        for key in self.__slots__:
            value = getattr(self, key, None)
            if hasattr(value, '_pretty_repr'):
                s += f'\t{key} : {value._pretty_repr([self])},\n'
            else:
                s += f'\t{key} : {value.__repr__()},\n'
        return s + '}'


# Cell nr. 224
class NotebookStruct(DictLikeAccess, DictLikeRepr):
    __slots__ = ('FilePath', 'RelativeFilePath', 
                 'NotebookCells', 'NotebookMetadata', 'NotebookVersion',
                 'ExportScopes', 'ExportCells', 'ExportUnits')
    def __init__(self, FilePath:Path,
                 NotebookCells:list, NotebookMetadata:dict, NotebookVersion:Tuple[int, int]):
        self.FilePath         = Path(FilePath)
        self.RelativeFilePath = os.path.relpath(FilePath, Config().proj_path).replace('\\', '/')
        self.NotebookCells    = NotebookCells
        self.NotebookVersion  = NotebookVersion
        self.NotebookMetadata = NotebookMetadata
        self.ExportScopes     = {(0,): None}# if (ExportScopes is None) else ExportScopes
        self.ExportCells      = list()      # if (ExportCells  is None) else ExportCells
        self.ExportUnits      = list()      # if (ExportUnits  is None) else ExportUnits


# Cell nr. 225
class CellInfoStruct(DictLikeAccess, DictLikeRepr):
    __slots__ = ('cell_nr', 'cell_type', 'Notebook',
                 'original_source_code', 'clean_source_code',
                 'scope', 'comments', 'export_units')
    def __init__(self, cell_nr, cell_type, Notebook, cell_source, scope):
        self.cell_nr               = cell_nr
        self.cell_type             = cell_type
        self.Notebook              = Notebook
        self.original_source_code  = cell_source
        self.clean_source_code     = cell_source
        self.scope                 = scope
        self.comments              = list()
        self.export_units          = list()


# Cell nr. 228
# TODO: Rename to CommandStruct
class CommentStruct(DictLikeAccess, DictLikeRepr):
    __slots__ = ('lineno', 'charno', 'Comment', 'Command', 'ParsingResult', 'IsSet', 'Cell')
    def __init__ (self, lineno:int, charno:int, Comment:str,
                  Command:str, ParsingResult:dict, IsSet:dict,
                  Cell:CellInfoStruct):
        self.lineno        = lineno
        self.charno        = charno
        self.Comment       = Comment
        self.Command       = Command
        self.ParsingResult = ParsingResult
        self.IsSet         = IsSet
        self.Cell          = Cell
    @property
    def location(self) -> Tuple[int, int]:
        return self.lineno, self.charno


# Cell nr. 229
class ScopeUnitStruct(DictLikeAccess, DictLikeRepr):
    __slots__ = ('target', 'add_dunder_all', 'cell_info')
    def __init__(self, target, add_dunder_all, cell_info):
        self.target         = target
        self.add_dunder_all = add_dunder_all
        self.cell_info      = cell_info


# Cell nr. 230
class ExportUnitStruct(DictLikeAccess, DictLikeRepr):
    __slots__ = ('cell_info'  , 'source_code'    , # TODO: Add scope and cell_nr for ease of use?
                 'export_to'  , 'export_to_scope',
                 'is_internal', 'names',)
    def __init__(self, cell_info:CellInfoStruct, source_code=None, names=None):
        self.cell_info         = cell_info # NOTE: The cell that this unit came from
        self.source_code       = source_code
        self.export_to         = None
        self.export_to_scope   = False
        self.is_internal       = None
        self.names             = names


# Cell nr. 231
class MergedFileInfoStruct(DictLikeAccess, DictLikeRepr):
    __slots__ = ('orig', 'code', 'names', 'add_dunder_all')
    def __init__(self):
        self.orig           = None
        self.code           = []
        self.names          = set()
        self.add_dunder_all = None


# Cell nr. 234
def register_command(cmd, args, active=True):
    "Store mapping from command name to args, and command name to reference to the decorated function in globals."
    if not active: return lambda f: f
    all_commands[cmd] = args
    def _reg(f):
        cmd2func[cmd] = f
        return f
    return _reg


# Cell nr. 235
all_commands = {}
cmd2func     = {}


# Cell nr. 237
@register_command(cmd='default_exp', # allow custom scope name that can be referenced in export?
                  args={'to': '', 'to_path': '', 'no_dunder_all': False, 'scoped': False})
@Traced
def kw_default_exp(Notebook:NotebookStruct, cell_info:CellInfoStruct, Comment:CommentStruct, st:StackTrace) -> bool:
    "Set the default file that cells of this notebook will be exported to."
    success:bool = True
    result = Comment.ParsingResult
    is_set = Comment.IsSet
    if not (is_set['to'] ^ is_set['to_path']): # NOTE: XOR
        return st.report_error(ValueError("The `default_exp` command expects exactly one of the arguments "\
                               f"'-to' or '-to_path' to be set, but recieved was: {result}"))
    # NOTE: use this cells indentation level, or the default tuple `(0,)` as key to identify scope
    scope:tuple     = cell_info['scope'] if result['scoped'] else (0,)
    old_target:Path = Notebook.ExportScopes.get(scope, None)
    conv_success, new_target = (module_to_path(result['to'], st=st)
                                if is_set['to'] else
                                make_valid_path(result['to_path'], st=st))
    if not conv_success: return False
    if old_target is not None:
        if old_target['target'] != new_target:
            return st.report_error(ValueError(f"Overwriting an existing export target is not allowed."\
                            f"\n\twas (cell {old_target['cell_info']['cell_nr']}): '{old_target['target']}'"\
                            f"\n\tnew (cell {cell_info['cell_nr']}): '{new_target}'"))
        else: pass # TODO: issue a warning in this case
    Notebook.ExportScopes[scope] = ScopeUnitStruct(target         = new_target,
                                                    add_dunder_all = (not result['no_dunder_all']),
                                                    cell_info      = cell_info)
    return success


# Cell nr. 239
@register_command(cmd='export',
                  args={'internal': False, 'to': '', 'to_path':'', 'ignore_scope':False, 'from_string':False})
@Traced
def kw_export(Notebook:NotebookStruct, cell_info:CellInfoStruct, Comment:CommentStruct, st:StackTrace) -> bool:
    "This cell will be exported from the notebook to a .py file."
    success:bool = True
    result = Comment.ParsingResult
    is_set = Comment.IsSet
    export_unit  = ExportUnitStruct(cell_info)
    if (is_set['to'] and is_set['to_path']):
        return st.report_error(ValueError("The `export` command does not accept the '-to' and '-to_path' "\
                               f"argument at the same time. They are mutually exclusive. Received: {result}"))
    source_code:str = cell_info.clean_source_code
    if result['from_string']:
        convert_success, source_code = from_string_cell(source_code)
        if not convert_success: return False
    is_internal =  export_unit.is_internal = result['internal']
    # TODO: move this `find_names()` code to `merge_all`
    if is_internal: pass # no contained names will be added to __all__ for importing
    else: success, export_unit.names = find_names(source_code)
    conv_success, export_target = True, None
    if is_set['to'     ]: conv_success, export_target = module_to_path (result['to'], st=st)
    if is_set['to_path']: conv_success, export_target = make_valid_path(result['to_path'], st=st)
    if not conv_success: return False
    if export_target is not None:
        if is_set['ignore_scope']:
            return st.report_error(ValueError("Setting 'ignore_scope' is not allowed when "\
                                   f"exporting to a custom target using 'to' or 'to_path'."))
        export_unit.export_to = export_target # Set a new export target just for this cell.
    else:
        export_unit.export_to_scope = not result['ignore_scope'] # NOTE: if ignore_scope: export_to_default
    export_unit.source_code = source_code
    cell_info.export_units.append(export_unit) # TODO: remove one of these two lines
    Notebook .ExportUnits.append(export_unit)
    return success


# Cell nr. 249
def crawl_directory(Directory:Union[Path, Iterable[Path]], Recurse:bool=True) -> Generator:
    "Crawl the `Directory` for a list of .ipynb files."
    # TODO: Handle symlinks?
    ReservedDirectories = (Config().lib_path, Config().doc_path) # TODO: Don't recreate this every time.
    if   isinstance(Directory, (list, tuple, set)):
        for Item in Directory: yield from crawl_directory(Item, Recurse)
    elif Directory.is_file():
        yield Directory
    else:
        for Item in Directory.iterdir():
            Name = Item.name
            if   Name.startswith('.') or Name.startswith('_'):
                continue
            elif Item.is_file() and Name.endswith('.ipynb'):
                yield Item
            elif Item.is_dir() and Recurse and (Item not in ReservedDirectories):
                yield from crawl_directory(Item, Recurse)
            else: continue


# Cell nr. 250
def read_notebook(FilePath:Path) -> NotebookStruct:
    "Read the `FilePath` notebook."
    with open(FilePath,'r', encoding='utf8') as File:
        Notebook = nbformat.read(File, as_version=4)
    return NotebookStruct(FilePath         = FilePath,
                          NotebookCells    = Notebook['cells'],
                          NotebookMetadata = dict(Notebook.pop('metadata')),
                          NotebookVersion  = (Notebook.pop('nbformat'), Notebook.pop('nbformat_minor')),
                         )


# Cell nr. 251
@prefetch(max_prefetch=0) # NOTE: max_prefetch <= 0 means the queue size is infinite
def async_load_notebooks(Directory:Path, Recurse:bool=True) -> Iterator[NotebookStruct]:
    "Crawl for notebooks in the `path` directory, and load in a background thread."
    for FilePath in crawl_directory(Directory, Recurse): yield read_notebook(FilePath)


# Internal Cell nr. 257
# https://docs.python.org/3/library/re.html
re_match_heading = re.compile(r"""
        ^              # start of the string
        (\#+)\s+       # 1 or more literal "#", then 1 or more whitespace
        (.*)           # group of arbitrary symbols (including new line)
        $              # end of the string
        """,re.IGNORECASE | re.VERBOSE | re.DOTALL)


# Cell nr. 259
@Traced
def parse_file(Notebook:NotebookStruct, st:StackTrace) -> bool:
    success = True
    PURE_COMMENTS_ONLY = True
    st.ext(file=Notebook.RelativeFilePath)
    cells:list = Notebook.ExportCells
    ScopeCount :[int] = [0]
    ScopeLevel :int   = 0
    for i, NotebookCell in enumerate(Notebook.NotebookCells):
        st.ext(cellno = i)
        CellType   = NotebookCell['cell_type']
        CellSource = NotebookCell['source']
        CellInfo    = CellInfoStruct(cell_nr     = i,
                                     cell_type   = CellType,
                                     Notebook    = Notebook,
                                     cell_source = CellSource,
                                     scope       = tuple(ScopeCount))
        if CellType == 'code':
            # DOC: Search for command Comments
            Comments = CellInfo.comments
            for Comment, (lineno, charno) in iter_comments(CellSource, PURE_COMMENTS_ONLY, line_limit=None):
                st.ext(lineno = lineno + 1) # zero counting offset
                CommandFound, cmd, result, is_set = parse_comment(all_commands,Comment,st=st)
                if CommandFound:
                    if (cmd not in cmd2func):
                        raise ValueError(f"The command '{cmd}' is recognized, but does not "\
                                        "map to a corresponding action in 'cmd2func'.")
                    if main_REPORT_COMMAND_FOUND:
                        print(f'Found: {cmd} @ ({i}, {lineno}, {charno}) with args: {result}')
                    Comments.append(CommentStruct(lineno, charno, Comment, cmd, result, is_set, CellInfo))
                else: pass # NOTE: This happens all the time, and just means this Comment is not a Command.
            if len(Comments) >= 1:
                # DOC: Remove command Comments from source code
                Lines     = CellSource.splitlines()
                Locations = (C.location for C in Comments[::-1])
                if PURE_COMMENTS_ONLY:
                    for lineno, charno in Locations: Lines.pop(lineno)
                else:
                    for lineno, charno in Locations: Lines[lineno] = Lines[lineno][:charno]
                CellInfo.clean_source_code = '\n'.join(Lines)
                # DOC: Run commands
                # TODO: Do this only after all cells have been parsed?
                #       
                #       That would make for a great opportunity to have a metaprogram run.
                for Comment in Comments:
                    cmd_success = cmd2func[Comment.Command](Notebook, CellInfo, Comment, st=st)
                    if not cmd_success: return False
            else: continue # No Commands found
        
        elif CellType == 'markdown':
            Match = re_match_heading.search(CellSource)
            if (Match is not None): # This cell contains a Heading
                # Modify the ScopeLevel and ScopeCount
                HeadingLevel, _HeadingName = Match.groups()
                NewScopeLevel = len(HeadingLevel) # number of '#' in the heading
                if NewScopeLevel > ScopeLevel:
                    ScopeCount += ([0] * (NewScopeLevel - (len(ScopeCount)))) # extend list if necessary
                elif NewScopeLevel < ScopeLevel:
                    ScopeCount = ScopeCount[:NewScopeLevel] # reset lower values
                ScopeCount[NewScopeLevel - 1] += 1
                ScopeLevel = NewScopeLevel
            else: pass # This cell is regular markdown
        
        elif CellType == 'raw': continue
        else: raise ValueError(f"Unknown Cell Type '{CellType}' in Cell number {i}."\
                                "Should be 'code', 'markdown', or 'raw'.")
        cells.append(CellInfo)
    return success


# Cell nr. 260
@Traced
def parse_all(Notebooks:Iterator[NotebookStruct], st:StackTrace) -> Tuple[bool, dict]:
    "Loads all .ipynb files in the origin_path directory, and passes them one at a time to parse_file."
    Success:bool = True
    ParsedNotebooks  = list()
    for Notebook in Notebooks:
        # NOTE: Try parsing every file and only check in the end if there was an error
        Success = parse_file(Notebook, st=st) and Success
        ParsedNotebooks.append(Notebook)
    return Success, ParsedNotebooks


# Cell nr. 262
@Traced
def merge_all(parsed_files:dict, st:StackTrace) -> (bool, dict):
    success:bool = True
    merged_files = defaultdict(MergedFileInfoStruct)
    zero_tuple = (0,)
    
    Notebook:NotebookStruct = None # type hint
    for Notebook in parsed_files:
        rel_orig:str = Notebook.RelativeFilePath
        st.ext(file  = rel_orig)
        st.ext_clear_cellno() # NOTE: Clear cellno, because this is a new file.
        scopes:dict  = Notebook.ExportScopes
        assert zero_tuple in scopes, f'No (0,) in export Scopes.\n{Notebook}'
        scopes_available:bool      = (len(scopes) > 1)
        default_scope   :ScopeUnitStruct = scopes[zero_tuple]
        # NOTE: Having no default is ok, as long as all cells still have a valid export target
        none_default    :bool      = (default_scope is None)
        default_export  :Path      = None if none_default else default_scope.target
        
        if not none_default:
            # NOTE: Set this notebook as the origin of this notebooks default target in `merged_files`.
            # NOTE: `state` is used multiple times, but it's reassigned before each new use.
            state:dict = merged_files[default_export]
            if (state.orig is None): state.orig = rel_orig
            else: return st.report_error(
                ValueError(f'Multiple files have {default_export} as the default export target. '\
                           f'(old: {state.orig} | new: {rel_orig})')), None
        
        # DOC: Set 'add_dunder_all' for ScopeUnits, and check for mismatches.
        v:ScopeUnitStruct = None
        for scope, v in scopes.items():
            if v is None: continue
            state = merged_files[v.target]
            if   state.add_dunder_all is None: # NOTE: defaults to None
                state.add_dunder_all = v.add_dunder_all
            elif state.add_dunder_all == v.add_dunder_all:
                continue # NOTE: Another scope, possibly in another file also exports to this target,
                         #       but 'add_dunder_all' has the same value there, so no problem.
            else:
                # TODO: To improve this error message further, information about which previous files / cells
                # affected the same export state are necessary
                return st.report_error(ValueError('Multiple `default_exp` commands which specify the same target '\
                                        'cannot have different values for the `no_dunder_all` argument.\n'\
                                       f"The value defined in cell nr {v.cell_info.cell_nr} in '{rel_orig}' "\
                                        'does not match with a previous definition.')), None
        
        # DOC: Parse ExportUnits and add their content of each one to one MergedFileInfo
        cell:ExportUnitStruct = None
        for cell in Notebook.ExportUnits:
            cell_nr = cell.cell_info.cell_nr
            st.ext(cellno=cell_nr)
            info_string = f"# {'Internal ' if cell.is_internal else ''}Cell nr. {cell_nr}"
            info_string_src = (info_string + f"; Comes from '{rel_orig}'")
            
            assert ((cell.source_code is not None)
                 or (cell.names is not None))
            
            assert cell.is_internal is not None
            
            to:Path         = None
            to_default:bool = None
            
            if (cell.export_to is not None):
                # NOTE: Handle a cell directly specifying its export target
                to:Path = cell.export_to
                to_default = False
            else:
                # NOTE: We know it's not a fixed target, so now search for a scope
                if scopes_available and cell.export_to_scope:
                    cell_scope:tuple = cell.cell_info.scope
                    best_fit, best_fit_len = zero_tuple, 0
                    # NOTE: The number of scopes should usually be relatively small, so this should be fine.
                    for scope in scopes.keys():
                        new_len = len(scope)
                        if ((new_len > best_fit_len) # Trying to find the tightest fit
                            and (scope == cell_scope[:new_len])): # iff cell is part of this scope
                            best_fit, best_fit_len = scope, new_len
                    to:Path = scopes[best_fit].target
                    if (best_fit == zero_tuple) or (to == default_export):
                        to_default = True
                    else:
                        to_default = False
                else:
                    # No alternative scopes are available, so export to default
                    # assert cell.export_to_default
                    if none_default:
                        return st.report_error(ValueError(f'Cell does not have a export target. '\
                                         'Did you forget to add a default target using `default_exp`?')), None
                    to:Path = default_export
                    to_default = True
            
            assert (not (to         is None)) and isinstance(to, Path)
            assert (not (to_default is None))
            
            state:dict = merged_files[to]
            if (not cell.is_internal) and (cell.names is not None):
                state.names.update(cell.names)
            if (cell.source_code is not None):
                info = info_string if to_default else info_string_src
                state.code.append(f"{info}\n{relativify_imports(to, cell.source_code)}")
        # NOTE: Here is the end of the "for each file" loop
    return success, merged_files


# Cell nr. 269
@Traced
def write_file(to:Path, state:dict, st:StackTrace) -> bool:
    success:bool = True
    orig:str            = state.orig
    names:set           = state.names # This can be an empty set
    code:list           = state.code # This can be an empty list
    add_dunder_all:bool = state.add_dunder_all
    sep:str = '\n\n\n'
    if orig is None:
        warning = f'# AUTOGENERATED! DO NOT EDIT! View info comment on each cell for file to edit.'
    else:
        warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {orig} (unless otherwise specified).'
    if add_dunder_all:
        if len(names) > 0:
            # TODO: add line breaks at regular intervals
            comma = "', '"
            dunder_all = f"{sep}__all__ = ['{comma.join(sorted(names))}']"
        else: dunder_all = f'{sep}__all__ = []'
    else: dunder_all = ''
    code :str = sep + sep.join(code)
    file_content:str = f'{warning}{dunder_all}{code}'
    # to.parent.mkdir(parents=True, exist_ok=True) # TODO: remove
    try:
        with open(to, 'w', encoding='utf8') as f: f.write(file_content)
    except Exception as e: return st.report_error(e)
    return success


# Cell nr. 270
@Traced
def write_all(merged_files:dict, st:StackTrace) -> bool:
    "initialize the package, and writes all `merged_file`"
    success:bool = True
    config       = Config()
    lib_path     = config.lib_path
    dirs           = set([lib_path]) # NOTE: Even if no files are exported, add __init__.py to package root.
    dirs_with_init = set()
    for to, _ in merged_files.items():
        d = to.parent
        dirs.add(d)
        if to.name == '__init__.py': dirs_with_init.add(d)
    for d in dirs:
        if not d.exists():
            try: d.mkdir(parents=True, exist_ok=True)
            except Exception as e: return st.report_error(e)
        if d not in dirs_with_init: # same as `dirs.difference(dirs_with_init)`
            # NOTE: If not exported by user, write __init__.py with default content on every run.
            if in_directory(d, lib_path): # NOTE: ignore outside of package (like a setup.py)
                try:
                    with open((d/'__init__.py'), 'w', encoding='utf8') as f:
                        f.write(f"__version__ = '{config.version}'\n")
                except Exception as e: return st.report_error(e)
    for to, state in merged_files.items():
        write_success = write_file(to=to, state=state, st=st)
        if not write_success: return False
    return success


# Cell nr. 272
@Traced
def convert2py(RecursiveFileSearch:bool=True,
               st:StackTrace=None) -> Tuple[bool, dict, dict]:
    "Load, Parse, Merge, and Write .ipynb files to .py files."
    Success:bool = True
    config = Config() # NOTE: Verify that a settings.ini file exists.
    Context = {}
    
    # NOTE: LOAD
    Notebooks = async_load_notebooks(Directory=config.nbs_path, Recurse=RecursiveFileSearch)
    
    # NOTE: PARSE
    Success, ParsedNotebooks = parse_all(Notebooks, st=st)
    if not Success:
        st.report_error(Exception('At least one Error has occured during parsing. '\
                                  'No files on disk have been modified. Exiting.'))
        return (Success, ParsedNotebooks, None)
    
    # NOTE: MERGE
    Success, MergedFiles = merge_all(ParsedNotebooks, st=st)
    if not Success:
        st.report_error(Exception('At least one Error occured during merging of files to be exported. '\
                                  'No files on disk have been modified. Exiting.'))
        return (Success, ParsedNotebooks, MergedFiles)
    
    # NOTE: WRITE
    Success = write_all(MergedFiles, st=st)
    if not Success:
        st.report_error(Exception('At least one Error occured during writing the parsed and merged files to disk. '\
                                  'Some files might have been written to disk and others might not. Exiting.'))
        return (Success, ParsedNotebooks, MergedFiles)
    
    # NOTE: REPORT
    if main_REPORT_RUN_STATISTICS:
        report_successful_export(ParsedNotebooks, MergedFiles)
        
    # NOTE: RETURN
    return (Success, ParsedNotebooks, MergedFiles)


# Cell nr. 274
set_arg_parse_report_options(report_error=False)
set_main_report_options(report_optional_error=False,
                        report_command_found=False,
                        report_run_statistics=True)