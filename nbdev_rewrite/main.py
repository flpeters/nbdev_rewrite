# AUTOGENERATED! DO NOT EDIT! File to edit: 00_export_v4.ipynb (unless otherwise specified).


__all__ = ['MODULE__MAIN__FLAG', 'StackTrace', 'all_commands', 'async_load_notebooks', 'cmd2func', 'crawl_directory', 'find_names', 'init_lib', 'iter_comments', 'kw_default_exp', 'kw_export', 'main', 'make_valid_path', 'merge_all', 'module_to_path', 'parse_all', 'parse_comment', 'parse_file', 'read_nb', 'register_command', 'relativify_imports', 'report_successful_export', 'set_main_report_options', 'traced', 'write_all', 'write_file']


# Cell nr. 68
# This Flag allows anyone to know if this Module exists in their namespace
MODULE__MAIN__FLAG = None


# Cell nr. 70
from collections import defaultdict
from inspect import signature, currentframe, getfullargspec
import nbformat
import ast
from ast import iter_fields, AST
import _ast


# Cell nr. 72
if (__name__ != '__main__') or ('MODULE__ARGUMENT_PARSING__FLAG' not in globals()):
    from .argument_parsing import *
assert 'MODULE__ARGUMENT_PARSING__FLAG' in globals(), "Missing the 'argument_parsing' module."

if (__name__ != '__main__') or ('MODULE__IMPORTS__FLAG' not in globals()):
    from .imports import *
assert 'MODULE__IMPORTS__FLAG' in globals(), "Missing the 'imports' module."


# Internal Cell nr. 75
main_REPORT_OPTIONAL_ERROR:bool = False
main_REPORT_COMMAND_FOUND:bool = False
main_REPORT_RUN_STATISTICS:bool = True


# Cell nr. 76
def set_main_report_options(report_optional_error:bool=False,
                            report_command_found:bool=False,
                            report_run_statistics:bool=True):
    "Set options for how the Main Module will behave on encountering errors or warnings.\n"\
    "report_optional_error prints the information and then continues."
    global main_REPORT_OPTIONAL_ERROR, main_REPORT_COMMAND_FOUND, main_REPORT_RUN_STATISTICS
    main_REPORT_OPTIONAL_ERROR = report_optional_error
    main_REPORT_COMMAND_FOUND  = report_command_found
    main_REPORT_RUN_STATISTICS = report_run_statistics


# Internal Cell nr. 78
def relative_path(file_path, relative_directory=Config().config_file.parent):
    return os.path.relpath(file_path, relative_directory).replace('\\', '/')


# Cell nr. 79
def report_successful_export(parsed_files, merged_files):
    "Report stats and compressed information about parsed and exported files."
    n_nbs = nr_of_notebooks_parsed = len(parsed_files['files'])
    n_py  = nr_of_output_py_files = len(merged_files)
    Title = f'{n_nbs} notebook{"s"*int(n_nbs!=1)} {"have" if n_nbs!=1 else "has"} been parsed, '\
            f'resulting in {n_py} python file{"s"*int(n_py!=1)}.\n\n'
    
    # Information about which notebooks export to which python files
    nb_info = f'The following {n_nbs} notebook{"s"*int(n_nbs!=1)} have been parsed:\n'
    nb_info += '-' * (len(nb_info) - 1)
    n_out = nr_of_files_outputting_code = 0
    for file in parsed_files['files']:
        nb_info += f"\n{file['relative_origin']} ({len(file['cells'])} cells total)\n"
        default = file['export_scopes'][(0,)]
        n_exp = len(file['export_scopes']) - int(default is None)
        nb_info += f'---> default:\t{None if (default is None) else relative_path(default["target"])}'
        for scope, target in sorted(file['export_scopes'].items(), key=lambda x: x[0]):
            if scope == (0,): continue
            nb_info += f"\n---> {scope}:\t{relative_path(target['target'])}"
        if n_exp > 0: n_out += 1
    
    
    Middle = f'Of the {n_nbs} notebook{"s"*int(n_nbs!=1)} parsed, '\
             f'{n_out} {"are" if n_out!=1 else "is"} outputting code.'
    
    # Information about how many Python files have been generated, and the number of cells exported to each
    py_info = f'The following {n_py} python file{"s"*int(n_py!=1)} {"have" if n_py!=1 else "has"} been generated:\n'
    py_info += '-' * (len(py_info) - 1) + '\n'
    for to, state in merged_files.items():
        n_cells = len(state['code'])
        py_info += f'---> {n_cells} cell{"s"*int(n_cells!=1)} output to {relative_path(to)}\n'
        
    print(f'{Title}{nb_info}\n\n{Middle}\n\n{py_info}')


# Cell nr. 82
class StackTrace: pass # only for :StackTrace annotations to work
class StackTrace:
    _up:StackTrace = None
    namespace:str = None
    lineno   :int = None
    _ext_file:dict = None
        
    def __init__(self, namespace:object=None, up:StackTrace=None):
        "`namespace` can be a function, a class, or None.\n"\
        "`up` is optional and can be another StackTrace instance."
        self.namespace = f'<{namespace.__qualname__}>()' if namespace else currentframe().f_back.f_code.co_name
        self._up, self.lineno, self._ext_file = up, currentframe().f_back.f_lineno, {}
    
    def ext(self, file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):
        "Set context information for reporting errors in external files e.g. notebooks."
        e = self._ext_file
        if file: e['file'] = file
        if cellno: e['cellno'] = cellno
        if lineno: e['lineno'] = lineno
        if excerpt: e['excerpt'] = excerpt
        if span   : e['span'   ] = span
    
    def to_list(self):
        "Creates list of the entire StackTrace (most recent last)."
        if self._up: return [*self._up.to_list(), self]
        else: return [self]
        
    def _reduce_ext(self):
        "Combines all `StackTrace._ext_file` dicts into one, prefering more recest settings over old ones."
        ext = [s._ext_file for s in self.to_list() if s._ext_file]
        if ext:
            e = ext[0]
            for d in ext[1:]: e.update(d)
            return e
        else: return {}
        
    def up(self, up:StackTrace):
        "Set this StackTraces `_up` reference and return `self`. Useful for chaining references."
        self._up=up
        return self
    
    def __repr__(self): return f"{__name__}.StackTrace(namespace={self.namespace},line={self.lineno})"
    
    def _repr(self):
        "Recursively create a string of all StackTraces for printing error messages."
        return f"{'' if self._up is None else self._up._repr()}"\
               f"<{__name__}>, line {self.lineno} in {self.namespace}\n"
    
    def _repr_ext(self, file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):
        "Create a string from the `StackTrace._ext_file` dict for printing error messages."
        s = f"<{file}>, cell {cellno}, line {lineno}\n"
        if excerpt:
            x = f"--->{' ' if ((lineno is None) or (0 <= lineno <= 9)) else ''}{lineno} "
            s += f"{x}{excerpt}\n"\
                 f"{(' ' * (len(x) + span[0]) + '^' * span[1]) if span else ''}\n"
        return s        
    
    def report_error(self, err:Exception,
                     file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None,
                     success=False, _ln_of_callsite=True) -> bool:
        "Report the Error `err`.\nOther args are used for setting `_ext_file` and are optional.\n"\
        "Returns whatever is passes as `success`."
        if _ln_of_callsite: self.lineno = currentframe().f_back.f_lineno
        err_type = err.__class__.__name__
        s = f"{'-'*75}\n"\
            f"{err_type}{' '*(41-len(err_type))}Stacktrace (most recent call last)\n"\
            f"{self._repr()}\n"
        self.ext(file, cellno, lineno, excerpt, span)
        ext:dict = self._reduce_ext()
        if ext: s += f"{self._repr_ext(**ext)}\n"
        s += f"[{err_type}]: {err}"
        print(s)
        return success
    
    def report_optional_error(self, err:Exception,
                        file:str=None, cellno:int=None, lineno:int=None, excerpt:str=None, span:(int, int)=None):
        "Report the error if the global variable `main_REPORT_OPTIONAL_ERROR` is set."
        if main_REPORT_OPTIONAL_ERROR:
            self.lineno = currentframe().f_back.f_lineno
            self.report_error(err=err, _ln_of_callsite=False,
                              file=file, cellno=cellno, lineno=lineno, excerpt=excerpt, span=span)


# Cell nr. 83
def traced(f):
    "The Annotated function will have a StackTrace instance passed to it as the `st` keyword-argument.\n"\
    "That instance represents the annotated function, with a reference to the calling site."
    spec = getfullargspec(f)
    assert ('st' in spec.args) or ('st' in spec.kwonlyargs), "Traced functions have to take a 'st' argument."
    if 'st' in spec.annotations:
        assert spec.annotations['st'] == StackTrace, "A traced functions 'st' argument is reserved for "\
                                                     "a StackTrace. Other annotations are not allowed."
    else: f.__annotations__['st'] = StackTrace # This modifies the original function. Is that acceptable?
    
    _st = StackTrace(f)
    def _wrapper(*args, st:StackTrace=None, **kwargs):
        if not st:
            st = StackTrace(None)
            st.namespace = currentframe().f_back.f_code.co_name
        elif (st is _st): return f(*args, st=st, **kwargs) # prevent self referencing due to e.g. recursion.
        st.lineno = currentframe().f_back.f_lineno
        return f(*args, st=_st.up(st), **kwargs)
    
    functools.update_wrapper(_wrapper, f)
    return _wrapper


# Cell nr. 98
# TODO: Only look for 0 indent comments?
def iter_comments(src:str, pure_comments_only:bool=True, line_limit:int=None) -> (str, (int, int)):
    "Detect all comments in a piece of code, excluding those that are a part of a string."
    in_lstr = in_sstr = False
    count, quote = 1, ''
    for i, line in enumerate(src.splitlines()[:line_limit]):
        is_pure, escape, prev_c = True, False, '\n'
        for j, c in enumerate(line):
            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns
            if is_pure and (not (c.isspace() or c == '#')): is_pure = False
            if (in_sstr or in_lstr):
                # assert in_sstr ^ in_lstr # XOR
                if escape: count = 0
                else:
                    if (c == quote):
                        count = ((count + 1) if (c == prev_c) else 1)
                        if in_sstr: in_sstr = False
                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False
                escape = False if escape else (c == '\\')
            else:                    
                if (c == '#'):
                    if (pure_comments_only and is_pure): yield (line, (i, j))
                    elif (not pure_comments_only):       yield (line[j:], (i, j))
                    break
                elif c == "'" or c == '"':
                    count = ((count + 1) if (c == prev_c) else 1)
                    if count == 1: in_sstr = True
                    elif count == 3: count, in_lstr = 0, True
                    else: assert False, 'If this code path happens, then the code keeping track of quotes is broken.'
                    quote = c
            prev_c = c


# Internal Cell nr. 102
# https://docs.python.org/3/library/re.html
re_match_comment = re.compile(r"""
        ^              # start of the string
        \s?            # 0 or 1 whitespace
        \#+\s?         # 1 or more literal "#", then 0 or 1 whitespace
        (.*)           # group of arbitrary symbols (except new line)
        $              # end of the string
        """,re.IGNORECASE | re.VERBOSE) # re.MULTILINE is not passed, since this regex is used on each line separately.


# Cell nr. 107
@traced
def parse_comment(all_commands:dict, comment:str, st:StackTrace) -> (bool, str, dict, dict):
    "Finds command names and arguments in comments and parses them with parse_arguments()"
    res = re_match_comment.search(comment)
    if not res:
        st.report_optional_error(SyntaxError('Not a valid comment syntax.'))
        return False, None, None, None
    
    all_args = res.groups()[0].split()
    if len(all_args) == 0:
        st.report_optional_error(SyntaxError(f"Need at least one argument in comment. Reveived: '{comment}'"))
        return False, None, None, None
    
    cmd, *args = all_args
    if cmd[0] != '+':
        st.report_optional_error(SyntaxError("The first argument (the command to execute) does not start with a '+'."\
                                            f"It was: '{cmd}'"), span=(1, 3))
        return False, None, None, None
    
    cmd = cmd[1:] # remove the '+'
    if cmd not in all_commands:
        st.report_optional_error(KeyError(f"'{cmd}' is not a recognized command. See 'all_commands'."))
        return False, None, None, None
    
    success, result, is_set = parse_arguments(all_commands[cmd], args)
    if not success: return False, None, None, None
    
    return True, cmd, result, is_set


# Internal Cell nr. 117
class Context:
    def __init__(self, cell_nr=None, export_nr=None):
        self.cell_nr   = cell_nr
        self.export_nr = export_nr
    def __repr__(self):
        return f'cell_nr: {self.cell_nr}, export_nr: {self.export_nr}'


# Internal Cell nr. 118
def lineno(node):
    "Format a string containing location information on ast nodes. Used for Debugging only."
    if hasattr(node, 'lineno') and hasattr(node, 'col_offset'):
        return f'line_nr: {node.lineno} col_offset: {node.col_offset}'
    else: return ''


# Internal Cell nr. 119
def info(context, node):
    "Format a string with available information on a ast node. Used for Debugging only."
    return f'\nLocation: {context} | {lineno(node)}'


# Internal Cell nr. 121
def unwrap_attr(node:_ast.Attribute) -> str:
    "Joins a sequance of Attribute accesses together in a single string. e.g. numpy.array"
    if isinstance(node.value, _ast.Attribute): return '.'.join((unwrap_attr(node.value), node.attr))
    else: return '.'.join((node.value.id, node.attr))


# Internal Cell nr. 122
def update_from_all_(node, names, c):
    "inplace, recursive update of set of names, by parsing the right side of a _all_ variable"
    if   isinstance(node, _ast.Str): names.add(node.s)
    elif isinstance(node, _ast.Name): names.add(node.id)
    elif isinstance(node, _ast.Attribute): names.add(unwrap_attr(node))
    elif isinstance(node, (_ast.List, _ast.Tuple, _ast.Set)):
        for x in node.elts: update_from_all_(x, names, c)
    elif isinstance(node, _ast.Subscript) :
        raise SyntaxError(f'Subscript expression not allowed in _all_. {info(c, node)}')
    elif isinstance(node, _ast.Starred):
        raise SyntaxError(f'Starred expression *{node.value.id} not allowed in _all_. {info(c, node)}')
    else: raise SyntaxError(f'Can\'t resolve {node} to name, unknown type. {info(c, node)}')


# Internal Cell nr. 123
def unwrap_assign(node, names, c):
    "inplace, recursive update of list of names"
    if   isinstance(node, _ast.Name)      : names.append(node.id)
    elif isinstance(node, _ast.Starred)   : names.append(node.value.id)
    elif isinstance(node, _ast.Attribute) : names.append(unwrap_attr(node))
    elif isinstance(node, _ast.Subscript) : pass # e.g. a[0] = 1
    elif isinstance(node, (_ast.List, _ast.Tuple)):
        for x in node.elts: unwrap_assign(x, names, c)
    elif isinstance(node, list):
        for x in node: unwrap_assign(x, names, c)
    else: raise SyntaxError(f'Can\'t resolve {node} to name, unknown type. {info(c, node)}')


# Internal Cell nr. 124
def not_private(name): return not (name.startswith('_') and (not name.startswith('__')))


# Internal Cell nr. 125
def add_names_A(node, names, c):
    "Handle Assignments to variables"
    tmp_names = list()
    if   isinstance(node, _ast.Assign):
        unwrap_assign(node.targets, tmp_names, c)
    elif isinstance(node, _ast.AnnAssign):
        unwrap_assign(node.target, tmp_names, c)
    else: assert False, 'add_names_A only accepts _ast.Assign or _ast.AnnAssign'
    for name in tmp_names:
        if not_private(name): names.add(name)
        # NOTE: special cases below can only use private variable names
        elif name == '_all_': # NOTE: _all_ is a keyword reserved by nbdev.
            if len(tmp_names) != 1:
                raise SyntaxError(f'Reserved keyword "_all_" can only be used in simple assignments. {info(c, node)}')
            update_from_all_(node.value, names, c)


# Internal Cell nr. 126
def resolve_decorator_name(node):
    if   isinstance(node, _ast.Name): return node.id
    elif isinstance(node, _ast.Call):
        if   isinstance(node.func, _ast.Name     ): return node.func.id
        elif isinstance(node.func, _ast.Attribute): return unwrap_attr(node.func)
    elif isinstance(node, _ast.Attribute): return unwrap_attr(node)
    raise SyntaxError(f'Can\'t resolve decorator {node} to name, unknown type. {info(c, node)}')

def decorators(node): yield from (resolve_decorator_name(d) for d in node.decorator_list)

def fastai_patch(cls, node, names, c):
    if   isinstance(cls, _ast.Name):
        if not_private(cls.id): names.add(f'{cls.id}.{node.name}')
    elif isinstance(cls, (_ast.List, _ast.Tuple, _ast.Set)):
            for x in cls.elts: fastai_patch(x, node, names, c)
    else: raise SyntaxError(f'Can\'t resolve {cls} to @patch annotation, unknown type. {info(c, node)}')

# ignoring `@typedispatch` might not even be neccesarry,
# since all names are added to a single set before being exported.
def add_names_FC(node, names, c, fastai_decorators=True):
    "Handle Function and Class Definitions"
    if fastai_decorators and ('patch' in decorators(node)):
        if not (len(node.args.args) >= 1): raise SyntaxError(f'fastai\'s @patch decorator requires at least one parameter. {info(c, node)}')
        cls = node.args.args[0].annotation
        if cls is None: raise SyntaxError(f'fastai\'s @patch decorator requires a type annotation on the first parameter. {info(c, node)}')
        fastai_patch(cls, node, names, c)
    elif fastai_decorators and ('typedispatch' in decorators(node)): return # ignore @typedispatch
    elif not_private(node.name): names.add(node.name)


# Cell nr. 127
def find_names(code:str, context:Context=None) -> list:
    "Find all function, class and variable names in the given source code."
    tree = ast.parse(code) # TODO: This can raise errors. Catch and wrap nicely?
    names = set()
    for node in tree.body:
        if   isinstance(node, (_ast.Assign     , _ast.AnnAssign)): add_names_A (node, names, context)
        elif isinstance(node, (_ast.FunctionDef, _ast.ClassDef )): add_names_FC(node, names, context)
        else: pass
    return names


# Internal Cell nr. 133
def make_import_relative(p_from:Path, m_to:str)->str:
    "Convert a module `m_to` to a name relative to `p_from`."
    mods = m_to.split('.')
    splits = str(p_from).split(os.path.sep)
    if mods[0] not in splits: return m_to
    i=len(splits)-1
    while i>0 and splits[i] != mods[0]: i-=1
    splits = splits[i:]
    while len(mods)>0 and splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]
    return '.' * len(splits) + '.'.join(mods)


# Internal Cell nr. 137
# https://docs.python.org/3/library/re.html
letter = 'a-zA-Z'
identifier = f'[{letter}_][{letter}0-9_]*'
re_import = ReLibName(fr"""
    ^                             # start of the string / line
    (\ *)                         # any amount of whitespace (indenting)
    from(\ +)                     # 'from', followed by at least one whitespace
    (LIB_NAME(?:\.{identifier})*) # Name of the library, possibly followed by dot separated submodules
    \ +import(.+)                 # whitespace, then 'import', followed by arbitrary symbols except new line
    $                             # end of the string / line
    """, re.VERBOSE | re.MULTILINE)


# Cell nr. 138
def relativify_imports(origin:Path, code:str)->str:
    "Transform an absolute 'from LIB_NAME import module' into a relative import of 'module' wrt the library."
    def repl(match):
        sp1,sp2,module,names = match.groups()
        return f'{sp1}from{sp2}{make_import_relative(origin, m_to=module)} import{names}'
    return re_import.re.sub(repl,code)


# Cell nr. 141
def init_lib():
    "initialize the module folder, if it's not initialized already"
    C = Config()
    if (not C.lib_path.exists()) or (not (C.lib_path/'__init__.py').exists()):
        C.lib_path.mkdir(parents=True, exist_ok=True)
        with (C.lib_path/'__init__.py').open('w') as f:
            f.write(f'__version__ = "{C.version}"\n')
    else: pass # module *should* already exists
init_lib()


# Internal Cell nr. 147
# https://docs.python.org/3/library/re.html
letter = 'a-zA-Z'
identifier = f'[{letter}_][{letter}0-9_]*'
module = fr'(?:{identifier}\.)*{identifier}'
module


# Internal Cell nr. 148
# https://docs.python.org/3/library/re.html
re_match_module = re.compile(fr"""
        ^              # start of the string
        {module}       # definition for matching a module 
        $              # end of the string
        """, re.VERBOSE)


# Cell nr. 150
@traced
def module_to_path(m:str, st:StackTrace)->(bool, Path):
    "Turn a module name into a path such that the exported file can be imported from the library "\
    "using the same expression."
    if re_match_module.search(m) is not None:
        if m.endswith('.py'):
            return st.report_error(ValueError(f"The module name '{m}' is not valid, because ending on '.py' "\
                                f"would produce a file called 'py.py' in the folder '{m.split('.')[-2]}', "\
                                 "which is most likely not what was intended.\nTo name a file 'py.py', use the "\
                                 "'-to_path' argument instead of '-to'.")), None
        return True, Config().path_to('lib')/f"{os.path.sep.join(m.split('.'))}.py"
    else: return st.report_error(ValueError(f"'{m}' is not a valid module name.")), None


# Internal Cell nr. 157
def commonpath(*paths)->Path:
    "Given a sequence of path names, returns the longest common sub-path."
    return Path(os.path.commonpath(paths))


# Internal Cell nr. 159
def in_directory(p:Path, d:Path)->bool:
    "Tests if `p` is pointing to something in the directory `d`.\n"\
    "Expects both `p` and `d` to be fully resolved and absolute paths."
    return p.as_posix().startswith(d.as_posix())


# Cell nr. 162
@traced
def make_valid_path(s:str, st:StackTrace)->(bool, Path):
    "Turn a export path argument into a valid path, resolving relative paths and checking for mistakes."
    p, lib = Path(s), Config().path_to('lib')
    is_abs = p.is_absolute()
    p = (p if is_abs else (lib/p)).absolute().resolve()
    if (not is_abs) and (not in_directory(p, lib)):
        return st.report_error(ValueError("Relative export path beyond top level directory of library"\
                                          "is not allowed by default. Use an absolute path, "\
                                          f"or set <NOT IMPLEMENTED YET> flag on the command. ('{s}')")), None
    if not p.suffix:
        return st.report_error(ValueError(f"The path '{s}' is missing a file type suffix like '.py'.")), None
    if p.suffix == '.py': return True, p
    else: return st.report_error(ValueError(f"Expected '.py' file ending, but got '{p.suffix}'. ('{s}')")), None


# Cell nr. 169
def register_command(cmd, args, active=True):
    "Store mapping from command name to args, and command name to reference to the decorated function in globals."
    if not active: return lambda f: f
    all_commands[cmd] = args
    def _reg(f):
        cmd2func[cmd] = f
        return f
    return _reg


# Cell nr. 170
all_commands = {}
cmd2func     = {}


# Cell nr. 172
@register_command(cmd='default_exp', # allow custom scope name that can be referenced in export?
                  args={'to': '', 'to_path': '', 'no_dunder_all': False, 'scoped': False})
@traced
def kw_default_exp(file_info, cell_info, result, is_set, st:StackTrace) -> bool:
    "Set the default file that cells of this notebook will be exported to."
    success:bool = True
    if not (is_set['to'] ^ is_set['to_path']): # NOTE: XOR
        return st.report_error(ValueError("The `default_exp` command expects exactly one of the arguments "\
                               f"'-to' or '-to_path' to be set, but recieved was: {result}"))
    # NOTE: use this cells indentation level, or the default tuple([0]) as key to identify scope
    scope:tuple     = cell_info['scope'] if result['scoped'] else tuple([0])
    old_target:Path = file_info['export_scopes'].get(scope, None)
    conv_success, new_target = (module_to_path(result['to'], st=st)
                                if is_set['to'] else
                                make_valid_path(result['to_path'], st=st))
    if not conv_success: return False
    if old_target is not None:
        if old_target['target'] != new_target:
            return st.report_error(ValueError(f"Overwriting an existing export target is not allowed."\
                            f"\n\twas (cell {old_target['cell_info']['cell_nr']}): '{old_target['target']}'"\
                            f"\n\tnew (cell {cell_info['cell_nr']}): '{new_target}'"))
        else: pass # TODO: issue a warning in this case
    file_info['export_scopes'][scope] = {
        'target' : new_target,
        'add_dunder_all' : (not result['no_dunder_all']),
        'cell_info' : cell_info,
    }
    return success


# Cell nr. 174
@register_command(cmd='export',
                  args={'internal': False, 'to': '', 'to_path':'', 'ignore_scope':False})
@traced
def kw_export(file_info, cell_info, result, is_set, st:StackTrace) -> bool:
    "This cell will be exported from the notebook to a .py file."
    success:bool = True
    if (is_set['to'] and is_set['to_path']):
        return st.report_error(ValueError("The `export` command does not accept the '-to' and '-to_path' "\
                               f"argument at the same time. They are mutually exclusive. Received: {result}"))
    cell_info['export_to_py'] = True # Using this command implicitly means to export this cell
    is_internal = cell_info['is_internal'] = result['internal']
    if is_internal: pass # no contained names will be added to __all__ for importing
    else: cell_info['names'] = find_names(cell_info['original_source_code'])
    conv_success, export_target = True, None
    if is_set['to'     ]: conv_success, export_target = module_to_path (result['to'], st=st)
    if is_set['to_path']: conv_success, export_target = make_valid_path(result['to_path'], st=st)
    if not conv_success: return False
    if export_target is not None:
        if is_set['ignore_scope']:
            return st.report_error(ValueError("Setting 'ignore_scope' is not allowed when "\
                                   f"exporting to a custom target using 'to' or 'to_path'."))
        cell_info['export_to'].append(export_target) # Set a new export target just for this cell.
    else:
        if result['ignore_scope']: cell_info['export_to_default'] += 1
        else:                      cell_info['export_to_scope']   += 1
    return success


# Cell nr. 184
_reserved_dirs = (Config().lib_path, Config().doc_path)
def crawl_directory(path:Path, recurse:bool=True) -> list:
    "Crawl the `path` directory for a list of .ipynb files."
    # TODO: Handle symlinks?
    if isinstance(path, (list, tuple, set)):
        for p in path: yield from crawl_directory(p, recurse)
    else:
        if path.is_file(): yield path
        else:
            for p in path.iterdir():
                fn = p.name
                if fn.startswith('.') or fn.startswith('_'): continue
                if p.is_file():
                    if fn.endswith('.ipynb'): yield p
                    else: continue
                elif p.is_dir() and recurse:
                    if p in _reserved_dirs: continue
                    else: yield from crawl_directory(p, recurse)
                else: continue


# Cell nr. 185
def read_nb(fname:Path) -> dict:
    "Read the `fname` notebook."
    with open(Path(fname),'r', encoding='utf8') as f: return dict(nbformat.reads(f.read(), as_version=4))


# Cell nr. 186
@prefetch(max_prefetch=-1) # NOTE: max_prefetch <= 0 means the queue size is infinite
def async_load_notebooks(path:Path=Config().nbs_path, recurse:bool=True) -> (Path, dict):
    "Crawl for notebooks in the `path` directory, and load in a background thread."
    for file_path in crawl_directory(path, recurse): yield (file_path, read_nb(file_path))


# Internal Cell nr. 192
# https://docs.python.org/3/library/re.html
re_match_heading = re.compile(r"""
        ^              # start of the string
        (\#+)\s+       # 1 or more literal "#", then 1 or more whitespace
        (.*)           # group of arbitrary symbols (including new line)
        $              # end of the string
        """,re.IGNORECASE | re.VERBOSE | re.DOTALL)


# Cell nr. 194
@traced
def parse_file(file_path:Path, file:dict, st:StackTrace) -> (bool, dict):
    success = True
    pure_comments_only = True
    nb_version:(int, int) = (file['nbformat'], file['nbformat_minor'])
    metadata  :dict       =  file['metadata']
        
    file_info = {
        'origin_file': file_path,
        'relative_origin': os.path.relpath(file_path, Config().config_file.parent).replace('\\', '/'),
        'nb_version': nb_version,
        'export_scopes': {
            tuple([0]): None, # This is the default for an entire file.
        },
        'cells': list()
    }
    scope_count :[int] = [0]
    scope_level :int   = 0
    
    cells:list = file_info['cells']
    
    st.ext(file=file_info['relative_origin'])
    
    for i, cell in enumerate(file['cells']):
        cell_type   = cell['cell_type']
        cell_source = cell['source']
        cell_info = {
            'cell_nr' : i,
            'cell_type' : cell_type,
            'original_source_code' : cell_source,
            'processed_source_code': cell_source,
            'scope' : tuple(scope_count),
            'export_to_py' : False,
            'export_to_scope' : 0,
            'export_to_default' : 0,
            'is_internal' : None,
            'export_to' : [],
            'names' : None,
            'comments' : []
        }
        if cell_type == 'code':
            st.ext(cellno = i)
            comments_to_remove = []
            for comment, (lineno, charno) in iter_comments(cell_source, pure_comments_only, line_limit=None):
                st.ext(lineno = lineno + 1) # zero counting offset
                st.ext(excerpt = comment)
                parsing_success, cmd, result, is_set = parse_comment(all_commands,comment,st=st)
                if not parsing_success: continue
                # TODO: cound nr of found cells
                if main_REPORT_COMMAND_FOUND:
                    print(f'Found: {cmd} @ ({i}, {lineno}, {charno}) with args: {result}')
                if cmd in cmd2func:
                    cmd_success = cmd2func[cmd](file_info, cell_info, result, is_set, st=st)
                    if not cmd_success: return False, file_info # TODO: Stop at first error or continue?
                else: raise ValueError(f"The command '{cmd}' in cell number {i} is recognized, "\
                                        "but is missing a corresponding action mapping in cmd2func.")
                cell_info['comments'].append(comment)
                comments_to_remove.append((lineno, charno))
            if len(comments_to_remove) > 0:
                lines = cell_source.splitlines()
                if pure_comments_only:
                    for lineno, charno in comments_to_remove[::-1]: lines.pop(lineno)
                else:
                    for lineno, charno in comments_to_remove[::-1]: lines[lineno] = lines[lineno][:charno]
                cell_info['processed_source_code'] = '\n'.join(lines)
            
        elif cell_type == 'markdown':
            res = re_match_heading.search(cell_source)
            if not (res is None): # this cell contains a heading
                heading_level, heading_name = res.groups()
                new_scope_level = len(heading_level) # number of '#' in the heading
                if new_scope_level > scope_level:
                    scope_count += ([0] * (new_scope_level - (len(scope_count)))) # extend list if necessary
                elif new_scope_level < scope_level:
                    scope_count = scope_count[:new_scope_level] # reset lower values
                scope_count[new_scope_level - 1] += 1
                scope_level = new_scope_level
            else: pass # this cell is regular markdown
        elif cell_type == 'raw': pass
        else: raise ValueError(f"Unknown cell_type '{cell_type}' in cell number {i}."\
                                "Should be 'code', 'markdown', or 'raw'.")
        cells.append(cell_info)
    return success, file_info


# Cell nr. 195
@traced
def parse_all(file_generator, st:StackTrace) -> (bool, dict):
    "Loads all .ipynb files in the origin_path directory, and passes them one at a time to parse_file."
    success:bool = True
    parsed_files = {
        # Add flags and settings variables above this line
        'files': list()
    }
    # TODO: use multithreading / multiprocessing per file / per n cells
    for file_path, file in file_generator:
        # if file_path.name != THIS_FILE: continue # For Debugging
        parse_success, file = parse_file(file_path, file, st=st)
        if not parse_success:
            success = False # TODO: Stop at first error or continue?
        # TODO: before returning, give any meta programm a chance to run.
        # maybe have parse_file return some additional information about any meta programm
        parsed_files['files'].append(file)
        
    return success, parsed_files


# Cell nr. 197
@traced
def merge_all(parsed_files:dict, st:StackTrace) -> (bool, dict):
    success:bool = True
    config    = Config()
    lib_path  = config.lib_path
    nbs_path  = config.nbs_path
    proj_path = config.config_file.parent
    zero_tuple = tuple([0])
    
    # NOTE: This will contain all the merges files
    export_files = defaultdict(lambda: {'names': set(), 'code': [], 'orig': None, 'add_dunder_all':None})
    
    for file_info in parsed_files['files']:
        rel_orig:str = file_info['relative_origin']
        scopes:dict  = file_info['export_scopes']
        assert zero_tuple in scopes, 'No default in export Scopes.'
        scopes_available:bool = (len(scopes) > 1)
        default_scope   :dict = scopes[zero_tuple]
        # NOTE: Having no default is ok, as long as all cells still have a valid export target
        none_default    :bool = (default_scope is None)
        default_export  :Path = None if none_default else default_scope['target']
            
        if not none_default:
            # NOTE: Set this notebooks default as the origin of one of the `export_files`.
            default_state:dict = export_files[default_export]
            if (default_state['orig'] is None): default_state['orig'] = rel_orig
            else: raise ValueError(f'Multiple files have {default_export} as the default export target. '\
                                   f'(old: {default_state["orig"]} | new: {rel_orig})')
                
        for cell in file_info['cells']:
            # NOTE: At this point, the `file_info` still contains all of the original cells of the notebook
            if not cell['export_to_py']: continue
            info_string = f"# {'Internal ' if cell['is_internal'] else ''}Cell nr. {cell['cell_nr']}"
            info_string_src = (info_string + f"; Comes from '{rel_orig}'")
            
            # NOTE: Handle a cell directly specifying its export target
            if len(cell['export_to']) > 0:
                for to in cell['export_to']:
                    state:dict = export_files[to]
                    if not cell['is_internal']: state['names'].update(cell['names'])
                    state['code'].append(f"{info_string_src}\n{relativify_imports(to, cell['processed_source_code'])}")
            
            # NOTE: Handle a cell belonging to a scope and find the best match
            if scopes_available:
                if cell['export_to_scope'] > 0:
                    # Do scope matching
                    cell_scope:tuple = cell['scope']
                    best_fit = zero_tuple
                    best_fit_len = 0
                    # NOTE: The number of scopes should usually be relatively small, so this should be fine.
                    for k in scopes.keys():
                        if ((len(k) > best_fit_len) # Trying to find the tightest fit
                            and (k == cell_scope[:len(k)])): # iff cell is part of this scope
                            best_fit, best_fit_len = k, len(k)
                    to:Path = scopes[best_fit]['target']
                    if (best_fit == zero_tuple) or (to == default_export):
                        cell['export_to_default'] += cell['export_to_scope']
                        cell['export_to_scope'] = 0
                        pass
                    else:
                        state:dict = export_files[to]
                        if not cell['is_internal']: state['names'].update(cell['names'])
                        for _ in range(cell['export_to_scope']):
                            state['code'].append(f"{info_string_src}\n{relativify_imports(to, cell['processed_source_code'])}")
            else:
                cell['export_to_default'] += cell['export_to_scope']
                cell['export_to_scope'] = 0
            
            # NOTE: Handle a cell ignoring all scopes, or being in the default scope.
            if cell['export_to_default'] > 0:
                if none_default:
                    raise ValueError(f'Export Target of cell {cell["cell_nr"]} is None. '\
                                     'Did you forget to add a default target using `default_exp`?')
                to:Path = default_export
                state:dict = export_files[to]
                if not cell['is_internal']: state['names'].update(cell['names'])
                for _ in range(cell['export_to_default']):
                    state['code'].append(f"{info_string}\n{relativify_imports(to, cell['processed_source_code'])}")
        # NOTE: Set 'add_dunder_all' and check for mismatches
        for k, v in scopes.items(): # for all scopes that this files exports to
            if v is None: continue
            state = export_files[v['target']]
            if   state['add_dunder_all'] is None: # it defaults to None, see top of the function
                 state['add_dunder_all'] = v['add_dunder_all']
            elif state['add_dunder_all'] == v['add_dunder_all']:
                continue
            else:
                # TODO: To improve this error message further, information about which previous files / cells
                # affected the same export state are necessary
                return st.report_error(ValueError('Multiple `default_exp` commands which specify the same target '\
                                        'cannot have different values for the `no_dunder_all` argument.\n'\
                                       f"The value defined in cell nr {v['cell_info']['cell_nr']} in '{rel_orig}' "\
                                       f'does not match with a previous definition.'))
        # NOTE: The files can't yet be written, because there might be other notebooks exporting to the same files.
        # NOTE: This is the end of the "for each file" loop
    return success, export_files


# Cell nr. 204
@traced
def write_file(to:Path, state:dict, st:StackTrace) -> bool:
    success:bool = True
    orig:str  = state['orig']
    names:set = state['names']
    code:list = state['code']
    add_dunder_all:bool = state['add_dunder_all']
    sep:str = '\n\n\n'
    if orig is None:
        warning = f'# AUTOGENERATED! DO NOT EDIT! View info comment on each cell for file to edit.'
    else:
        warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {orig} (unless otherwise specified).'
    if add_dunder_all:
        if len(names) > 0:
            # TODO: add line breaks at regular intervals
            comma = "', '"
            dunder_all = f"{sep}__all__ = ['{comma.join(sorted(names))}']"
        else: dunder_all = f'{sep}__all__ = []'
    else: dunder_all = ''
    code :str = sep + sep.join(code)
    file_content:str = f'{warning}{dunder_all}{code}'
    to.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(to, 'w', encoding='utf8') as f: f.write(file_content)
    except Exception as e: return st.report_error(e)
    return success


# Cell nr. 205
@traced
def write_all(merged_files:dict, st:StackTrace) -> bool:
    # print(dict(export_files))
    success:bool = True
    for to, state in merged_files.items():
        write_success = write_file(to=to, state=state, st=st)
        if not write_success: return False
    return success


# Cell nr. 207
@traced
def main(nbs_path:str=None, lib_path:str=None, recurse:bool=True, st:StackTrace=None) -> (bool, dict, dict):
    "Load, Parse, Merge, and Write .ipynb files to .py files."
    success:bool = True
    config = Config()
    proj_path:Path = config.config_file.parent
    nbs_path:Path  = config.nbs_path if (nbs_path is None) else Path(nbs_path).absolute().resolve()
    lib_path:Path  = config.lib_path if (lib_path is None) else Path(lib_path).absolute().resolve()
    
    # NOTE: LOAD
    notebooks = async_load_notebooks(path=nbs_path, recurse=recurse)
    
    # NOTE: PARSE
    parse_success, parsed_files = parse_all(notebooks, st=st)
    if not parse_success:
        st.report_error(Exception('At least one Error has occured during parsing. '\
                                  'No files on disk have been modified. Exiting.'))
        return False, parsed_files, None
    
    # NOTE: MERGE
    merge_success, merged_files = merge_all(parsed_files, st=st)
    if not merge_success:
        st.report_error(Exception('At least one Error occured during merging of files to be exported. '\
                                  'No files on disk have been modified. Exiting.'))
        return False, parsed_files, merged_files
    
    # NOTE: WRITE
    write_success = write_all(merged_files, st=st)
    if not write_success:
        st.report_error(Exception('At least one Error occured during writing the parsed and merged files to disk. '\
                                  'Some files might have been written to disk and others might not. Exiting.'))
        return False, parsed_files, merged_files
    
    if main_REPORT_RUN_STATISTICS:
        report_successful_export(parsed_files, merged_files)
    # NOTE: RETURN
    return success, parsed_files, merged_files


# Cell nr. 209
set_arg_parse_report_options(report_error=False)
set_main_report_options(report_optional_error=False,
                        report_command_found=False,
                        report_run_statistics=True)