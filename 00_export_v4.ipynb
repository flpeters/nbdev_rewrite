{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parsing [Module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +default_exp -to argument_parsing -use_scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "arg_parse_REPORT_ERROR  :bool = True\n",
    "arg_parse_REPORT_WARNING:bool = True\n",
    "arg_parse_RAISE_ERROR  :bool  = False\n",
    "arg_parse_RAISE_WARNING:bool  = False\n",
    "arg_parse_SILENT:bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def set_arg_parse_report_options(report_error:bool=True, report_warning:bool=True,\n",
    "                                 raise_error:bool=False, raise_warning:bool=False,\n",
    "                                 silent=False):\n",
    "    \"Set options for how the Argument Parsing Module will behave on encountering errors or warnings.\\n\"\\\n",
    "    \"Raise causes an exception to be raised, and it supersedes report.\\n\"\\\n",
    "    \"Report prints the information and then continues. If raise is set, then this setting is ignored.\"\\\n",
    "    \"Silent overwrites all other settings and causes all errors and warnings to be ignored.\"\\\n",
    "    \"The priority is thus: silent > raise > report\"\n",
    "    global arg_parse_REPORT_ERROR, arg_parse_REPORT_WARNING\n",
    "    global arg_parse_RAISE_ERROR, arg_parse_RAISE_WARNING\n",
    "    global arg_parse_SILENT\n",
    "    arg_parse_REPORT_ERROR, arg_parse_REPORT_WARNING = report_error, report_warning\n",
    "    arg_parse_RAISE_ERROR , arg_parse_RAISE_WARNING  = raise_error , raise_warning\n",
    "    arg_parse_SILENT = (silent or not (report_error and report_warning and raise_error and raise_warning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def report_error(err:Exception):\n",
    "    if   arg_parse_SILENT: pass\n",
    "    elif arg_parse_RAISE_ERROR : raise err\n",
    "    elif arg_parse_REPORT_ERROR: print(f'[{err.__class__.__name__}]: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def report_warning(warn:str):\n",
    "    if   arg_parse_SILENT: pass\n",
    "    elif arg_parse_RAISE_WARNING : raise Warning(warn)\n",
    "    elif arg_parse_REPORT_WARNING: print(f'[Warning]: {warn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a fancy way of advancing the cursor and checking for out of bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def get_next_argument(args:list, name:str, cursor:int, suppress_error:bool=False) -> (bool, int, str):\n",
    "    \"Gets the next argument from the list.\\nReturns success, the cursor, and the next argument\"\n",
    "    cursor_1 = cursor + 1\n",
    "    try: return True, cursor_1, args[cursor_1]\n",
    "    except IndexError:\n",
    "        if not suppress_error:\n",
    "            report_error(SyntaxError(f\"End of arguments reached. Missing a value for argument '{name}' at position {cursor_1}\"))\n",
    "        return False, cursor, ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, 'c')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'b', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SyntaxError]: End of arguments reached. Missing a value for argument 'c' at position 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, 2, '')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'c', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 2, '')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_argument(['a', 'b', 'c'], 'c', 2, suppress_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to Argument Parsing is just a string, so values have to be converted based on the information provided by the caller.  These function help to do that in a safe way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def to_integer(value:str) -> (bool, int, float):\n",
    "    \"Try converting a str to int.\\nReturn success, the value, and possibly a float remainder.\"\n",
    "    try:\n",
    "        f_value = float(value)\n",
    "        int_value = int(f_value)\n",
    "        remainder = f_value - int_value\n",
    "    except: return False, value, None\n",
    "    return True, int_value, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, -2, -0.10000000000000009), (False, 'nice', None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_integer('-2.1'), to_integer('nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def to_float(value:str) -> (bool, float):\n",
    "    \"Try converting a str to float.\\nReturn success, and the value.\"\n",
    "    # TODO: check if 'inf', 'nan', ...?\n",
    "    try   : return True , float(value)\n",
    "    except: return False, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, -0.001), (True, nan), (False, 'nice'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_float('-1e-3'), to_float('nan'), to_float('nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def to_bool(value:str) -> (bool, bool):\n",
    "    \"\"\"Try converting a str to bool.\n",
    "    'True' and 'False' are recognized, otherwise the value is cast to float, and then to bool.\n",
    "    Return success, and the value.\"\"\"\n",
    "    if value == 'True' : return True, True\n",
    "    if value == 'False': return True, False\n",
    "    try   : return True , bool(float(value))\n",
    "    except: return False, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((True, True), (True, False), (True, True), (True, False), (False, 'abc'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_bool('1'), to_bool('0'), to_bool('True'), to_bool('False'), to_bool('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def to_unbounded_array(args:list, cursor:int) -> (bool, int, list):\n",
    "    \"\"\"Consume any number of values until either reaching the end of args,\n",
    "    or until finding a value starting with '-', denoting the beginning of a new argument.\n",
    "    Return success, the cursor, and the list of values.\n",
    "    Currently this can't actually fail... don't use unbounded lists kids.\"\"\"\n",
    "    values = []\n",
    "    while True:\n",
    "        string_success, cursor, value = get_next_argument(args, None, cursor, suppress_error=True)\n",
    "        if string_success:\n",
    "            if value[0] != '-': values.append(value)\n",
    "            else: # value starting with '-' means it's the next command\n",
    "                cursor -= 1\n",
    "                break\n",
    "        else: break\n",
    "    return True, cursor, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, ['1', '2'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_unbounded_array(['-list', '1', '2', '-3'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def typify(type_or_value:object) -> (type, object):\n",
    "    \"\"\"Takes a type or a value.\n",
    "    Returns a tuple of the type (or type of the value) and value (or None)\"\"\"\n",
    "    return (type_or_value, None) if isinstance(type_or_value, type) else (type(type_or_value), type_or_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, (int, int, int, int))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typify((int, int)*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def parse_arguments(command:dict, comment:str) -> (bool, dict, dict):\n",
    "    \"Finds, casts, and returns values from command, in the given comment.\"    \n",
    "    members = command.keys()\n",
    "    result  = command.copy() # copy needed?\n",
    "    args    = comment.split()\n",
    "    # TODO: check that the type of all commands is supported ahead of time?\n",
    "    # TODO: handle quoted arguments?\n",
    "    \n",
    "    is_set = {member : False for member in members}\n",
    "    \n",
    "    state = {'args': args, 'name': '', 'cursor': 0,\n",
    "             'inside_array': False,}\n",
    "    \n",
    "    success = True\n",
    "    while state['cursor'] < len(args): # for arg in args:\n",
    "        arg = args[state['cursor']]\n",
    "        if arg[0] != '-':\n",
    "            report_error(SyntaxError(f\"Argument {state['cursor']} does not start with a '-'.\"))\n",
    "            return False, result, is_set\n",
    "        arg = arg[1:] # remove '-'\n",
    "        state['name'] = arg # TODO: check that len(arg) > 0?\n",
    "        \n",
    "        for key in members: # loop over keys of command (the things we're supposed to find)\n",
    "            if key != arg: continue    \n",
    "            if is_set[key]: # TODO: improve error msg. maybe: \"this is the second time this argument was given\"?\n",
    "                report_error(SyntaxError(f\"Argument {state['cursor']} ('{arg}') was given multiple times.\"))\n",
    "                success = False\n",
    "            else:\n",
    "                arg_type, arg_default = typify(command[key])\n",
    "                member_success = handle_one_argument(result, state, arg_type, arg_default)\n",
    "                if member_success: is_set[key] = True\n",
    "                else: success = False\n",
    "            break # once we have found the correct struct member, stop!\n",
    "        else: # TODO: improve this msg. maybe: \"is not part of the command\"?\n",
    "            report_error(SyntaxError(f\"Argument {state['cursor']} ('{arg}') is not valid.\"))\n",
    "            success = False\n",
    "        if not success: break # stop at first error\n",
    "        state['cursor'] += 1\n",
    "        \n",
    "    if success: success = check_is_set(result, is_set)\n",
    "    return success, result, is_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def handle_one_argument(result:dict, state:dict, arg_type:type, arg_default:object) -> bool:\n",
    "    \"Parse the input args based on arg_type, and set arg_name in result to that value.\"\n",
    "    # NOTE: state and result are modified from here and essentially treated as pointers\n",
    "    args     = state['args']\n",
    "    arg_name = state['name']\n",
    "    success  = True\n",
    "    if arg_type == str:\n",
    "        # get the next argument, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        # TODO: how to handle strings that start with a '-'\n",
    "        if string_success: result[arg_name] = value\n",
    "        else: success = False\n",
    "\n",
    "    elif arg_type == bool:\n",
    "        if state['inside_array']:\n",
    "            string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "            if string_success:\n",
    "                bool_success, value = to_bool(value)\n",
    "                if bool_success: result[arg_name] = value\n",
    "                else:\n",
    "                    report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                    was not convertable to bool. Please use 'True', 'False', '0', or '1'. (It was '{value}')\"))\n",
    "                    success = False\n",
    "            else: success = False\n",
    "        # special case where supplying the argument means True and not supplying it means use the default (False)\n",
    "        else: result[arg_name] = True\n",
    "\n",
    "    elif arg_type == int:\n",
    "        # get the next argument, cast to int, check for remainder, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        if not string_success: return False\n",
    "        int_success, value, remainder = to_integer(value)\n",
    "        if int_success:\n",
    "            result[arg_name] = value\n",
    "            if remainder:\n",
    "                report_warning(f\"Junk on the end of the value for int argument \\\n",
    "                               {state['cursor']-1} ('{arg_name}'): {remainder}\")\n",
    "        else:\n",
    "            report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                                    was not an int. (It was '{value}')\"))\n",
    "            success = False\n",
    "\n",
    "    elif arg_type == float:\n",
    "        # get the next argument, cast to float, advance cursor, set success\n",
    "        string_success, state['cursor'], value = get_next_argument(args, arg_name, state['cursor'])\n",
    "        if not string_success: return False\n",
    "        float_success, value = to_float(value)\n",
    "        if float_success: result[arg_name] = value\n",
    "        else:\n",
    "            report_error(ValueError(f\"Value of argument {state['cursor']-1} ('{arg_name}') \\\n",
    "                                    was not a float. (It was '{value}')\"))\n",
    "            success = False\n",
    "\n",
    "    elif arg_type == list or arg_type == tuple:\n",
    "        if arg_default is None: # unbounded list / tuple\n",
    "            if state['inside_array']:\n",
    "                report_error(SyntaxError(f\"Using an unbounded list or tuple inside an array is not supported.\"))\n",
    "                return False\n",
    "            \n",
    "            array_success, state['cursor'], value = to_unbounded_array(args, state['cursor'])\n",
    "            if array_success: # NOTE: currently this can't actually fail... don't use unbounded lists kids.\n",
    "                result[arg_name] = arg_type(value)\n",
    "            else: success = False\n",
    "            \n",
    "        else: # predefined list\n",
    "            s = {'args': args, 'name': 'v', 'cursor': state['cursor'],\n",
    "                 'inside_array': True}\n",
    "            value = []\n",
    "            for i, x in enumerate(arg_default):\n",
    "                t, d = typify(x)\n",
    "                n = f'{arg_name}[{i}]'\n",
    "                s['name'] = n\n",
    "                r = {n:d}\n",
    "                member_success = handle_one_argument(r, s, t, d)\n",
    "                if member_success: value.append(r[n])\n",
    "                else: # TODO: Improve error message\n",
    "                    # report_error(SyntaxError(f\"Array argument {state['cursor']} ('{arg_name}') was not passed correctly.\"))\n",
    "                    return False\n",
    "            state['cursor'] = s['cursor']\n",
    "            result[arg_name] = arg_type(value)\n",
    "\n",
    "    else:\n",
    "        report_error(TypeError(f\"Argument {state['cursor']} ('{arg_name}') is of unsupported type {arg_type}.\"))\n",
    "        success = False\n",
    "        \n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def check_is_set(result:dict, is_set:dict) -> bool:\n",
    "    \"Check if any required values (those without defaults), haven't been set yet\"\n",
    "    success = True\n",
    "    for member, v_is_set in is_set.items():\n",
    "        if v_is_set: continue\n",
    "        arg_type, arg_default = typify(result[member])\n",
    "        if arg_default is None: \n",
    "            if arg_type == bool: # NOTE: Special case, not setting a boolean means it's False.\n",
    "                result[member] = False # TODO: set is_set as well? what's the use-case here?\n",
    "                continue\n",
    "            report_error(ValueError(f\"Argument '{member}' has not been set, and no default value was given.\"))\n",
    "            success = False\n",
    "        elif (arg_type == list) or (arg_type == tuple): # this is a bounded list\n",
    "            name = [f'{member}[{i}]' for i in range(len(arg_default))]\n",
    "            r = {n:x for n, x in zip(name, arg_default)}\n",
    "            s = {n:False for n in r}\n",
    "            is_set_success = check_is_set(r, s)\n",
    "            if is_set_success: # re-set result\n",
    "                result[member] = arg_type([r[n] for n in name])\n",
    "                continue\n",
    "            else: success = False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This argument parser is largely inspired by these two videos by Jonathan Blow.\n",
    ">[Part 1](https://youtu.be/TwqXTf7VfZk)  \n",
    ">[Part 2](https://youtu.be/pgiVrhsGkKY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module besically provides only one function:  \n",
    "```python\n",
    "def parse_arguments(command:dict, comment:str) -> (bool, dict, dict)\n",
    "```  \n",
    "\n",
    "It takes one __\"command\" dictionary__, and a __\"comment\" string__.  \n",
    "\n",
    "#### __The command__\n",
    "\n",
    "is a simple key-value collection of expected flags, where a attribute name maps to either a type, or a default value, from which the type is infered.  \n",
    "```python\n",
    "command = {\n",
    "    'arg1':bool,\n",
    "    'arg2':str,\n",
    "    'arg3':32,\n",
    "    'arg4':3.14,\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The comment__\n",
    "is just a list of space-separated arguments, with words starting with a minus (`'-'`) denoting a keyword, and anything without a minus as the first character being a value to the previous keyword.  \n",
    "```python\n",
    "'-name bob -age 99 -celsius 30.5 -thirsty'\n",
    "```  \n",
    "is a valid string for the command  \n",
    "```python\n",
    "{\n",
    "    'name'   : str,\n",
    "    'weather': 'sunny',\n",
    "    'celsius': float,\n",
    "    'age'    : int,\n",
    "    'thirsty': bool,\n",
    "    'tired'  : bool\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The primitive types:__\n",
    "Currently the following primitive types are supported:  \n",
    "- `str`\n",
    "    - a `str` argument requires one value.\n",
    "    - e.g.: `-weather sunny`\n",
    "- `bool`\n",
    "    - a `bool` argument requires no values. setting the flag automatically sets the value to `True`.\n",
    "    - writing `bool` is the same as using the default value `False`.\n",
    "    - e.g.: `-is_wet`\n",
    "- `int`\n",
    "    - a `int` argument requires one value.\n",
    "    - the value will first be cast to `float`, and then to `int`, partly due to how python works, and also to check for a remainder in case the provided value was actually in a float format.\n",
    "    - e.g.: `-age 99`, `-negative -1`\n",
    "- `float`\n",
    "    - a `float` argument requires one value.\n",
    "    - the value has to be castable to `float`. what is and what isn't a float can be suprising, so you should check the [casting rules](https://stackoverflow.com/a/20929983/) beforehand.\n",
    "    - e.g.: `-pi 3.14`, `-negative -1.0`, `-weird nan`, `-large inf`, `-small -inf`\n",
    "  \n",
    "Any of these types can be declared either by just using the `type` directly, or by giving a default value of the specific `type`. All arguments that use the `type` directly have to be passed in the comment. If a default value is specified, or if the `type` is `bool`, the argument does not have to be passed in the comment, and instead the `result` will simply contain the default value. This changes with composite types (see below). If an argument was passed in the comment or not, can be seen by looking at the `is_set` return value (see below).\n",
    "\n",
    "  \n",
    "##### __The composite types__\n",
    "`list` and `tuple` (referred to as 'array' when it can be either one of them) are also supported, however due to pythons lack of strong typing, they have slightly different semantics.  \n",
    "\n",
    "Specifying only the type `list` or `tuple`, will result in an 'unbounded array' of that type, meaning that all values following the keyword will be added to the array, until either the end of arguments is reached, or a value starts with a minus (`'-'`), which denotes the start of the next argument. All values or the array will be of type `str`. This kind of argument should be used with caution, because, for instance, negative values will be treated as the start of a new argument.  \n",
    "```python\n",
    "{\n",
    "    'unbounded_list' : list,\n",
    "    'unbounded_tuple': tuple,\n",
    "}\n",
    "```  \n",
    "\n",
    "The other, better way to use arrays is to actually create an array containing the types, default values, and ordering you want the values to have. This can get arbitrarily complex, mixing and matching any supported primitive type you want. The only thing not allowed, is using an unbounded array (see above).  \n",
    "All values will be cast to the corresponding type using all the same semantics as of they were single values (see above). The only exception to that is the `bool` type, where the value has to be either `'True'`, `'False'`, or interpretable as a `float`, which will then be cast to a `bool`. This means that e.g. `'0.0'` will result in `False`, and `'123'` will result in `'True'` (careful, check the [casting rules](https://docs.python.org/3.3/library/stdtypes.html?highlight=frozenset#truth-value-testing) first).\n",
    "```python\n",
    "{\n",
    "    'arg1': [int]*5,\n",
    "    'arg2': (3.14, 'pi', bool),\n",
    "    'arg3': (bool, str, 123)*2,\n",
    "    'arg4': [[0]*3, [1]*3, [str]*3],\n",
    "    'arg5': [str, int, bool, True, [1, '2', 3, bool], (2.1, float)]\n",
    "}\n",
    "```\n",
    "\n",
    "#### __The return value__\n",
    "is a three-tuple of `(success, result, is_set)`.  \n",
    "- `success` is a `bool`, saying whether or not parsing was successful. If it is `False`, the other two arguments are not guaranteed to be valid. There will be an error message with details on what happened to help debugging.  \n",
    "- `result` is a `dict` with exactly the same keys as the input `command`, with the corresponding values set to whatever was extracted from the comment. In cases where `success` if `False`, this might only be partially filled out, so `success` should always be checked.\n",
    "- `is_set` is a `dict`, which also contains exactly the same keys as the input `command`, this time mapping to a `bool`. It is `True` if `comment` contains a value for the particular argument, and `False` otherwise. In cases where a default value is given in `command`, the same rule applies. Meaning that only if the default was overwritten by an argument in `comment` will the `is_set` value be `True`. This holds even for `bool`s, which default to `False` even if no explicit default was given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'test': True,\n",
       "  'sunny': True,\n",
       "  'toast': 'jelly',\n",
       "  'shots': 25,\n",
       "  'scale': 69105.1234,\n",
       "  'scoops': ['a', 1, False, [5, 6, 7, False], (3.0, 2.1)],\n",
       "  'valid': (1, 1.23, False, 'hi', [1, 2]),\n",
       "  'nah': 'boi',\n",
       "  'sweet': False,\n",
       "  'nr': 21,\n",
       "  'list': ['2']},\n",
       " {'test': True,\n",
       "  'sunny': True,\n",
       "  'toast': True,\n",
       "  'shots': True,\n",
       "  'scale': True,\n",
       "  'scoops': True,\n",
       "  'valid': False,\n",
       "  'nah': False,\n",
       "  'sweet': False,\n",
       "  'nr': True,\n",
       "  'list': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = {\n",
    "    'test'  : bool,\n",
    "    'sunny' : False,\n",
    "    'toast' : str,\n",
    "    'shots' : int,\n",
    "    'scale' : float,\n",
    "    'scoops': [str, int, bool, [1, 2, 3, bool], (float, float)],\n",
    "    # 'valid' : (bool, bool),\n",
    "    'valid' : (1, 1.23, bool, 'hi', [1, 2]),\n",
    "    'nah'   : 'boi',\n",
    "    'sweet' : bool,\n",
    "    'nr'    : int,\n",
    "    'list'  : list\n",
    "}\n",
    "\n",
    "comment = '-sunny -toast jelly -shots 25 -scale 69105.1234 -test -list 2 -scoops a 1 0 5 6 7 False 3.0 2.1 -nr 21'\n",
    "# comment = '-sunny -toast jelly -shots 25 -scale 69105.1234 -test -nr 1'\n",
    "parse_arguments(command, comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit parse_arguments(command, comment)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit parse_arguments(command, comment)\n",
    ">>> 44 µs ± 98.9 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main [Module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +default_exp -to main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS_FILE = '00_export_v4.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "from collections import namedtuple, defaultdict\n",
    "import os\n",
    "import re\n",
    "from nbdev_rewrite.imports import *\n",
    "\n",
    "from inspect import signature, currentframe\n",
    "\n",
    "import functools\n",
    "from types import MethodType,FunctionType\n",
    "\n",
    "import ast\n",
    "from ast import iter_fields, AST\n",
    "import _ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# Only import if executing as a python file, because then argument_parsing is in a different file.\n",
    "if (__name__ != '__main__') or ('parse_arguments' not in globals()):\n",
    "    from nbdev_rewrite.argument_parsing import *\n",
    "    assert 'parse_arguments' in globals(), \"Missing the 'parse_arguments' function after import.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _all_ = ['parse_arguments', 'set_arg_parse_report_options']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a class for passing along contextual information during execution.  \n",
    "The class is a linked list, which can be extended each time a new function is called.  \n",
    "Everytime a function is called, create a new StackTrace instance, and pass the current instance to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "main_REPORT_OPTIONAL_ERROR:bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def set_main_report_options(report_optional_error:bool=False):\n",
    "    \"Set options for how the Main Module will behave on encountering errors or warnings.\\n\"\\\n",
    "    \"report_optional_error prints the information and then continues.\"\n",
    "    global main_REPORT_OPTIONAL_ERROR\n",
    "    main_REPORT_OPTIONAL_ERROR = report_optional_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "class StackTrace: pass # only for :StackTrace annotations to work\n",
    "class StackTrace:\n",
    "    up:StackTrace = None\n",
    "    namespace:str = None\n",
    "    lineno   :int = None\n",
    "    extern:bool = False\n",
    "    file:str    = None\n",
    "    cellno:int  = None\n",
    "    excerpt:str = None\n",
    "    span:(int, int) = None\n",
    "        \n",
    "    def __init__(self, namespace:object, up:StackTrace=None):\n",
    "        self.namespace = namespace.__qualname__ if namespace else None\n",
    "        self.up = up\n",
    "        self.lineno = currentframe().f_back.f_lineno\n",
    "        \n",
    "    @classmethod\n",
    "    def ext(cls, file:str, cellno:int=None, lineno:int=None, excerpt:str=None, up:StackTrace=None):\n",
    "        st = cls(None, up=up)\n",
    "        st.extern = True\n",
    "        st.file = file\n",
    "        st.cellno = cellno\n",
    "        st.lineno = lineno\n",
    "        st.excerpt = excerpt\n",
    "        return st\n",
    "        \n",
    "    def __repr__(self):\n",
    "        ln = self.lineno\n",
    "        if self.extern:\n",
    "            s = f\"{'' if self.up is None else self.up.__repr__()}\"\\\n",
    "                f\"\\n<{self.file}>, cell {self.cellno}, line {ln}\\n\"\n",
    "            if self.excerpt:\n",
    "                x = f\"--->{' ' if ((ln is None) or (0 <= ln <= 9)) else ''}{ln} \"\n",
    "                s += f\"{x}{self.excerpt}\\n\"\\\n",
    "                     f\"{(' ' * (len(x) + self.span[0]) + '^' * self.span[1]) if self.span else ''}\"\n",
    "            return s\n",
    "        else: # the default\n",
    "            return f\"{'' if self.up is None else self.up.__repr__()}\"\\\n",
    "                   f\"<{__name__}>, line {ln} in <{self.namespace}>\\n\"\n",
    "    \n",
    "    def report_error(self, err:Exception, lineno=None, excerpt=None, span:(int, int)=None):\n",
    "        if lineno: self.lineno = lineno\n",
    "        if excerpt: self.excerpt = excerpt\n",
    "        self.span = span\n",
    "        err_type = err.__class__.__name__\n",
    "        s = f\"{'-'*75}\\n\"\\\n",
    "            f\"{err_type}{' '*(41-len(err_type))}Stacktrace (most recent call last)\\n\"\\\n",
    "            f\"{self.__repr__()}\\n\"\\\n",
    "            f\"[{err_type}]: {err}\"\n",
    "        print(s)\n",
    "    \n",
    "    def report_optional_error(self, err:Exception, lineno=None, excerpt=None, span:(int, int)=None):\n",
    "        if main_REPORT_OPTIONAL_ERROR:\n",
    "            self.report_error(err=err, lineno=lineno, span=span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _part(st):\n",
    "    success = True\n",
    "    st.report_error(Exception('Failed doing the thing'))\n",
    "    success = False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _start():\n",
    "    st = StackTrace(_start)\n",
    "    success = True\n",
    "    success_part = _part(StackTrace(_part, up=st))\n",
    "    if not success_part:\n",
    "        success = False\n",
    "        return 0\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Exception                                Stacktrace (most recent call last)\n",
      "<__main__>, line 2 in <_start>\n",
      "<__main__>, line 4 in <_part>\n",
      "\n",
      "[Exception]: Failed doing the thing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SyntaxError                              Stacktrace (most recent call last)\n",
      "<__main__>, line 1 in <_start>\n",
      "<__main__>, line 2 in <_part>\n",
      "\n",
      "<file.py>, cell 18, line 45\n",
      "--->45 # another weird comment\n",
      "         ^^^^^^^\n",
      "[SyntaxError]: Failed to parse\n"
     ]
    }
   ],
   "source": [
    "_st=StackTrace(namespace=_start)\n",
    "_st=StackTrace(_part, up=_st)\n",
    "_st=StackTrace.ext(file='file.py', cellno=5, lineno=45, excerpt='# weird comment', up=_st)\n",
    "_st.cellno=18\n",
    "_st.excerpt = '# another weird comment'\n",
    "_st.report_error(SyntaxError('Failed to parse'), lineno=None, span=(2, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference of Python Tracebacks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> (lambda: 1/0)()\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \"<stdin>\", line 1, in <lambda>\n",
    "ZeroDivisionError: division by zero"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(lambda: 1/0)()\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "ZeroDivisionError                         Traceback (most recent call last)\n",
    "<ipython-input-200-e700a98730a6> in <module>\n",
    "----> 1 (lambda: 1/0)()\n",
    "\n",
    "<ipython-input-200-e700a98730a6> in <lambda>()\n",
    "----> 1 (lambda: 1/0)()\n",
    "\n",
    "ZeroDivisionError: division by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Parse Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding comments in source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "# TODO: Only look for 0 indent comments?\n",
    "def iter_comments(src:str, pure_comments_only:bool=True, line_limit:int=None) -> (str, (int, int)):\n",
    "    \"Detect all comments in a piece of code, excluding those that are a part of a string.\"\n",
    "    in_lstr = in_sstr = False\n",
    "    count, quote = 1, ''\n",
    "    for i, line in enumerate(src.splitlines()[:line_limit]):\n",
    "        is_pure, escape, prev_c = True, False, '\\n'\n",
    "        for j, c in enumerate(line):\n",
    "            # we can't break as soon as not is_pure, because we have to detect if a multiline string beginns\n",
    "            if is_pure and (not (c.isspace() or c == '#')): is_pure = False\n",
    "            if (in_sstr or in_lstr):\n",
    "                # assert in_sstr ^ in_lstr # XOR\n",
    "                if escape: count = 0\n",
    "                else:\n",
    "                    if (c == quote):\n",
    "                        count = ((count + 1) if (c == prev_c) else 1)\n",
    "                        if in_sstr: in_sstr = False\n",
    "                        elif (in_lstr and (count == 3)): count, in_lstr = 0, False\n",
    "                escape = False if escape else (c == '\\\\')\n",
    "            else:                    \n",
    "                if (c == '#'):\n",
    "                    if (pure_comments_only and is_pure): yield (line, (i, j))\n",
    "                    elif (not pure_comments_only):       yield (line[j:], (i, j))\n",
    "                    break\n",
    "                elif c == \"'\" or c == '\"':\n",
    "                    count = ((count + 1) if (c == prev_c) else 1)\n",
    "                    if count == 1: in_sstr = True\n",
    "                    elif count == 3: count, in_lstr = 0, True\n",
    "                    else: assert False, 'If this code path happens, then the code keeping track of quotes is broken.'\n",
    "                    quote = c\n",
    "            prev_c = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('# this is a zero indented comment', (0, 0))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iter_comments('# this is a zero indented comment'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This regex is used to remove whitespace and the '#' of python comments.  \n",
    "The content of the comment will be added to a group, which can be extracted afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_comment = re.compile(r\"\"\"\n",
    "        ^              # start of the string\n",
    "        \\s?            # 0 or 1 whitespace\n",
    "        \\#+\\s?         # 1 or more literal \"#\", then 0 or 1 whitespace\n",
    "        (.*)           # group of arbitrary symbols (except new line)\n",
    "        $              # end of the string\n",
    "        \"\"\",re.IGNORECASE | re.VERBOSE) # re.MULTILINE is not passed, since this regex is used on each line separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='# hi'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_comment.search('# hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_match_comment.search('a\\n# hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('# hi',)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_comment.search('# # hi').groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specifies what a valid nbdev comment has to look like, and filters out everything whose syntax does not fit with any of the registered commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def parse_comment(all_commands:dict, comment:str, st:StackTrace) -> (bool, str, dict, dict):\n",
    "    \"Finds command names and arguments in comments and parses them with parse_arguments()\"\n",
    "    res = re_match_comment.search(comment)\n",
    "    if not res:\n",
    "        st.report_optional_error(SyntaxError('Not a valid comment syntax.'))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    all_args = res.groups()[0].split()\n",
    "    if len(all_args) == 0:\n",
    "        st.report_optional_error(SyntaxError(f\"Need at least one argument in comment. Reveived: '{comment}'\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    cmd, *args = all_args\n",
    "    if cmd[0] != '+':\n",
    "        st.report_optional_error(SyntaxError(\"The first argument (the command to execute) does not start with a '+'.\"\\\n",
    "                                            f\"It was: '{cmd}'\"), span=(1, 3))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    cmd = cmd[1:] # remove the '+'\n",
    "    if cmd not in all_commands:\n",
    "        st.report_optional_error(KeyError(f\"'{cmd}' is not a recognized command. See 'all_commands'.\"))\n",
    "        return False, None, None, None\n",
    "    \n",
    "    success, result, is_set = parse_arguments(all_commands[cmd], ' '.join(args))\n",
    "    if not success: return False, None, None, None\n",
    "    \n",
    "    return True, cmd, result, is_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_default_exp = {'scope': 'file' , 'to': str}\n",
    "kw_export      = {'internal': bool, 'to': ''}\n",
    "\n",
    "all_commands   = {'default_exp': kw_default_exp, 'export': kw_export}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, {'internal': True, 'to': 'file.py'}, {'internal': True, 'to': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_arguments(all_commands['export'], '-internal -to file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 'export',\n",
       " {'internal': True, 'to': 'file.py'},\n",
       " {'internal': True, 'to': True})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_comment(all_commands, '# +export -internal -to file.py', st=StackTrace(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find function, class and variable Names in Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/3/library/ast.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is using pythons builtin `ast` module to parse source code into an abstract syntax tree, from which the set of all variable-, function-, and classnames is extracted.  \n",
    "All names found, that are not private (prefixed with a single underscore), are added to a set to get rid of duplicate names.  \n",
    "It also seperately parses the nbdev-reserved special variable name `_all_` and adds all assignments to it to the set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some special cases (like fastai specific python extensions) are also handled here, although this will probably change in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debug help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "class Context:\n",
    "    def __init__(self, cell_nr=None, export_nr=None):\n",
    "        self.cell_nr   = cell_nr\n",
    "        self.export_nr = export_nr\n",
    "    def __repr__(self):\n",
    "        return f'cell_nr: {self.cell_nr}, export_nr: {self.export_nr}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def lineno(node):\n",
    "    \"Format a string containing location information on ast nodes. Used for Debugging only.\"\n",
    "    if hasattr(node, 'lineno') and hasattr(node, 'col_offset'):\n",
    "        return f'line_nr: {node.lineno} col_offset: {node.col_offset}'\n",
    "    else: return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def info(context, node):\n",
    "    \"Format a string with available information on a ast node. Used for Debugging only.\"\n",
    "    return f'\\nLocation: {context} | {lineno(node)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def unwrap_attr(node:_ast.Attribute) -> str:\n",
    "    \"Joins a sequance of Attribute accesses together in a single string. e.g. numpy.array\"\n",
    "    if isinstance(node.value, _ast.Attribute): return '.'.join((unwrap_attr(node.value), node.attr))\n",
    "    else: return '.'.join((node.value.id, node.attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def update_from_all_(node, names, c):\n",
    "    \"inplace, recursive update of set of names, by parsing the right side of a _all_ variable\"\n",
    "    if   isinstance(node, _ast.Str): names.add(node.s)\n",
    "    elif isinstance(node, _ast.Name): names.add(node.id)\n",
    "    elif isinstance(node, _ast.Attribute): names.add(unwrap_attr(node))\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "        for x in node.elts: update_from_all_(x, names, c)\n",
    "    elif isinstance(node, _ast.Subscript) :\n",
    "        raise SyntaxError(f'Subscript expression not allowed in _all_. {info(c, node)}')\n",
    "    elif isinstance(node, _ast.Starred):\n",
    "        raise SyntaxError(f'Starred expression *{node.value.id} not allowed in _all_. {info(c, node)}')\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type. {info(c, node)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def unwrap_assign(node, names, c):\n",
    "    \"inplace, recursive update of list of names\"\n",
    "    if   isinstance(node, _ast.Name)      : names.append(node.id)\n",
    "    elif isinstance(node, _ast.Starred)   : names.append(node.value.id)\n",
    "    elif isinstance(node, _ast.Attribute) : names.append(unwrap_attr(node))\n",
    "    elif isinstance(node, _ast.Subscript) : pass # e.g. a[0] = 1\n",
    "    elif isinstance(node, (_ast.List, _ast.Tuple)):\n",
    "        for x in node.elts: unwrap_assign(x, names, c)\n",
    "    elif isinstance(node, list):\n",
    "        for x in node: unwrap_assign(x, names, c)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {node} to name, unknown type. {info(c, node)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def not_private(name): return not (name.startswith('_') and (not name.startswith('__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def add_names_A(node, names, c):\n",
    "    \"Handle Assignments to variables\"\n",
    "    tmp_names = list()\n",
    "    if   isinstance(node, _ast.Assign):\n",
    "        unwrap_assign(node.targets, tmp_names, c)\n",
    "    elif isinstance(node, _ast.AnnAssign):\n",
    "        unwrap_assign(node.target, tmp_names, c)\n",
    "    else: assert False, 'add_names_A only accepts _ast.Assign or _ast.AnnAssign'\n",
    "    for name in tmp_names:\n",
    "        if not_private(name): names.add(name)\n",
    "        # NOTE: special cases below can only use private variable names\n",
    "        elif name == '_all_': # NOTE: _all_ is a keyword reserved by nbdev.\n",
    "            if len(tmp_names) != 1:\n",
    "                raise SyntaxError(f'Reserved keyword \"_all_\" can only be used in simple assignments. {info(c, node)}')\n",
    "            update_from_all_(node.value, names, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def decorators(node):\n",
    "    yield from [(d.id if isinstance(d, _ast.Name) else d.func.id) for d in node.decorator_list]\n",
    "\n",
    "def fastai_patch(cls, node, names, c):\n",
    "    if   isinstance(cls, _ast.Name):\n",
    "        if not_private(cls.id): names.add(f'{cls.id}.{node.name}')\n",
    "    elif isinstance(cls, (_ast.List, _ast.Tuple, _ast.Set)):\n",
    "            for x in cls.elts: fastai_patch(x, node, names, c)\n",
    "    else: raise SyntaxError(f'Can\\'t resolve {cls} to @patch annotation, unknown type. {info(c, node)}')\n",
    "\n",
    "# ignoring `@typedispatch` might not even be neccesarry,\n",
    "# since all names are added to a single set before being exported.\n",
    "def add_names_FC(node, names, c, fastai_decorators=True):\n",
    "    \"Handle Function and Class Definitions\"\n",
    "    if fastai_decorators and ('patch' in decorators(node)):\n",
    "        if not (len(node.args.args) >= 1): raise SyntaxError(f'fastai\\'s @patch decorator requires at least one parameter. {info(c, node)}')\n",
    "        cls = node.args.args[0].annotation\n",
    "        if cls is None: raise SyntaxError(f'fastai\\'s @patch decorator requires a type annotation on the first parameter. {info(c, node)}')\n",
    "        fastai_patch(cls, node, names, c)\n",
    "    elif fastai_decorators and ('typedispatch' in decorators(node)): return # ignore @typedispatch\n",
    "    elif not_private(node.name): names.add(node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def find_names(code:str, context:Context=None) -> list:\n",
    "    \"Find all function, class and variable names in the given source code.\"\n",
    "    tree = ast.parse(code)\n",
    "    names = set()\n",
    "    for node in tree.body:\n",
    "        if   isinstance(node, (_ast.Assign     , _ast.AnnAssign)): add_names_A (node, names, context)\n",
    "        elif isinstance(node, (_ast.FunctionDef, _ast.ClassDef )): add_names_FC(node, names, context)\n",
    "        else: pass\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_names('x = 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relativify import statements in output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is responsible for transforming import statements.  \n",
    "It only affects 'from' imports of the library the project belongs to.  \n",
    "So if the project library is called \"my_library\", then `from my_library import *` might be transformed into `from . import *` in the output file.  \n",
    "The relative path is generated in such a way that it will be a valid import from the file the code is exported to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"normal\" `import module` statement does not allow relative module names, so it can not be translated from an absolute version in the notebook to a relative one in the output file.  \n",
    "Similarly, using a relative module name in the notebook in a `from .module import ...` statement does not work due to the interactive nature of the notebook environment.  \n",
    "Those two cases are not supported for automatic translation since they would require a very hacky solution, which can not be guaranteed to be always correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def make_import_relative(p_from:Path, m_to:str)->str:\n",
    "    \"Convert a module `m_to` to a name relative to `p_from`.\"\n",
    "    mods = m_to.split('.')\n",
    "    splits = str(p_from).split(os.path.sep)\n",
    "    if mods[0] not in splits: return m_to\n",
    "    i=len(splits)-1\n",
    "    while i>0 and splits[i] != mods[0]: i-=1\n",
    "    splits = splits[i:]\n",
    "    while len(mods)>0 and splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]\n",
    "    return '.' * len(splits) + '.'.join(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2, n3, n4, n5 = 'nbdev.core', 'nbdev.core', 'nbdev.vision.transform', 'nbdev.notebook.core', 'nbdev.vision'\n",
    "p1, p2, p3 = Path('./nbdev/data.py').absolute(), Path('./nbdev/vision/data.py'), Path('./nbdev/vision/data.py')\n",
    "p4, p5     = Path('./nbdev/data/external.py'), Path('./nbdev/vision/learner.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(make_import_relative(p1, n1),'.core')\n",
    "test_eq(make_import_relative(p2, n2),'..core')\n",
    "test_eq(make_import_relative(p3, n3),'.transform')\n",
    "test_eq(make_import_relative(p4, n4),'..notebook.core')\n",
    "test_eq(make_import_relative(p5, n5),'.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit\n",
    ">>> 8.49 µs ± 23.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "letter = 'a-zA-Z'\n",
    "identifier = f'[{letter}_][{letter}0-9_]*'\n",
    "re_import = ReLibName(fr\"\"\"\n",
    "    ^                             # start of the string / line\n",
    "    (\\ *)                         # any amount of whitespace (indenting)\n",
    "    from(\\ +)                     # 'from', followed by at least one whitespace\n",
    "    (LIB_NAME(?:\\.{identifier})*) # Name of the library, possibly followed by dot separated submodules\n",
    "    \\ +import(.+)                 # whitespace, then 'import', followed by arbitrary symbols except new line\n",
    "    $                             # end of the string / line\n",
    "    \"\"\", re.VERBOSE | re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def relativify_imports(origin:Path, code:str)->str:\n",
    "    \"Transform an absolute 'from LIB_NAME import module' into a relative import of 'module' wrt the library.\"\n",
    "    def repl(match):\n",
    "        sp1,sp2,module,names = match.groups()\n",
    "        return f'{sp1}from{sp2}{make_import_relative(origin, m_to=module)} import{names}'\n",
    "    return re_import.re.sub(repl,code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod\n",
      "import nbdev_rewrite.vision\n",
      "# Nothing to see here\n",
      "from   ..abc import array as arr, linalg.solve, module as mod\n",
      "def function():\n",
      "    \"from nbdev_rewrite import *\"\n",
      "    pass\n",
      "from     .. import (abs, b as c, h,) # sure\n",
      "from .. import *\n",
      "from ..core import* # ok\n",
      "    from . import *\n",
      "from .. import(\n",
      "    abs\n",
      "                  as a\n",
      "    , # this is weird, but legal\n",
      "                       absolute \n",
      "    as \n",
      "                  f\n",
      "                  )\n"
     ]
    }
   ],
   "source": [
    "print(relativify_imports(Path('./nbdev_rewrite/submodule/data.py'),\"\"\"\n",
    "import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod\n",
    "import nbdev_rewrite.vision\n",
    "# Nothing to see here\n",
    "from   nbdev_rewrite.abc   import array as arr, linalg.solve, module as mod\n",
    "def function():\n",
    "    \"from nbdev_rewrite import *\"\n",
    "    pass\n",
    "from     nbdev_rewrite import (abs, b as c, h,) # sure\n",
    "from nbdev_rewrite import *\n",
    "from nbdev_rewrite.core import* # ok\n",
    "    from . import *\n",
    "from nbdev_rewrite  import(\n",
    "    abs\n",
    "                  as a\n",
    "    , # this is weird, but legal\n",
    "                       absolute \n",
    "    as \n",
    "                  f\n",
    "                  )\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O and Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def init_config(lib_name='nbdev_rewrite', user='flpeters', nbs_path='.'):\n",
    "    \"create a config file, if it doesn't already exist\"\n",
    "    if not Config().config_file.exists(): create_config(lib_name=lib_name, user=user, nbs_path=nbs_path)\n",
    "init_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def init_lib():\n",
    "    \"initialize the module folder, if it's not initialized already\"\n",
    "    C = Config()\n",
    "    if (not C.lib_path.exists()) or (not (C.lib_path/'__init__.py').exists()):\n",
    "        C.lib_path.mkdir(parents=True, exist_ok=True)\n",
    "        with (C.lib_path/'__init__.py').open('w') as f:\n",
    "            f.write(f'__version__ = \"{C.version}\"\\n')\n",
    "    else: pass # module *should* already exists\n",
    "init_lib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/00_export_v4.ipynb'),\n",
       " WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/99_index.ipynb')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +export\n",
    "_reserved_dirs = (Config().lib_path, Config().nbs_path, Config().doc_path)\n",
    "def crawl_directory(path:Path, recurse:bool=True) -> list:\n",
    "    \"finds a list of ipynb files to convert\"\n",
    "    # TODO: Handle symlinks?\n",
    "    if isinstance(path, (list, tuple)):\n",
    "        for p in path: yield from crawl_directory(p, recurse)\n",
    "    elif path.is_file(): yield path\n",
    "    else:\n",
    "        for p in path.iterdir():\n",
    "            f = p.name\n",
    "            if f.startswith('.') or f.startswith('_'): continue\n",
    "            if p.is_file():\n",
    "                if f.endswith('.ipynb'): yield p\n",
    "                else: continue\n",
    "            elif p.is_dir() and recurse:\n",
    "                if p in _reserved_dirs: continue\n",
    "                else: yield from crawl_directory(p, recurse)\n",
    "            else: continue\n",
    "list(crawl_directory(Config().nbs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def read_nb(fname:Path) -> dict:\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return dict(nbformat.reads(f.read(), as_version=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_nb(THIS_FILE)['cells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@prefetch(max_prefetch=4)\n",
    "def file_generator(path:Path=Config().nbs_path) -> (Path, dict):\n",
    "    for file_path in crawl_directory(path): yield (file_path, read_nb(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [len(x[1]['cells']) for x in file_generator()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[len(x[1]['cells']) for x in file_generator()]\n",
    "\n",
    ">>> [90, 2, 100, 174, 31, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Path Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identify modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use pattern matching to identify valid module names."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://docs.python.org/2.0/ref/identifiers.html\n",
    "identifier:     (letter|\"_\") (letter|digit|\"_\")*\n",
    "letter:         lowercase | uppercase\n",
    "lowercase:      \"a\"...\"z\"\n",
    "uppercase:      \"A\"...\"Z\"\n",
    "digit:          \"0\"...\"9\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://docs.python.org/2.0/ref/import.html\n",
    "import_stmt:    \"import\" module [\"as\" name] (\",\" module [\"as\" name] )* \n",
    "              | \"from\" module \"import\" identifier [\"as\" name]\n",
    "                (\",\" identifier [\"as\" name] )*\n",
    "              | \"from\" module \"import\" \"*\" \n",
    "module:         (identifier \".\")* identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "letter = 'a-zA-Z'\n",
    "identifier = f'[{letter}_][{letter}0-9_]*'\n",
    "module = fr'(?:{identifier}\\.)*{identifier}'\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_module = re.compile(fr\"\"\"\n",
    "        ^              # start of the string\n",
    "        {module}       # definition for matching a module \n",
    "        $              # end of the string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 16), match='module.main.test'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_match_module.search('module.main.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def module_to_path(m:str)->Path:\n",
    "    \"Turn a module name into a path such that the exported file can be imported from the library \"\\\n",
    "    \"using the same expression.\"\n",
    "    if re_match_module.search(m) is not None:\n",
    "        if m.endswith('.py'):\n",
    "            raise ValueError(f\"The module name '{m}' is not valid, because ending on '.py' \"\\\n",
    "                             f\"would produce a file called 'py.py' in the folder '{m.split('.')[-2]}', \"\\\n",
    "                              \"which is most likely not what was intended.\\nTo name a file 'py.py', use the \"\\\n",
    "                              \"'-to_path' argument instead of '-to'.\")\n",
    "        return Config().path_to('lib')/f\"{os.path.sep.join(m.split('.'))}.py\"\n",
    "    else: raise ValueError(f\"'{m}' is not a valid module name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/module/sub/file.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_to_path('module.sub.file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/main/main.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_to_path('main')\n",
    "module_to_path('main.main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions might come in handy late on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??importlib.util._resolve_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.util.resolve_name??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'module.export'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.util.resolve_name('..export', 'module.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identify paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the user explicitly passes a path, then this code is tasked with checking it for correctness and converting it to an absolute path from the perspective of the library path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def commonpath(*paths)->Path:\n",
    "    \"Given a sequence of path names, returns the longest common sub-path.\"\n",
    "    return Path(os.path.commonpath(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/abc/fgh')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonpath(Path('c:/abc/fgh/a'), Path('c:/abc/fgh/b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "def in_directory(p:Path, d:Path)->bool:\n",
    "    \"Tests if `p` is pointing to something in the directory `d`.\\n\"\\\n",
    "    \"Expects both `p` and `d` to be fully resolved and absolute paths.\"\n",
    "    return p.as_posix().startswith(d.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_directory_slow_1(p, d)->bool:\n",
    "    try: p.relative_to(d)\n",
    "    except: return False\n",
    "    else: return True\n",
    "def in_directory_slow_2(p, d)->bool:\n",
    "    return len(commonpath(p, d).parts) >= len(d.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_directory(p=Path('C:/abc/fgh/abc.txt'), d=Path('C:/abc/fgh/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def make_valid_path(s:str)->Path:\n",
    "    \"Turn a export path argument into a valid path, resolving relative paths and checking for mistakes.\"\n",
    "    p, lib = Path(s), Config().path_to('lib')\n",
    "    is_abs = p.is_absolute()\n",
    "    p = (p if is_abs else (lib/p)).absolute().resolve()\n",
    "    if (not is_abs) and (not in_directory(p, lib)):\n",
    "        raise ValueError(\"Relative export path beyond top level directory of library is not allowed by default. \"\\\n",
    "                        f\"Use an absolute path, or set <NOT IMPLEMENTED YET> flag on the command. ('{s}')\")\n",
    "    if not p.suffix: raise ValueError(f\"The path '{s}' is missing a file type suffix like '.py'.\")\n",
    "    if p.suffix == '.py': return p\n",
    "    else: raise ValueError(f\"'{p.suffix}' is not a valid file ending. ('{s}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/hi.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path(Path('./module/../hi.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/main.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_valid_path('main.py')\n",
    "make_valid_path('./main.py')\n",
    "make_valid_path('../../nbdev_rewrite/nbdev_rewrite/main.py')\n",
    "make_valid_path('d:/main.py')\n",
    "make_valid_path('main/main.py')\n",
    "make_valid_path('../nbdev_rewrite/main.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: add support for a scoped #default_exp. Support exporting cells under a specific heading to a seperate file.\n",
    "setting #default_exp on a per-heading / per-scope level, not on a once per file level."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IDEA: # file-documentation tag, for writing a doc string for an entire file, or for an entire module"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "global settings:\n",
    "- seperation amount (vertical whitespace) between cells\n",
    "- how to look for comments\n",
    "- command syntax\n",
    "- \n",
    "\n",
    "all cell data:  \n",
    "- meta cells\n",
    "- default export target\n",
    "- file name\n",
    "\n",
    "per cell data:  \n",
    "- source code\n",
    "- variable, function and class names\n",
    "- export yes/no\n",
    "- internal (export names) yes/no\n",
    "- cell number / order\n",
    "\n",
    "Things that need to be aggregated before return:\n",
    "- union of all names\n",
    "- ordered list of source code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "default_export -> default file | None\n",
    "\n",
    "cell X export -to cell_X -> cell_X file\n",
    "cell Y export -to cell_X -> cell_X file\n",
    "cell Z export -> default file\n",
    "\n",
    "scope A default_export -> scope_A file\n",
    "    cell A_Y export -to cell_X -> cell_X file\n",
    "    cell A_Z export -> scope_A file\n",
    "\n",
    "scope B default_export -> scope_B file\n",
    "    cell B_Z export -> scope_B file\n",
    "    \n",
    "cell K export -> default file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@register_command` stores argument information about the registered function in the global variables `all_commands`, and a reference to the function in `cmd2func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def register_command(cmd, args, active=True):\n",
    "    \"Store mapping from command name to args, and command name to reference to the decorated function in globals.\"\n",
    "    if not active: return lambda f: f\n",
    "    all_commands[cmd] = args\n",
    "    def _reg(f):\n",
    "        cmd2func[cmd] = f\n",
    "        return f\n",
    "    return _reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "all_commands = {}\n",
    "cmd2func     = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@register_command(cmd='default_exp', # allow custom scope name that can be referenced in export?\n",
    "                  args={'to': '', 'to_path': '', 'use_scope': False})\n",
    "def kw_default_exp(file_info, cell_info, result, is_set):\n",
    "    \"Set the default file that cells of this notebook will be exported to.\"\n",
    "    if not (is_set['to'] ^ is_set['to_path']): # NOTE: XOR\n",
    "        raise ValueError(\"The `default_exp` command expects exactly one of the arguments \"\\\n",
    "                         f\"'-to' or '-to_path' to be set, but recieved was: {result}\")\n",
    "    # NOTE: use this cells indentation level, or the default tuple([0]) as key to identify scope\n",
    "    scope:tuple     = cell_info['scope'] if result['use_scope'] else tuple([0])\n",
    "    old_target:Path = file_info['export_scopes'].get(scope, None)\n",
    "    new_target:Path = (module_to_path(result['to'])\n",
    "                       if is_set['to'] else\n",
    "                       make_valid_path(result['to_path']))\n",
    "    if old_target is not None:\n",
    "        raise ValueError(f\"Overwriting an existing export target is not allowed. (cell nr. {cell_info['cell_nr']})\"\\\n",
    "                        f\"\\n\\t\\t->(was: '{old_target}', new: '{new_target}')\")\n",
    "    file_info['export_scopes'][scope] = new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "@register_command(cmd='export',\n",
    "                  args={'internal': False, 'to': '', 'to_path':'', 'ignore_scope':False,\n",
    "                        'cell_nr': 0, 'prepend': False, 'append': False})\n",
    "def kw_export(file_info, cell_info, result, is_set):\n",
    "    \"This cell will be exported from the notebook to a .py file.\"\n",
    "    if (is_set['to'] and is_set['to_path']):\n",
    "        raise ValueError(\"The `export` command does not accept the '-to' and '-to_path' argument at the same time. \"\\\n",
    "                         f\"They are mutually exclusive. Recieved: {result}\")\n",
    "    cell_info['export_to_py'] = True # Using this command implicitly means to export this cell\n",
    "    if is_set['cell_nr']: cell_info['cell_nr'] = result['cell_nr'] # overwrite the cell_nr of this cell\n",
    "    is_internal = cell_info['is_internal'] = result['internal']\n",
    "    if is_internal: pass # no contained names will be added to __all__ for importing\n",
    "    else: cell_info['names'] = find_names(cell_info['original_source_code'])\n",
    "    export_target:Path = None\n",
    "    if is_set['to'     ]: export_target = module_to_path (result['to'])\n",
    "    if is_set['to_path']: export_target = make_valid_path(result['to_path'])\n",
    "    if export_target is not None:\n",
    "        if is_set['ignore_scope']:\n",
    "            raise ValueError(\"Setting 'ignore_scope' is not allowed when exporting to a custom target \"\\\n",
    "                            f\"using 'to' or 'to_path'. (cell nr. {cell_info['cell_nr']})\")\n",
    "        cell_info['export_to'].append(export_target) # Set a new export target just for this cell.\n",
    "    else:\n",
    "        if result['ignore_scope']: cell_info['export_to_default'] += 1\n",
    "        else:                      cell_info['export_to_scope']   += 1\n",
    "    \n",
    "    # TODO: support setting append or prepend\n",
    "#     append, prepend = result['append'], result['prepend']\n",
    "#     if append : cls.to[targ].append(cell)\n",
    "#     if prepend: cls.to[targ].prepend(cell)\n",
    "#     if (append and prepend):\n",
    "#         report_warning(f'Cell nr. {cell.cell_nr} is being appended AND prepended to the output file.')\n",
    "#     else: cls.to[targ].add(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_command(cmd='set',\n",
    "                  args={'file': '', 'use_names': True},\n",
    "                  active=False)\n",
    "def kw_set(file_info, cell_info, result, is_set):\n",
    "    \"set some predefined variables that control execution behaviour\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `default_exp`  \n",
    "Set the default file that cells of this notebook will be exported to.  \n",
    "Args:\n",
    "- `to`: The target file name. \n",
    "- `scope`: Set a scope for which this default value is valid. The default is 'file' level. Smaller scopes overwrite larger ones. Other options are: 'heading' (Not Implemented Yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `export`  \n",
    "This cell will be exported from the notebook to a .py file.  \n",
    "Args:  \n",
    "- `internal`: The variable, function and class names of this cell will not be added to `__all__` in the exported file, making them hidden from any `import *`.\n",
    "- `to`: Instead of exporting to the notebook or scope wide default file, this cell is exported to the file specified in this argument.\n",
    "- `cell_nr`: Overwrite the cell_nr of this cell. every cell has this number, based on it's position in the notebook file. Overwriting it has the effect of repositioning this cell in the output .py file, since cells are sorted by cell_nr.\n",
    "- `prepend`: Every file has three \"buckets\" that cells can be added to. The 'before', 'normal', and 'after' Bucket. Setting `prepend` to `True`, means this cell will be added to the 'before' Bucket. Cells in the 'before' Bucket will appear before all cells in both the 'normal' and 'after' Bucket in the output .py file.\n",
    "- `append`: Setting `append` to `True`, means this cell will be added to the 'after' Bucket. Cells in the 'after' Bucket will appear after all cells in both the 'before' and 'normal' Bucket in the output .py file. Setting neither `prepend` nor `append`, means this cell will be added to the 'normal' Bucket. Use cases for these two arguments might be sending all imports in a notebook to the top of the .py file, or helping with correctly ordering cells exported to a different file (e.g. using the `to` arg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `set`  \n",
    "Set some predefined variables that control execution behaviour.  \n",
    "Args:  \n",
    "- `file`: If this is set, the variables will only be set on this specific file.\n",
    "- `use_names`: Control whether or not a `__all__` with all (non internal) variable, function and class names should be inserted at the top of the file. Default is `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changelog:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Rethink the structure of data used to represent the programm state.\n",
    "    - To export a cell multiple times a list of some form is necessary\n",
    "    - To give better error messages a mapping from commands back to the cells that use those commands might be helpful. Such a mapping would also allow cells to be added multiple times in order to export them more than once.\n",
    "- Use the StackTrace class for error reporting in registered commands, when interacting with other files.\n",
    "- Support Automatic / Explicit Versioning\n",
    "- Add better debugging information. e.g. default_exp should show the previous occurence in case it is defined multiple times.\n",
    "- Implement code appending / prepending when exporting to non-default files\n",
    "- improve error messages in name parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = read_nb(THIS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export -internal\n",
    "# https://docs.python.org/3/library/re.html\n",
    "re_match_heading = re.compile(r\"\"\"\n",
    "        ^              # start of the string\n",
    "        (\\#+)\\s+       # 1 or more literal \"#\", then 1 or more whitespace\n",
    "        (.*)           # group of arbitrary symbols (including new line)\n",
    "        $              # end of the string\n",
    "        \"\"\",re.IGNORECASE | re.VERBOSE | re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('##', 'test')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = re_match_heading.search('## test')\n",
    "res.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config().config_file.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def parse_file(file_path:Path, file:dict, st:StackTrace) -> (bool, dict):\n",
    "    success = True\n",
    "    pure_comments_only = True\n",
    "    nb_version:(int, int) = (file['nbformat'], file['nbformat_minor'])\n",
    "    metadata  :dict       =  file['metadata']\n",
    "        \n",
    "    file_info = {\n",
    "        'origin_file': file_path,\n",
    "        'relative_origin': os.path.relpath(file_path, Config().config_file.parent).replace('\\\\', '/'),\n",
    "        'nb_version': nb_version,\n",
    "        'export_scopes': {\n",
    "            tuple([0]): None, # This is the default for an entire file.\n",
    "        },\n",
    "        'cells': list()\n",
    "    }\n",
    "    scope_count :[int] = [0]\n",
    "    scope_level :int   = 0\n",
    "    \n",
    "    cells:list = file_info['cells']\n",
    "    \n",
    "    f_pc_st = StackTrace.ext(file=file_info['relative_origin'],\n",
    "                             up=StackTrace(parse_comment, up=st))\n",
    "    \n",
    "    for i, cell in enumerate(file['cells']):\n",
    "        cell_type   = cell['cell_type']\n",
    "        cell_source = cell['source']\n",
    "        cell_info = {\n",
    "            'cell_nr' : i,\n",
    "            'cell_type' : cell_type,\n",
    "            'original_source_code' : cell_source,\n",
    "            'processed_source_code': cell_source,\n",
    "            'scope' : tuple(scope_count),\n",
    "            'export_to_py' : False,\n",
    "            'export_to_scope' : 0,\n",
    "            'export_to_default' : 0,\n",
    "            'is_internal' : None,\n",
    "            'export_to' : [],\n",
    "            'names' : None,\n",
    "            'comments' : []\n",
    "        }\n",
    "        if cell_type == 'code':\n",
    "            f_pc_st.cellno = i\n",
    "            comments_to_remove = []\n",
    "            for comment, (lineno, charno) in iter_comments(cell_source, pure_comments_only, line_limit=None):\n",
    "                f_pc_st.lineno = lineno\n",
    "                f_pc_st.excerpt = comment\n",
    "                parsing_success, cmd, result, is_set = parse_comment(all_commands, comment, st=f_pc_st)\n",
    "                if not parsing_success: continue\n",
    "                print(f'Found: {cmd} @ ({i}, {lineno}, {charno}) with args: {result}')\n",
    "                if cmd in cmd2func: cmd2func[cmd](file_info, cell_info, result, is_set)\n",
    "                else: raise ValueError(f\"The command '{cmd}' in cell number {i} is recognized, \"\\\n",
    "                                        \"but is missing a corresponding action mapping in cmd2func.\")\n",
    "                cell_info['comments'].append(comment)\n",
    "                comments_to_remove.append((lineno, charno))\n",
    "            if len(comments_to_remove) > 0:\n",
    "                lines = cell_source.splitlines()\n",
    "                if pure_comments_only:\n",
    "                    for lineno, charno in comments_to_remove[::-1]: lines.pop(lineno)\n",
    "                else:\n",
    "                    for lineno, charno in comments_to_remove[::-1]: lines[lineno] = lines[lineno][:charno]\n",
    "                cell_info['processed_source_code'] = '\\n'.join(lines)\n",
    "            \n",
    "        elif cell_type == 'markdown':\n",
    "            res = re_match_heading.search(cell_source)\n",
    "            if not (res is None): # this cell contains a heading\n",
    "                heading_level, heading_name = res.groups()\n",
    "                new_scope_level = len(heading_level) # number of '#' in the heading\n",
    "                if new_scope_level > scope_level:\n",
    "                    scope_count += ([0] * (new_scope_level - (len(scope_count)))) # extend list if necessary\n",
    "                elif new_scope_level < scope_level:\n",
    "                    scope_count = scope_count[:new_scope_level] # reset lower values\n",
    "                scope_count[new_scope_level - 1] += 1\n",
    "                scope_level = new_scope_level\n",
    "            else: pass # this cell is regular markdown\n",
    "        elif cell_type == 'raw': pass\n",
    "        else: raise ValueError(f\"Unknown cell_type '{cell_type}' in cell number {i}.\"\\\n",
    "                                \"Should be 'code', 'markdown', or 'raw'.\")\n",
    "        cells.append(cell_info)\n",
    "    return success, file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def load_and_parse_all(origin_path:Path, output_path:Path, recurse:bool, st:StackTrace) -> (bool, dict):\n",
    "    \"Loads all .ipynb files in the origin_path directory, and passes them one at a time to parse_file.\"\n",
    "    # TODO: replace these two lines with a call to file_generator() defined above.\n",
    "    file_paths:list = crawl_directory(Config().nbs_path)\n",
    "    \n",
    "    # TODO: fine tune, or even pass an argument from the user on how many thread to use for prefetching files.\n",
    "    #       num_cpus() from nbdev.imports can be used here\n",
    "    file_generator = BackgroundGenerator(((file_path, read_nb(file_path)) for file_path in file_paths), max_prefetch=4)\n",
    "    \n",
    "    parsed_files = {\n",
    "        # Add flags and settings variables above this line\n",
    "        'files': list()\n",
    "    }\n",
    "    \n",
    "    # TODO: use multithreading / multiprocessing per file / per bunch of cells\n",
    "    for file_path, file in file_generator:\n",
    "        # if file_path.name != THIS_FILE: continue # For Debugging\n",
    "        success, file = parse_file(file_path, file, st=StackTrace(parse_file, up=st))\n",
    "        # TODO: try parsing all the files, even if one fails?\n",
    "        if not success:\n",
    "            st.report_error(Exception(f'Error while parsing {file_path}'))\n",
    "            return 0, None\n",
    "        # TODO: before returning, give any meta programm a chance to run.\n",
    "        # maybe have parse_file return some additional information about any meta programm\n",
    "        parsed_files['files'].append(file)\n",
    "        \n",
    "    return True, parsed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_names(names:set, sep='\\n\\n\\n')->str:\n",
    "    start, part = \"__all__ = [\", ''\n",
    "    for name in sorted(names):\n",
    "        if len(part) + len(name) < 80:\n",
    "            part = f\"{part}'{name}', \"\n",
    "        else:\n",
    "            start += (part + '\\n')\n",
    "            part = f\"           '{name}', \"\n",
    "    return f'{sep}{start}{part[:-2]}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_names_2(names):\n",
    "    return f\"\\n\\n\\n__all__ = ['{', '.join(sorted(names))}']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ['abc'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit stringify_names(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit stringify_names(test_data)\n",
    "\n",
    ">>> 242 µs ± 489 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit stringify_names_2(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit stringify_names_2(test_data)\n",
    "\n",
    ">>> 18 µs ± 146 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def write_file(to:Path, orig:str, names:set, code:list, st:StackTrace) -> bool:\n",
    "    sep:str = '\\n\\n\\n'\n",
    "    if orig is None:\n",
    "        warning = f'# AUTOGENERATED! DO NOT EDIT! View info comment on each cell for file to edit.'\n",
    "    else:\n",
    "        warning = f'# AUTOGENERATED! DO NOT EDIT! File to edit: {orig} (unless otherwise specified).'\n",
    "    if len(names) > 0:\n",
    "        # TODO: add line breaks at regular intervals\n",
    "        comma = \"', '\"\n",
    "        names:str = f\"{sep}__all__ = ['{comma.join(sorted(names))}']\"\n",
    "    else: names:str = f'{sep}__all__ = []'\n",
    "    code :str = sep + sep.join(code)\n",
    "    file_content:str = f'{warning}{names}{code}'\n",
    "    # print('-'*70)\n",
    "    # print(to)\n",
    "    # print(file_content)\n",
    "    to.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(to, 'w', encoding='utf8') as f: f.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def write_out_all(parsed_files, st:StackTrace) -> bool:\n",
    "    # TODO: write one file at a time to disk, to the correct directory,\n",
    "    # initialize a python module, if it doesn't already exists,\n",
    "    # Handle mergers between multiple parsed_files. <-----------------\n",
    "    config    = Config()\n",
    "    lib_path  = config.lib_path\n",
    "    nbs_path  = config.nbs_path\n",
    "    proj_path = config.config_file.parent\n",
    "    zero_tuple = tuple([0])\n",
    "    \n",
    "    export_files = defaultdict(lambda: {'names': set(), 'code': [], 'orig': None})\n",
    "    \n",
    "    for file_info in parsed_files['files']:\n",
    "        rel_orig:str = file_info['relative_origin']\n",
    "        scopes:dict  = file_info['export_scopes']\n",
    "        assert zero_tuple in scopes, 'No default in export Scopes.'\n",
    "        scopes_available:bool = (len(scopes) > 1)\n",
    "        default_export:Path = scopes[zero_tuple]\n",
    "        # NOTE: Having no default is ok, as long as all cells still have a valid export target\n",
    "        none_default  :bool = (default_export is None)\n",
    "            \n",
    "        if not none_default:\n",
    "            default_state = export_files[default_export]\n",
    "            if (default_state['orig'] is None): default_state['orig'] = rel_orig\n",
    "            else: raise ValueError(f'Multiple files have {default_export} as the default export target. '\\\n",
    "                                   f'(old: {default_state[\"orig\"]} | new: {rel_orig})')\n",
    "                \n",
    "        for cell in file_info['cells']:\n",
    "            if not cell['export_to_py']: continue\n",
    "            info_string = f\"# {'Internal ' if cell['is_internal'] else ''}Cell nr. {cell['cell_nr']}\"\n",
    "            info_string_src = f\"{info_string}; Comes from '{rel_orig}'\"\n",
    "            \n",
    "            if len(cell['export_to']) > 0:\n",
    "                for to in cell['export_to']:\n",
    "                    state:dict = export_files[to]\n",
    "                    if not cell['is_internal']: state['names'].update(cell['names'])\n",
    "                    # TODO: implement code appending / prepending here\n",
    "                    state['code'].append(f\"{info_string_src}\\n{relativify_imports(to, cell['processed_source_code'])}\")\n",
    "            \n",
    "            if scopes_available:\n",
    "                if cell['export_to_scope'] > 0:\n",
    "                    # Do scope matching\n",
    "                    cell_scope:tuple = cell['scope']\n",
    "                    best_fit = zero_tuple\n",
    "                    best_fit_len = 0\n",
    "                    # NOTE: The number of scopes should usually be relatively small\n",
    "                    for k in scopes.keys(): # TODO: can this go faster with sorting, binary search, quit early?\n",
    "                        if ((len(k) > best_fit_len) # Trying to find the tightest fit\n",
    "                            and (k == cell_scope[:len(k)])): # iff cell is part of this scope\n",
    "                            best_fit, best_fit_len = k, len(k)\n",
    "                    to:Path = scopes[best_fit]\n",
    "                    if (best_fit == zero_tuple) or (to == default_export):\n",
    "                        cell['export_to_default'] += cell['export_to_scope']\n",
    "                        pass\n",
    "                    else:\n",
    "                        state:dict = export_files[to]\n",
    "                        if not cell['is_internal']: state['names'].update(cell['names'])\n",
    "                        for _ in range(cell['export_to_scope']):\n",
    "                            # TODO: implement code appending / prepending here\n",
    "                            state['code'].append(f\"{info_string_src}\\n{relativify_imports(to, cell['processed_source_code'])}\")\n",
    "            else: cell['export_to_default'] += cell['export_to_scope']\n",
    "                \n",
    "            if cell['export_to_default'] > 0:\n",
    "                if none_default:\n",
    "                    raise ValueError(f'Export Target of cell {cell[\"cell_nr\"]} is None. '\\\n",
    "                                     'Did you forget to add a default target using `default_exp`?')\n",
    "                to = default_export\n",
    "                state:dict = export_files[to]\n",
    "                if not cell['is_internal']: state['names'].update(cell['names'])\n",
    "                for _ in range(cell['export_to_default']):\n",
    "                    # TODO: implement code appending / prepending here\n",
    "                    state['code'].append(f\"{info_string}\\n{relativify_imports(to, cell['processed_source_code'])}\")\n",
    "        # NOTE: Files can't be written at this point, since there might be other notebooks exporting to the same file.\n",
    "    \n",
    "    # print(dict(export_files))\n",
    "    for to, state in export_files.items():\n",
    "        write_file(to=to, orig=state['orig'], names=state['names'], code=state['code'],\n",
    "                   st=StackTrace(write_file, up=st))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "def main(origin_path:str=None, output_path:str=None, recurse:bool=True) -> bool:\n",
    "    st = StackTrace(main)\n",
    "    origin_path:Path = Config().nbs_path if origin_path is None else Path(origin_path).resolve()\n",
    "    output_path:Path = Config().lib_path if output_path is None else Path(output_path).resolve()\n",
    "    \n",
    "    success, parsed_files = load_and_parse_all(origin_path, output_path, recurse,\n",
    "                                               st=StackTrace(load_and_parse_all, up=st))\n",
    "    if not success:\n",
    "        return 0, None\n",
    "    # NOTE: At this point all files are completely parsed, and any meta programm has run.\n",
    "    \n",
    "    success = write_out_all(parsed_files, st=StackTrace(write_out_all, st))\n",
    "    return success, parsed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +export\n",
    "set_arg_parse_report_options(report_error=False)\n",
    "set_main_report_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: default_exp @ (1, 0, 0) with args: {'to': 'argument_parsing', 'to_path': '', 'use_scope': True}\n",
      "Found: export @ (3, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (4, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (5, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (6, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (9, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (16, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (18, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (20, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (22, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (24, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (27, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (28, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (29, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: default_exp @ (38, 0, 0) with args: {'to': 'main', 'to_path': '', 'use_scope': False}\n",
      "Found: export @ (40, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (41, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (45, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (46, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (47, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (58, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (62, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (67, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (77, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (78, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (79, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (81, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (82, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (83, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (84, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (85, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (86, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (87, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (93, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (97, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (98, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (102, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (103, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (105, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (106, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (108, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (116, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (117, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (119, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (128, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (130, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (133, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (144, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (145, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (146, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (147, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (158, 0, 0) with args: {'internal': True, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (161, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (162, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (171, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (172, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (174, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n",
      "Found: export @ (176, 0, 0) with args: {'internal': False, 'to': '', 'to_path': '', 'ignore_scope': False, 'cell_nr': 0, 'prepend': False, 'append': False}\n"
     ]
    }
   ],
   "source": [
    "success, parsed_files = main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev_rewrite.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, parsed_files = main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0,): WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/main.py'),\n",
       " (1,): WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite/argument_parsing.py')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_files['files'][0]['export_scopes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in parsed_files['files'][0]['cells'] if c['export_to_py']];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop new Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config().lib_path == Config().path_to('lib_path') == Config().path_to('lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//DESKTOP-MDPTPCT/Projects/GitHub/nbdev_rewrite/nbdev_rewrite')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib = Config().path_to('lib'); lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regex for matching import statements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://docs.python.org/3.0/reference/simple_stmts.html#the-import-statement\n",
    "import_stmt     ::=  \"import\" module [\"as\" name] ( \",\" module [\"as\" name] )*\n",
    "                     \n",
    "                     | \"from\" relative_module \"import\" identifier [\"as\" name]\n",
    "                     ( \",\" identifier [\"as\" name] )*\n",
    "                     \n",
    "                     | \"from\" relative_module \"import\" \"(\" identifier [\"as\" name]\n",
    "                     ( \",\" identifier [\"as\" name] )* [\",\"] \")\"\n",
    "                     \n",
    "                     | \"from\" module \"import\" \"*\"\n",
    "module          ::=  (identifier \".\")* identifier\n",
    "relative_module ::=  \".\"* module | \".\"+\n",
    "name            ::=  identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "letter = 'a-zA-Z'\n",
    "identifier = f'[{letter}_][{letter}0-9_]*'\n",
    "module = fr'(?:{identifier}\\.)*{identifier}'\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_module = fr'(?:\\.*{module}|\\.+)'\n",
    "name = identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:from\\\\ +((?:\\\\.*(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*|\\\\.+))\\\\ +import\\\\ +([a-zA-Z_][a-zA-Z0-9_]*(?:\\\\ +as\\\\ +[a-zA-Z_][a-zA-Z0-9_]*)?(?:\\\\ *,\\\\ *(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*(?:\\\\ +as\\\\ +[a-zA-Z_][a-zA-Z0-9_]*)?)*)|from\\\\ +((?:\\\\.*(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*|\\\\.+))\\\\ +import\\\\ *(\\\\(\\\\s*[a-zA-Z_][a-zA-Z0-9_]*(?:\\\\s+as\\\\s+[a-zA-Z_][a-zA-Z0-9_]*)?(?:\\\\s*,\\\\s*(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*(?:\\\\s+as\\\\s+[a-zA-Z_][a-zA-Z0-9_]*)?)*\\\\s*,?\\\\s*\\\\))|from\\\\ +((?:\\\\.*(?:[a-zA-Z_][a-zA-Z0-9_]*\\\\.)*[a-zA-Z_][a-zA-Z0-9_]*|\\\\.+))\\\\ +import\\\\ *\\\\*)'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_name  = fr'(?:\\ +as\\ +{name})'\n",
    "as_name  = fr'{as_name}?(?:\\ *,\\ *{module}{as_name}?)*'\n",
    "\n",
    "import_1 = fr'import\\ +({module})({as_name})'\n",
    "\n",
    "import_2 = fr'from\\ +({relative_module})\\ +import\\ +({identifier}{as_name})'\n",
    "\n",
    "as_name_s  = fr'(?:\\s+as\\s+{name})'\n",
    "as_name_s  = fr'{as_name_s}?(?:\\s*,\\s*{module}{as_name_s}?)*'\n",
    "import_3   = fr'from\\ +({relative_module})\\ +import\\ *(\\(\\s*{identifier}{as_name_s}\\s*,?\\s*\\))'\n",
    "\n",
    "# NOTE: The docs say 'module', but in reality relative imports work as well.\n",
    "import_4 = fr'from\\ +({relative_module})\\ +import\\ *\\*'\n",
    "\n",
    "# NOTE: import_1 is not included, because it doesn't allow relative imports.\n",
    "import_stmt = fr'(?:{import_2}|{import_3}|{import_4})'\n",
    "import_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html\n",
    "re_test = re.compile(fr\"\"\"\n",
    "        ^              # start of the string\n",
    "        (\\ *)          # capturing group of any amount of whitespace (indenting)\n",
    "        {import_stmt}  # definition for matching a module \n",
    "        \\ *            # non-capturing whitespace\n",
    "                       # TODO: match any remaining character in case of e.g. comments\n",
    "        $              # end of the string\n",
    "        \"\"\", re.VERBOSE | re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_test.search('import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod') # import_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from numpy import array as arr, linalg.solve, module as mod'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_test.search('from numpy import array as arr, linalg.solve, module as mod').group() # import_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from numpy import (abs, b as c, h,)'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_test.search('from numpy import (abs, b as c, h,)').group() # import_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from . import *'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_test.search('from numpy import *').group() # import_4\n",
    "re_test.search('from . import *').group() # import_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'numpy', 'array as arr, linalg.solve, module as mod', None, None, None)\n",
      "('', None, None, 'numpy', '(abs, b as c, h,)', None)\n",
      "('', None, None, None, None, 'numpy')\n",
      "('    ', None, None, None, None, '.')\n",
      "('', None, None, 'numpy', '(\\n    abs\\n                  as a\\n    ,\\n                       absolute \\n    as \\n                  f\\n                  )', None)\n",
      "\n",
      "import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod\n",
      "# Nothing to see here\n",
      "from <REL>numpy import array as arr, linalg.solve, module as mod\n",
      "def function():\n",
      "    pass\n",
      "\n",
      "\n",
      "    from . import *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_The_Name = 'numpy'\n",
    "# import_stmt\n",
    "def repl(match):\n",
    "    print(match.groups())\n",
    "    sp, n2, a2, n3, a3, n4 = match.groups()\n",
    "    if n2:\n",
    "        if n2 == _The_Name: return f'{sp}from <REL>{n2} import {a2}'\n",
    "        else: return f'{sp}from {n2} import {a2}'\n",
    "    elif n3:\n",
    "        if n3 == _The_Name: f'{sp}from <REL>{n3} import {a3}'\n",
    "        else: return f'{sp}from {n3} import {a3}'\n",
    "    elif n4:\n",
    "        if n4 == _The_Name: f'{sp}from <REL>{n4} import *'\n",
    "        else: return f'{sp}from {n4} import *'\n",
    "\n",
    "res = re_test.sub(repl, \"\"\"\n",
    "import numpy as np, matplotlib.pyplot, moduleaaaabbb as mod\n",
    "# Nothing to see here\n",
    "from numpy import array as arr, linalg.solve, module as mod\n",
    "def function():\n",
    "    pass\n",
    "from numpy import (abs, b as c, h,)\n",
    "from numpy import *\n",
    "    from . import *\n",
    "from numpy  import(\n",
    "    abs\n",
    "                  as a\n",
    "    ,\n",
    "                       absolute \n",
    "    as \n",
    "                  f\n",
    "                  )\"\"\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
